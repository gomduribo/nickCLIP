{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6ba10f-0def-48d3-b726-926f4558d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import torch\n",
    "# from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ce285c-6ee1-41ab-ace2-f49af16857c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d5c2f-6373-4d1e-a762-41d5d53c1f9a",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93377edb-602d-4ddd-9c12-d89c1e445297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, root, phase, transformer=None):\n",
    "        self.root=root\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.image_list=sorted(os.listdir(root+phase+\"/image/\"))\n",
    "        self.des_list=sorted(os.listdir(root+phase+\"/description/\"))\n",
    "        self.label_list=sorted(os.listdir(root+phase+\"/label/\"))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img, des, label = self.get_data(index)\n",
    "        return img['image'], des, label\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def get_data(self, index):\n",
    "        # label\n",
    "        try:\n",
    "            label_file_name=self.label_list[index]\n",
    "            lab_f=open(self.root+self.phase+\"/label/\"+label_file_name, \"r\")\n",
    "            label=lab_f.read()\n",
    "            if(len(label)>=10):\n",
    "                label=label[0:10]\n",
    "            elif(len(label)<10):\n",
    "                margin=10-len(label)\n",
    "                padding=\" \"*margin\n",
    "                label=label+padding\n",
    "            label=list(label.lower())\n",
    "\n",
    "            # description\n",
    "            des_file_name=self.des_list[index]\n",
    "            des_f=open(self.root+self.phase+\"/description/\"+des_file_name, \"r\")\n",
    "            des_text=des_f.read()\n",
    "    #         des=des_text.split(\" \")\n",
    "            des=des_text\n",
    "\n",
    "            # image\n",
    "            img_file_name=self.image_list[index]\n",
    "            image=cv2.imread(self.root+self.phase+\"/image/\"+img_file_name)\n",
    "            img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if(self.transformer!=None):\n",
    "                transformed_img=self.transformer(image=img)\n",
    "                img=transformed_img\n",
    "        except:\n",
    "            print(f\"error: image name=>{img_file_name} des name=>{des_file_name} label name=>{label_file_name}\")\n",
    "            img={'image':torch.zeros((3,448,448))}\n",
    "            des=''\n",
    "            label=''\n",
    "        return img, des, label\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4eade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(PATH, batch_size=2):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=None)\n",
    "    train_dataset=Dataset(root=PATH, phase=\"train\", transformer=transformer)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "    val_dataset=Dataset(root=PATH, phase=\"valid\", transformer=transformer)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    print(f\"trainset:{len(train_dataset)} validset:{len(val_dataset)}\")\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a342875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb5975-f093-4940-952b-abff5967f2fc",
   "metadata": {},
   "source": [
    "## MODELs\n",
    " ![Untitled](../img/nickCLIP_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae290c3",
   "metadata": {},
   "source": [
    "### Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d328de53-85c7-43e6-808c-32c4241de00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        resnet = torchvision.models.resnet34(pretrained = True)\n",
    "        layers = [m for m in resnet.children()]\n",
    "        \n",
    "        self.backbone = nn.Sequential(*layers[:-2]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=128, out_channels=32, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=32, out_channels=4, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(4),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features=784, out_features=768)\n",
    "            \n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.head(out) # final output=> (1, 196)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b041c468-eff7-4f10-a803-cebecf1bbe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "             ReLU-14         [-1, 64, 112, 112]               0\n",
      "           Conv2d-15         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 112, 112]             128\n",
      "             ReLU-17         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-18         [-1, 64, 112, 112]               0\n",
      "           Conv2d-19         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-20         [-1, 64, 112, 112]             128\n",
      "             ReLU-21         [-1, 64, 112, 112]               0\n",
      "           Conv2d-22         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-23         [-1, 64, 112, 112]             128\n",
      "             ReLU-24         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-25         [-1, 64, 112, 112]               0\n",
      "           Conv2d-26          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 56, 56]             256\n",
      "             ReLU-28          [-1, 128, 56, 56]               0\n",
      "           Conv2d-29          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
      "           Conv2d-31          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-34          [-1, 128, 56, 56]               0\n",
      "           Conv2d-35          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 56, 56]             256\n",
      "             ReLU-37          [-1, 128, 56, 56]               0\n",
      "           Conv2d-38          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 56, 56]             256\n",
      "             ReLU-40          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-41          [-1, 128, 56, 56]               0\n",
      "           Conv2d-42          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 56, 56]             256\n",
      "             ReLU-44          [-1, 128, 56, 56]               0\n",
      "           Conv2d-45          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 56, 56]             256\n",
      "             ReLU-47          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-48          [-1, 128, 56, 56]               0\n",
      "           Conv2d-49          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
      "             ReLU-51          [-1, 128, 56, 56]               0\n",
      "           Conv2d-52          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
      "             ReLU-54          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-55          [-1, 128, 56, 56]               0\n",
      "           Conv2d-56          [-1, 256, 28, 28]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 28, 28]             512\n",
      "             ReLU-58          [-1, 256, 28, 28]               0\n",
      "           Conv2d-59          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 28, 28]             512\n",
      "           Conv2d-61          [-1, 256, 28, 28]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 28, 28]             512\n",
      "             ReLU-63          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-64          [-1, 256, 28, 28]               0\n",
      "           Conv2d-65          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 28, 28]             512\n",
      "             ReLU-67          [-1, 256, 28, 28]               0\n",
      "           Conv2d-68          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 28, 28]             512\n",
      "             ReLU-70          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 256, 28, 28]               0\n",
      "           Conv2d-72          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 28, 28]             512\n",
      "             ReLU-74          [-1, 256, 28, 28]               0\n",
      "           Conv2d-75          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 28, 28]             512\n",
      "             ReLU-77          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-78          [-1, 256, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 28, 28]             512\n",
      "             ReLU-84          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-85          [-1, 256, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 28, 28]             512\n",
      "             ReLU-88          [-1, 256, 28, 28]               0\n",
      "           Conv2d-89          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 28, 28]             512\n",
      "             ReLU-91          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-92          [-1, 256, 28, 28]               0\n",
      "           Conv2d-93          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 28, 28]             512\n",
      "             ReLU-95          [-1, 256, 28, 28]               0\n",
      "           Conv2d-96          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 28, 28]             512\n",
      "             ReLU-98          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-99          [-1, 256, 28, 28]               0\n",
      "          Conv2d-100          [-1, 512, 14, 14]       1,179,648\n",
      "     BatchNorm2d-101          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-102          [-1, 512, 14, 14]               0\n",
      "          Conv2d-103          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-104          [-1, 512, 14, 14]           1,024\n",
      "          Conv2d-105          [-1, 512, 14, 14]         131,072\n",
      "     BatchNorm2d-106          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-107          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-108          [-1, 512, 14, 14]               0\n",
      "          Conv2d-109          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-110          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-111          [-1, 512, 14, 14]               0\n",
      "          Conv2d-112          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-113          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-114          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-115          [-1, 512, 14, 14]               0\n",
      "          Conv2d-116          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-117          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-118          [-1, 512, 14, 14]               0\n",
      "          Conv2d-119          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-120          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-121          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-122          [-1, 512, 14, 14]               0\n",
      "          Conv2d-123          [-1, 256, 14, 14]         131,072\n",
      "     BatchNorm2d-124          [-1, 256, 14, 14]             512\n",
      "            ReLU-125          [-1, 256, 14, 14]               0\n",
      "          Conv2d-126          [-1, 128, 14, 14]         294,912\n",
      "     BatchNorm2d-127          [-1, 128, 14, 14]             256\n",
      "            ReLU-128          [-1, 128, 14, 14]               0\n",
      "          Conv2d-129           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-130           [-1, 32, 14, 14]              64\n",
      "            ReLU-131           [-1, 32, 14, 14]               0\n",
      "          Conv2d-132            [-1, 4, 14, 14]           1,152\n",
      "     BatchNorm2d-133            [-1, 4, 14, 14]               8\n",
      "            ReLU-134            [-1, 4, 14, 14]               0\n",
      "         Flatten-135                  [-1, 784]               0\n",
      "          Linear-136                  [-1, 768]         602,880\n",
      "================================================================\n",
      "Total params: 22,352,392\n",
      "Trainable params: 22,352,392\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 387.01\n",
      "Params size (MB): 85.27\n",
      "Estimated Total Size (MB): 474.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Image_Enc = Image_Encoder()\n",
    "Image_Enc.to(device)\n",
    "torchsummary.summary(Image_Enc, (3,448,448))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04259a95",
   "metadata": {},
   "source": [
    "### Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d841b979-6222-4183-854d-a83b06918ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Encoder(nn.Module):\n",
    "    def __init__(self, device, pretrained='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.pretrained=pretrained\n",
    "        self.device=device\n",
    "        self.BERT = BertModel.from_pretrained(self.pretrained)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.pretrained)\n",
    "    \n",
    "#     def preprocess(self, text):\n",
    "#         tokenizer = BertTokenizer.from_pretrained(self.pretrained)\n",
    "#         marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "#         tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#         segments_ids = [1] * len(tokenized_text)\n",
    "        \n",
    "#         tokens_tensor = torch.tensor([indexed_tokens]).to(self.device)\n",
    "#         segments_tensors = torch.tensor([segments_ids]).to(self.device)\n",
    "        \n",
    "#         return tokens_tensor, segments_tensors\n",
    "        \n",
    "#     def postprocess(self, encoded_layers):\n",
    "# #         token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "# #         token_embeddings = token_embeddings.permute(1,0,2)\n",
    "#         token_vecs = encoded_layers[11][0]\n",
    "#         sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        \n",
    "#         return sentence_embedding\n",
    "    \n",
    "    def forward(self,x):\n",
    "        tokens=self.tokenizer(x, \n",
    "                 add_special_tokens=True, \n",
    "                 max_length=100, \n",
    "                 padding=\"max_length\",\n",
    "                 truncation=True,\n",
    "                 return_tensors=\"pt\")\n",
    "        tokens.to(self.device)\n",
    "        output = self.BERT(**tokens)\n",
    "        out = output.last_hidden_state.mean(axis=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926c73a0-8099-4ced-a244-25a563220ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text_Encoder(\n",
       "  (BERT): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_Enc=Text_Encoder(device=device)\n",
    "Text_Enc.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d41ac",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e14cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_decoder(nn.Module):\n",
    "    ''' Decodes hidden state output by encoder '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "\n",
    "        '''\n",
    "        : param input_size:     the number of features in the input X\n",
    "        : param hidden_size:    the number of features in the hidden state h\n",
    "        : param num_layers:     number of recurrent layers (i.e., 2 means there are\n",
    "        :                       2 stacked LSTMs)\n",
    "        '''\n",
    "        \n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
    "                            num_layers = num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)           \n",
    "\n",
    "    def forward(self, x_input, encoder_hidden_states):\n",
    "        \n",
    "        '''        \n",
    "        : param x_input:                    should be 2D (batch_size, input_size)\n",
    "        : param encoder_hidden_states:      hidden states\n",
    "        : return output, hidden:            output gives all the hidden states in the sequence;\n",
    "        :                                   hidden gives the hidden state and cell state for the last\n",
    "        :                                   element in the sequence \n",
    " \n",
    "        '''\n",
    "#         print(x_input.shape)\n",
    "        lstm_out, self.hidden = self.lstm(x_input, encoder_hidden_states)\n",
    "#         print(f\"lstm_out shape:{lstm_out.shape}\") #lstm_out.shape->(1,1,768)\n",
    "        output = self.linear(lstm_out)     \n",
    "        \n",
    "        return output, self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3a4bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstm_decoder(\n",
       "  (lstm): LSTM(37, 768, batch_first=True)\n",
       "  (linear): Linear(in_features=768, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder=lstm_decoder(input_size=37, hidden_size=768)\n",
    "decoder.to(device)\n",
    "# torchsummary.summary(decoder)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "992212fe",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a91d7",
   "metadata": {},
   "source": [
    "## nickCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55dfcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nickCLIP(nn.Module):\n",
    "    def __init__(self, image_encoder, text_encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.image_encoder=image_encoder.to(device)\n",
    "        self.text_encoder=text_encoder.to(device)\n",
    "        self.decoder=decoder.to(device)\n",
    "        \n",
    "    def forward(self, image, description):\n",
    "        img_embed=self.image_encoder(image).unsqueeze(0)\n",
    "        sen_embed=self.text_encoder(description).unsqueeze(0)\n",
    "        merged_embed=img_embed+sen_embed\n",
    "        \n",
    "        batch_size=image.shape[0]\n",
    "        target_len=10\n",
    "        initial_c=torch.zeros(1,batch_size,768).to(device)\n",
    "        start_token = torch.zeros(batch_size,1,37).to(device) # start token??\n",
    "        \n",
    "        inputs=start_token\n",
    "        hidden_state=merged_embed\n",
    "        cell_state=initial_c\n",
    "        \n",
    "        outputs=torch.zeros(batch_size, target_len, 37)\n",
    "#         for b in range(batch_size):\n",
    "        for i in range(target_len):\n",
    "            output,(hidden_state, cell_state)=decoder(inputs,(hidden_state, cell_state))\n",
    "            inputs=output\n",
    "#             print(f\"{i}-output_shape:{output.shape}\")\n",
    "#             print(f\"{outputs[:,i,:].shape}, {output.shape}\" )\n",
    "            outputs[:,i,:]=output.squeeze(1)\n",
    "        \n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd216e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nickCLIP(\n",
       "  (image_encoder): Image_Encoder(\n",
       "    (backbone): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Flatten(start_dim=1, end_dim=-1)\n",
       "      (13): Linear(in_features=784, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (text_encoder): Text_Encoder(\n",
       "    (BERT): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): lstm_decoder(\n",
       "    (lstm): LSTM(37, 768, batch_first=True)\n",
       "    (linear): Linear(in_features=768, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image_Enc = Image_Encoder()\n",
    "Text_Enc=Text_Encoder(device=device)\n",
    "Decoder=lstm_decoder(input_size=37, hidden_size=768)\n",
    "model=nickCLIP(image_encoder=Image_Enc, text_encoder=Text_Enc, decoder=Decoder, device=device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0877f3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d99077a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, des, label\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    des_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        des_list.append(b)\n",
    "        label_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), des_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d825a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot dict\n",
    "def alp_to_mat(string_list,batch_size):\n",
    "    one_hot_dict={'a':0,'b':1,'c':2,'d':3,'e':4,'f':5,'g':6,'h':7,'i':8,'j':9,'k':10,'l':11,'m':12,'n':13,'o':14,'p':15,'q':16,'r':17,'s':18,'t':19,'u':20,'v':21,'w':22,'x':23,'y':24,'z':25,'0':26,'1':27,'2':28,'3':29,'4':30,'5':31,'6':32,'7':33,'8':34,'9':35,' ':36}\n",
    "    alp_to_num_list=[]\n",
    "    batch_size=len(string_list)\n",
    "    alp_to_mat_list=torch.zeros((batch_size,len(string_list[0]),37)) #(B,name_len,one_hot_len)\n",
    "    for j in range(batch_size):\n",
    "        for i in range(len(string_list[j])):\n",
    "            char=string_list[j][i]\n",
    "            if(char in one_hot_dict.keys()):\n",
    "                pass\n",
    "            else:\n",
    "                char=' '\n",
    "                \n",
    "            alp_to_num_list.append(one_hot_dict[char])\n",
    "            mat=torch.zeros(37)\n",
    "    #         print(len(string_list))\n",
    "    #         print(mat.shape)\n",
    "            mat[one_hot_dict[char]]=1\n",
    "#             print(f\"{alp_to_mat_list.shape}-{mat.shape}\")\n",
    "            alp_to_mat_list[j,i,:]=mat\n",
    "    #         result=torch.Tensor(alp_to_mat_list)\n",
    "    return alp_to_mat_list\n",
    "    \n",
    "\n",
    "\n",
    "# test=[list(\"heloo     \"),list(\"     fffff\"),list(\"kdkdkkdkdk\"),list(\"abcdefghij\")]\n",
    "# result=alp_to_mat(test,len(test))\n",
    "# result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc063d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cf74912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "            \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            description = batch[1]\n",
    "            label = batch[2]\n",
    "            \n",
    "            target=alp_to_mat(label,len(label))\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                predictions = model(images, description)\n",
    "                \n",
    "            target_for_loss=target.view(-1,370).to(device)\n",
    "            predictions_for_loss=predictions.view(-1,370).to(device)\n",
    "\n",
    "#             loss=criterion(predictions_for_loss, target_for_loss, torch.Tensor(predictions_for_loss.size(0)).cuda().fill_(1.0))\n",
    "            loss=criterion(predictions_for_loss, target_for_loss)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "        \n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "            \n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2c61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset:43864 validset:11340\n"
     ]
    }
   ],
   "source": [
    "PATH=\"/workspace/team2/data/filter_50000/\"\n",
    "\n",
    "is_cuda = True\n",
    "\n",
    "IMAGE_SIZE = 448\n",
    "# BATCH_SIZE = 32\n",
    "BATCH_SIZE = 48\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "\n",
    "IMAGE_ENC=\"RESNET34\"\n",
    "TEXT_ENC=\"BERT\"\n",
    "DECODER=\"LSTM\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(PATH=PATH, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "Image_Enc = Image_Encoder()\n",
    "Text_Enc=Text_Encoder(device=device)\n",
    "Decoder=lstm_decoder(input_size=37, hidden_size=768)\n",
    "model=nickCLIP(image_encoder=Image_Enc, text_encoder=Text_Enc, decoder=Decoder, device=device)\n",
    "model.to(device)\n",
    "\n",
    "# criterion = torch.nn.CosineEmbeddingLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79bc8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/team2/yb_workspace/nickCLIP/experiments/wandb/run-20231121_171718-lbcu7p5z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/nickclip_baseline/runs/lbcu7p5z' target=\"_blank\">polished-lion-7</a></strong> to <a href='https://wandb.ai/urp/nickclip_baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/nickclip_baseline' target=\"_blank\">https://wandb.ai/urp/nickclip_baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/nickclip_baseline/runs/lbcu7p5z' target=\"_blank\">https://wandb.ai/urp/nickclip_baseline/runs/lbcu7p5z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/nickclip_baseline/runs/lbcu7p5z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1cc7379a30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"nickclip_baseline\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"image encoder\":IMAGE_ENC,\n",
    "    \"test encoder\":TEXT_ENC,\n",
    "    \"decoder\":DECODER,\n",
    "    \"dataset\": PATH,\n",
    "    \"epochs\": num_epochs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/914] - total_loss: 61.7041  \n",
      "<<<iteration:[40/914] - total_loss: 58.5447  \n",
      "<<<iteration:[60/914] - total_loss: 58.4517  \n",
      "<<<iteration:[80/914] - total_loss: 58.3640  \n",
      "<<<iteration:[100/914] - total_loss: 58.2778  \n",
      "<<<iteration:[120/914] - total_loss: 58.2522  \n",
      "<<<iteration:[140/914] - total_loss: 58.1868  \n",
      "<<<iteration:[160/914] - total_loss: 58.1622  \n",
      "<<<iteration:[180/914] - total_loss: 58.1081  \n",
      "<<<iteration:[200/914] - total_loss: 58.0756  \n",
      "<<<iteration:[220/914] - total_loss: 58.0767  \n",
      "<<<iteration:[240/914] - total_loss: 58.0723  \n",
      "<<<iteration:[260/914] - total_loss: 58.0664  \n",
      "<<<iteration:[280/914] - total_loss: 58.0326  \n",
      "<<<iteration:[300/914] - total_loss: 58.0215  \n",
      "<<<iteration:[320/914] - total_loss: 58.0104  \n",
      "<<<iteration:[340/914] - total_loss: 57.9943  \n",
      "<<<iteration:[360/914] - total_loss: 57.9679  \n",
      "<<<iteration:[380/914] - total_loss: 57.9753  \n",
      "<<<iteration:[400/914] - total_loss: 57.9587  \n",
      "<<<iteration:[420/914] - total_loss: 57.9799  \n",
      "<<<iteration:[440/914] - total_loss: 57.9315  \n",
      "<<<iteration:[460/914] - total_loss: 57.9003  \n",
      "<<<iteration:[480/914] - total_loss: 57.9018  \n",
      "<<<iteration:[500/914] - total_loss: 57.9001  \n",
      "<<<iteration:[520/914] - total_loss: 57.9121  \n",
      "<<<iteration:[540/914] - total_loss: 57.9080  \n",
      "<<<iteration:[560/914] - total_loss: 57.9157  \n",
      "<<<iteration:[580/914] - total_loss: 57.9163  \n",
      "<<<iteration:[600/914] - total_loss: 57.9102  \n",
      "<<<iteration:[620/914] - total_loss: 57.8922  \n",
      "<<<iteration:[640/914] - total_loss: 57.8850  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[660/914] - total_loss: 57.8951  \n",
      "<<<iteration:[680/914] - total_loss: 57.8529  \n",
      "<<<iteration:[700/914] - total_loss: 57.8713  \n",
      "<<<iteration:[720/914] - total_loss: 57.8726  \n",
      "<<<iteration:[740/914] - total_loss: 57.8271  \n",
      "<<<iteration:[760/914] - total_loss: 57.8686  \n",
      "<<<iteration:[780/914] - total_loss: 57.9035  \n",
      "<<<iteration:[800/914] - total_loss: 57.8675  \n",
      "<<<iteration:[820/914] - total_loss: 57.8403  \n",
      "<<<iteration:[840/914] - total_loss: 57.8420  \n",
      "<<<iteration:[860/914] - total_loss: 57.8705  \n",
      "<<<iteration:[880/914] - total_loss: 57.8498  \n",
      "<<<iteration:[900/914] - total_loss: 57.8547  \n",
      "\n",
      "epoch:1/100 - Train Loss: 58.0103, Val Loss: 57.8534\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.6800  \n",
      "<<<iteration:[40/914] - total_loss: 57.8606  \n",
      "<<<iteration:[60/914] - total_loss: 57.8770  \n",
      "<<<iteration:[80/914] - total_loss: 57.8593  \n",
      "<<<iteration:[100/914] - total_loss: 57.8635  \n",
      "<<<iteration:[120/914] - total_loss: 57.8289  \n",
      "<<<iteration:[140/914] - total_loss: 57.8680  \n",
      "<<<iteration:[160/914] - total_loss: 57.8192  \n",
      "<<<iteration:[180/914] - total_loss: 57.8260  \n",
      "<<<iteration:[200/914] - total_loss: 57.8408  \n",
      "<<<iteration:[220/914] - total_loss: 57.8015  \n",
      "<<<iteration:[240/914] - total_loss: 57.8202  \n",
      "<<<iteration:[260/914] - total_loss: 57.8306  \n",
      "<<<iteration:[280/914] - total_loss: 57.8233  \n",
      "<<<iteration:[300/914] - total_loss: 57.8368  \n",
      "<<<iteration:[320/914] - total_loss: 57.8234  \n",
      "<<<iteration:[340/914] - total_loss: 57.8353  \n",
      "<<<iteration:[360/914] - total_loss: 57.8502  \n",
      "<<<iteration:[380/914] - total_loss: 57.7803  \n",
      "<<<iteration:[400/914] - total_loss: 57.8404  \n",
      "<<<iteration:[420/914] - total_loss: 57.8220  \n",
      "<<<iteration:[440/914] - total_loss: 57.8070  \n",
      "<<<iteration:[460/914] - total_loss: 57.7832  \n",
      "<<<iteration:[480/914] - total_loss: 57.8398  \n",
      "<<<iteration:[500/914] - total_loss: 57.7846  \n",
      "<<<iteration:[520/914] - total_loss: 57.8126  \n",
      "<<<iteration:[540/914] - total_loss: 57.8213  \n",
      "<<<iteration:[560/914] - total_loss: 57.8086  \n",
      "<<<iteration:[580/914] - total_loss: 57.7904  \n",
      "<<<iteration:[600/914] - total_loss: 57.8082  \n",
      "<<<iteration:[620/914] - total_loss: 57.8329  \n",
      "<<<iteration:[640/914] - total_loss: 57.7837  \n",
      "<<<iteration:[660/914] - total_loss: 57.8275  \n",
      "<<<iteration:[680/914] - total_loss: 57.8170  \n",
      "<<<iteration:[700/914] - total_loss: 57.8110  \n",
      "<<<iteration:[720/914] - total_loss: 57.8212  \n",
      "<<<iteration:[740/914] - total_loss: 57.7870  \n",
      "<<<iteration:[760/914] - total_loss: 57.7854  \n",
      "<<<iteration:[780/914] - total_loss: 57.8044  \n",
      "<<<iteration:[800/914] - total_loss: 57.8093  \n",
      "<<<iteration:[820/914] - total_loss: 57.8111  \n",
      "<<<iteration:[840/914] - total_loss: 57.8246  \n",
      "<<<iteration:[860/914] - total_loss: 57.8126  \n",
      "<<<iteration:[880/914] - total_loss: 57.8047  \n",
      "<<<iteration:[900/914] - total_loss: 57.7928  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:2/100 - Train Loss: 57.8198, Val Loss: 57.8046\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.6811  \n",
      "<<<iteration:[40/914] - total_loss: 57.8348  \n",
      "<<<iteration:[60/914] - total_loss: 57.7962  \n",
      "<<<iteration:[80/914] - total_loss: 57.7939  \n",
      "<<<iteration:[100/914] - total_loss: 57.8221  \n",
      "<<<iteration:[120/914] - total_loss: 57.7837  \n",
      "<<<iteration:[140/914] - total_loss: 57.8376  \n",
      "<<<iteration:[160/914] - total_loss: 57.7916  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/914] - total_loss: 57.7762  \n",
      "<<<iteration:[200/914] - total_loss: 57.7988  \n",
      "<<<iteration:[220/914] - total_loss: 57.8119  \n",
      "<<<iteration:[240/914] - total_loss: 57.7827  \n",
      "<<<iteration:[260/914] - total_loss: 57.8015  \n",
      "<<<iteration:[280/914] - total_loss: 57.7999  \n",
      "<<<iteration:[300/914] - total_loss: 57.7760  \n",
      "<<<iteration:[320/914] - total_loss: 57.8007  \n",
      "<<<iteration:[340/914] - total_loss: 57.7976  \n",
      "<<<iteration:[360/914] - total_loss: 57.8064  \n",
      "<<<iteration:[380/914] - total_loss: 57.7915  \n",
      "<<<iteration:[400/914] - total_loss: 57.7457  \n",
      "<<<iteration:[420/914] - total_loss: 57.8057  \n",
      "<<<iteration:[440/914] - total_loss: 57.7898  \n",
      "<<<iteration:[460/914] - total_loss: 57.7872  \n",
      "<<<iteration:[480/914] - total_loss: 57.7954  \n",
      "<<<iteration:[500/914] - total_loss: 57.7791  \n",
      "<<<iteration:[520/914] - total_loss: 57.8017  \n",
      "<<<iteration:[540/914] - total_loss: 57.8032  \n",
      "<<<iteration:[560/914] - total_loss: 57.7928  \n",
      "<<<iteration:[580/914] - total_loss: 57.7704  \n",
      "<<<iteration:[600/914] - total_loss: 57.8102  \n",
      "<<<iteration:[620/914] - total_loss: 57.7847  \n",
      "<<<iteration:[640/914] - total_loss: 57.7712  \n",
      "<<<iteration:[660/914] - total_loss: 57.7637  \n",
      "<<<iteration:[680/914] - total_loss: 57.7604  \n",
      "<<<iteration:[700/914] - total_loss: 57.7923  \n",
      "<<<iteration:[720/914] - total_loss: 57.7707  \n",
      "<<<iteration:[740/914] - total_loss: 57.7606  \n",
      "<<<iteration:[760/914] - total_loss: 57.7296  \n",
      "<<<iteration:[780/914] - total_loss: 57.7938  \n",
      "<<<iteration:[800/914] - total_loss: 57.8199  \n",
      "<<<iteration:[820/914] - total_loss: 57.7776  \n",
      "<<<iteration:[840/914] - total_loss: 57.8119  \n",
      "<<<iteration:[860/914] - total_loss: 57.7678  \n",
      "<<<iteration:[880/914] - total_loss: 57.7914  \n",
      "<<<iteration:[900/914] - total_loss: 57.7840  \n",
      "\n",
      "epoch:3/100 - Train Loss: 57.7900, Val Loss: 57.7871\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.6384  \n",
      "<<<iteration:[40/914] - total_loss: 57.7898  \n",
      "<<<iteration:[60/914] - total_loss: 57.7890  \n",
      "<<<iteration:[80/914] - total_loss: 57.7812  \n",
      "<<<iteration:[100/914] - total_loss: 57.7929  \n",
      "<<<iteration:[120/914] - total_loss: 57.8018  \n",
      "<<<iteration:[140/914] - total_loss: 57.8178  \n",
      "<<<iteration:[160/914] - total_loss: 57.7570  \n",
      "<<<iteration:[180/914] - total_loss: 57.7828  \n",
      "<<<iteration:[200/914] - total_loss: 57.7833  \n",
      "<<<iteration:[220/914] - total_loss: 57.8004  \n",
      "<<<iteration:[240/914] - total_loss: 57.7773  \n",
      "<<<iteration:[260/914] - total_loss: 57.7502  \n",
      "<<<iteration:[280/914] - total_loss: 57.8020  \n",
      "<<<iteration:[300/914] - total_loss: 57.8073  \n",
      "<<<iteration:[320/914] - total_loss: 57.7523  \n",
      "<<<iteration:[340/914] - total_loss: 57.7413  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[360/914] - total_loss: 57.7778  \n",
      "<<<iteration:[380/914] - total_loss: 57.7774  \n",
      "<<<iteration:[400/914] - total_loss: 57.7976  \n",
      "<<<iteration:[420/914] - total_loss: 57.8242  \n",
      "<<<iteration:[440/914] - total_loss: 57.7871  \n",
      "<<<iteration:[460/914] - total_loss: 57.8155  \n",
      "<<<iteration:[480/914] - total_loss: 57.7870  \n",
      "<<<iteration:[500/914] - total_loss: 57.7751  \n",
      "<<<iteration:[520/914] - total_loss: 57.7597  \n",
      "<<<iteration:[540/914] - total_loss: 57.7943  \n",
      "<<<iteration:[560/914] - total_loss: 57.7642  \n",
      "<<<iteration:[580/914] - total_loss: 57.7552  \n",
      "<<<iteration:[600/914] - total_loss: 57.7539  \n",
      "<<<iteration:[620/914] - total_loss: 57.7528  \n",
      "<<<iteration:[640/914] - total_loss: 57.7758  \n",
      "<<<iteration:[660/914] - total_loss: 57.7872  \n",
      "<<<iteration:[680/914] - total_loss: 57.7983  \n",
      "<<<iteration:[700/914] - total_loss: 57.7524  \n",
      "<<<iteration:[720/914] - total_loss: 57.8082  \n",
      "<<<iteration:[740/914] - total_loss: 57.8136  \n",
      "<<<iteration:[760/914] - total_loss: 57.7625  \n",
      "<<<iteration:[780/914] - total_loss: 57.7893  \n",
      "<<<iteration:[800/914] - total_loss: 57.7685  \n",
      "<<<iteration:[820/914] - total_loss: 57.7684  \n",
      "<<<iteration:[840/914] - total_loss: 57.7400  \n",
      "<<<iteration:[860/914] - total_loss: 57.7548  \n",
      "<<<iteration:[880/914] - total_loss: 57.7766  \n",
      "<<<iteration:[900/914] - total_loss: 57.7601  \n",
      "\n",
      "epoch:4/100 - Train Loss: 57.7789, Val Loss: 57.7815\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.6687  \n",
      "<<<iteration:[40/914] - total_loss: 57.7403  \n",
      "<<<iteration:[60/914] - total_loss: 57.7675  \n",
      "<<<iteration:[80/914] - total_loss: 57.7757  \n",
      "<<<iteration:[100/914] - total_loss: 57.7642  \n",
      "<<<iteration:[120/914] - total_loss: 57.7877  \n",
      "<<<iteration:[140/914] - total_loss: 57.7818  \n",
      "<<<iteration:[160/914] - total_loss: 57.7743  \n",
      "<<<iteration:[180/914] - total_loss: 57.7501  \n",
      "<<<iteration:[200/914] - total_loss: 57.7674  \n",
      "<<<iteration:[220/914] - total_loss: 57.7480  \n",
      "<<<iteration:[240/914] - total_loss: 57.7878  \n",
      "<<<iteration:[260/914] - total_loss: 57.7549  \n",
      "<<<iteration:[280/914] - total_loss: 57.7933  \n",
      "<<<iteration:[300/914] - total_loss: 57.7130  \n",
      "<<<iteration:[320/914] - total_loss: 57.7531  \n",
      "<<<iteration:[340/914] - total_loss: 57.7861  \n",
      "<<<iteration:[360/914] - total_loss: 57.7412  \n",
      "<<<iteration:[380/914] - total_loss: 57.7558  \n",
      "<<<iteration:[400/914] - total_loss: 57.7487  \n",
      "<<<iteration:[420/914] - total_loss: 57.7844  \n",
      "<<<iteration:[440/914] - total_loss: 57.7577  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[460/914] - total_loss: 57.7757  \n",
      "<<<iteration:[480/914] - total_loss: 57.7583  \n",
      "<<<iteration:[500/914] - total_loss: 57.8036  \n",
      "<<<iteration:[520/914] - total_loss: 57.7755  \n",
      "<<<iteration:[540/914] - total_loss: 57.7605  \n",
      "<<<iteration:[560/914] - total_loss: 57.8016  \n",
      "<<<iteration:[580/914] - total_loss: 57.7555  \n",
      "<<<iteration:[600/914] - total_loss: 57.7325  \n",
      "<<<iteration:[620/914] - total_loss: 57.7774  \n",
      "<<<iteration:[640/914] - total_loss: 57.7558  \n",
      "<<<iteration:[660/914] - total_loss: 57.7772  \n",
      "<<<iteration:[680/914] - total_loss: 57.7940  \n",
      "<<<iteration:[700/914] - total_loss: 57.7920  \n",
      "<<<iteration:[720/914] - total_loss: 57.7956  \n",
      "<<<iteration:[740/914] - total_loss: 57.8123  \n",
      "<<<iteration:[760/914] - total_loss: 57.7884  \n",
      "<<<iteration:[780/914] - total_loss: 57.7926  \n",
      "<<<iteration:[800/914] - total_loss: 57.7639  \n",
      "<<<iteration:[820/914] - total_loss: 57.7993  \n",
      "<<<iteration:[840/914] - total_loss: 57.7681  \n",
      "<<<iteration:[860/914] - total_loss: 57.7939  \n",
      "<<<iteration:[880/914] - total_loss: 57.8194  \n",
      "<<<iteration:[900/914] - total_loss: 57.7518  \n",
      "\n",
      "epoch:5/100 - Train Loss: 57.7730, Val Loss: 57.7766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/914] - total_loss: 60.6115  \n",
      "<<<iteration:[40/914] - total_loss: 57.7677  \n",
      "<<<iteration:[60/914] - total_loss: 57.7527  \n",
      "<<<iteration:[80/914] - total_loss: 57.7832  \n",
      "<<<iteration:[100/914] - total_loss: 57.7491  \n",
      "<<<iteration:[120/914] - total_loss: 57.8119  \n",
      "<<<iteration:[140/914] - total_loss: 57.7736  \n",
      "<<<iteration:[160/914] - total_loss: 57.7473  \n",
      "<<<iteration:[180/914] - total_loss: 57.7814  \n",
      "<<<iteration:[200/914] - total_loss: 57.7765  \n",
      "<<<iteration:[220/914] - total_loss: 57.7808  \n",
      "<<<iteration:[240/914] - total_loss: 57.7375  \n",
      "<<<iteration:[260/914] - total_loss: 57.7467  \n",
      "<<<iteration:[280/914] - total_loss: 57.7461  \n",
      "<<<iteration:[300/914] - total_loss: 57.7690  \n",
      "<<<iteration:[320/914] - total_loss: 57.7877  \n",
      "<<<iteration:[340/914] - total_loss: 57.7544  \n",
      "<<<iteration:[360/914] - total_loss: 57.7300  \n",
      "<<<iteration:[380/914] - total_loss: 57.7549  \n",
      "<<<iteration:[400/914] - total_loss: 57.7795  \n",
      "<<<iteration:[420/914] - total_loss: 57.7613  \n",
      "<<<iteration:[440/914] - total_loss: 57.7714  \n",
      "<<<iteration:[460/914] - total_loss: 57.7803  \n",
      "<<<iteration:[480/914] - total_loss: 57.7381  \n",
      "<<<iteration:[500/914] - total_loss: 57.7841  \n",
      "<<<iteration:[520/914] - total_loss: 57.7674  \n",
      "<<<iteration:[540/914] - total_loss: 57.7783  \n",
      "<<<iteration:[560/914] - total_loss: 57.7648  \n",
      "<<<iteration:[580/914] - total_loss: 57.8032  \n",
      "<<<iteration:[600/914] - total_loss: 57.8114  \n",
      "<<<iteration:[620/914] - total_loss: 57.7390  \n",
      "<<<iteration:[640/914] - total_loss: 57.7628  \n",
      "<<<iteration:[660/914] - total_loss: 57.7874  \n",
      "<<<iteration:[680/914] - total_loss: 57.7935  \n",
      "<<<iteration:[700/914] - total_loss: 57.7912  \n",
      "<<<iteration:[720/914] - total_loss: 57.7509  \n",
      "<<<iteration:[740/914] - total_loss: 57.7746  \n",
      "<<<iteration:[760/914] - total_loss: 57.7431  \n",
      "<<<iteration:[780/914] - total_loss: 57.7311  \n",
      "<<<iteration:[800/914] - total_loss: 57.7643  \n",
      "<<<iteration:[820/914] - total_loss: 57.7337  \n",
      "<<<iteration:[840/914] - total_loss: 57.7953  \n",
      "<<<iteration:[860/914] - total_loss: 57.7750  \n",
      "<<<iteration:[880/914] - total_loss: 57.7595  \n",
      "<<<iteration:[900/914] - total_loss: 57.7523  \n",
      "\n",
      "epoch:6/100 - Train Loss: 57.7658, Val Loss: 57.7741\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.6984  \n",
      "<<<iteration:[40/914] - total_loss: 57.7730  \n",
      "<<<iteration:[60/914] - total_loss: 57.7444  \n",
      "<<<iteration:[80/914] - total_loss: 57.7412  \n",
      "<<<iteration:[100/914] - total_loss: 57.7450  \n",
      "<<<iteration:[120/914] - total_loss: 57.7230  \n",
      "<<<iteration:[140/914] - total_loss: 57.7934  \n",
      "<<<iteration:[160/914] - total_loss: 57.7432  \n",
      "<<<iteration:[180/914] - total_loss: 57.7586  \n",
      "<<<iteration:[200/914] - total_loss: 57.7533  \n",
      "<<<iteration:[220/914] - total_loss: 57.7483  \n",
      "<<<iteration:[240/914] - total_loss: 57.7239  \n",
      "<<<iteration:[260/914] - total_loss: 57.7203  \n",
      "<<<iteration:[280/914] - total_loss: 57.7717  \n",
      "<<<iteration:[300/914] - total_loss: 57.7535  \n",
      "<<<iteration:[320/914] - total_loss: 57.7375  \n",
      "<<<iteration:[340/914] - total_loss: 57.7813  \n",
      "<<<iteration:[360/914] - total_loss: 57.7248  \n",
      "<<<iteration:[380/914] - total_loss: 57.7499  \n",
      "<<<iteration:[400/914] - total_loss: 57.6996  \n",
      "<<<iteration:[420/914] - total_loss: 57.7733  \n",
      "<<<iteration:[440/914] - total_loss: 57.7594  \n",
      "<<<iteration:[460/914] - total_loss: 57.7247  \n",
      "<<<iteration:[480/914] - total_loss: 57.7286  \n",
      "<<<iteration:[500/914] - total_loss: 57.7569  \n",
      "<<<iteration:[520/914] - total_loss: 57.7789  \n",
      "<<<iteration:[540/914] - total_loss: 57.7449  \n",
      "<<<iteration:[560/914] - total_loss: 57.7315  \n",
      "<<<iteration:[580/914] - total_loss: 57.7179  \n",
      "<<<iteration:[600/914] - total_loss: 57.7650  \n",
      "<<<iteration:[620/914] - total_loss: 57.7288  \n",
      "<<<iteration:[640/914] - total_loss: 57.7667  \n",
      "<<<iteration:[660/914] - total_loss: 57.7452  \n",
      "<<<iteration:[680/914] - total_loss: 57.7878  \n",
      "<<<iteration:[700/914] - total_loss: 57.7286  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[720/914] - total_loss: 57.7601  \n",
      "<<<iteration:[740/914] - total_loss: 57.7804  \n",
      "<<<iteration:[760/914] - total_loss: 57.7386  \n",
      "<<<iteration:[780/914] - total_loss: 57.7892  \n",
      "<<<iteration:[800/914] - total_loss: 57.7700  \n",
      "<<<iteration:[820/914] - total_loss: 57.7676  \n",
      "<<<iteration:[840/914] - total_loss: 57.7343  \n",
      "<<<iteration:[860/914] - total_loss: 57.7081  \n",
      "<<<iteration:[880/914] - total_loss: 57.7386  \n",
      "<<<iteration:[900/914] - total_loss: 57.7514  \n",
      "\n",
      "epoch:7/100 - Train Loss: 57.7513, Val Loss: 57.7702\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.6004  \n",
      "<<<iteration:[40/914] - total_loss: 57.7647  \n",
      "<<<iteration:[60/914] - total_loss: 57.7335  \n",
      "<<<iteration:[80/914] - total_loss: 57.7204  \n",
      "<<<iteration:[100/914] - total_loss: 57.7337  \n",
      "<<<iteration:[120/914] - total_loss: 57.7635  \n",
      "<<<iteration:[140/914] - total_loss: 57.7037  \n",
      "<<<iteration:[160/914] - total_loss: 57.7323  \n",
      "<<<iteration:[180/914] - total_loss: 57.7414  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/914] - total_loss: 57.7056  \n",
      "<<<iteration:[220/914] - total_loss: 57.7098  \n",
      "<<<iteration:[240/914] - total_loss: 57.7538  \n",
      "<<<iteration:[260/914] - total_loss: 57.6941  \n",
      "<<<iteration:[280/914] - total_loss: 57.7379  \n",
      "<<<iteration:[300/914] - total_loss: 57.7206  \n",
      "<<<iteration:[320/914] - total_loss: 57.7284  \n",
      "<<<iteration:[340/914] - total_loss: 57.6849  \n",
      "<<<iteration:[360/914] - total_loss: 57.7224  \n",
      "<<<iteration:[380/914] - total_loss: 57.7116  \n",
      "<<<iteration:[400/914] - total_loss: 57.6738  \n",
      "<<<iteration:[420/914] - total_loss: 57.7350  \n",
      "<<<iteration:[440/914] - total_loss: 57.6953  \n",
      "<<<iteration:[460/914] - total_loss: 57.6898  \n",
      "<<<iteration:[480/914] - total_loss: 57.6919  \n",
      "<<<iteration:[500/914] - total_loss: 57.7470  \n",
      "<<<iteration:[520/914] - total_loss: 57.7575  \n",
      "<<<iteration:[540/914] - total_loss: 57.7065  \n",
      "<<<iteration:[560/914] - total_loss: 57.6966  \n",
      "<<<iteration:[580/914] - total_loss: 57.7052  \n",
      "<<<iteration:[600/914] - total_loss: 57.7140  \n",
      "<<<iteration:[620/914] - total_loss: 57.6906  \n",
      "<<<iteration:[640/914] - total_loss: 57.7488  \n",
      "<<<iteration:[660/914] - total_loss: 57.6690  \n",
      "<<<iteration:[680/914] - total_loss: 57.7187  \n",
      "<<<iteration:[700/914] - total_loss: 57.6816  \n",
      "<<<iteration:[720/914] - total_loss: 57.6874  \n",
      "<<<iteration:[740/914] - total_loss: 57.6961  \n",
      "<<<iteration:[760/914] - total_loss: 57.7058  \n",
      "<<<iteration:[780/914] - total_loss: 57.7068  \n",
      "<<<iteration:[800/914] - total_loss: 57.7247  \n",
      "<<<iteration:[820/914] - total_loss: 57.6974  \n",
      "<<<iteration:[840/914] - total_loss: 57.6926  \n",
      "<<<iteration:[860/914] - total_loss: 57.7204  \n",
      "<<<iteration:[880/914] - total_loss: 57.7087  \n",
      "<<<iteration:[900/914] - total_loss: 57.6987  \n",
      "\n",
      "epoch:8/100 - Train Loss: 57.7136, Val Loss: 57.7667\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.5475  \n",
      "<<<iteration:[40/914] - total_loss: 57.6431  \n",
      "<<<iteration:[60/914] - total_loss: 57.6773  \n",
      "<<<iteration:[80/914] - total_loss: 57.6574  \n",
      "<<<iteration:[100/914] - total_loss: 57.6630  \n",
      "<<<iteration:[120/914] - total_loss: 57.5895  \n",
      "<<<iteration:[140/914] - total_loss: 57.6072  \n",
      "<<<iteration:[160/914] - total_loss: 57.6841  \n",
      "<<<iteration:[180/914] - total_loss: 57.6179  \n",
      "<<<iteration:[200/914] - total_loss: 57.5925  \n",
      "<<<iteration:[220/914] - total_loss: 57.6025  \n",
      "<<<iteration:[240/914] - total_loss: 57.6277  \n",
      "<<<iteration:[260/914] - total_loss: 57.6588  \n",
      "<<<iteration:[280/914] - total_loss: 57.7125  \n",
      "<<<iteration:[300/914] - total_loss: 57.6587  \n",
      "<<<iteration:[320/914] - total_loss: 57.6376  \n",
      "<<<iteration:[340/914] - total_loss: 57.6418  \n",
      "<<<iteration:[360/914] - total_loss: 57.6165  \n",
      "<<<iteration:[380/914] - total_loss: 57.6319  \n",
      "<<<iteration:[400/914] - total_loss: 57.6761  \n",
      "<<<iteration:[420/914] - total_loss: 57.6648  \n",
      "<<<iteration:[440/914] - total_loss: 57.6217  \n",
      "<<<iteration:[460/914] - total_loss: 57.5985  \n",
      "<<<iteration:[480/914] - total_loss: 57.5967  \n",
      "<<<iteration:[500/914] - total_loss: 57.6246  \n",
      "<<<iteration:[520/914] - total_loss: 57.6610  \n",
      "<<<iteration:[540/914] - total_loss: 57.6349  \n",
      "<<<iteration:[560/914] - total_loss: 57.6862  \n",
      "<<<iteration:[580/914] - total_loss: 57.6335  \n",
      "<<<iteration:[600/914] - total_loss: 57.6417  \n",
      "<<<iteration:[620/914] - total_loss: 57.6882  \n",
      "<<<iteration:[640/914] - total_loss: 57.6180  \n",
      "<<<iteration:[660/914] - total_loss: 57.6289  \n",
      "<<<iteration:[680/914] - total_loss: 57.6317  \n",
      "<<<iteration:[700/914] - total_loss: 57.6348  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[720/914] - total_loss: 57.6537  \n",
      "<<<iteration:[740/914] - total_loss: 57.6361  \n",
      "<<<iteration:[760/914] - total_loss: 57.6240  \n",
      "<<<iteration:[780/914] - total_loss: 57.6457  \n",
      "<<<iteration:[800/914] - total_loss: 57.5884  \n",
      "<<<iteration:[820/914] - total_loss: 57.6132  \n",
      "<<<iteration:[840/914] - total_loss: 57.6673  \n",
      "<<<iteration:[860/914] - total_loss: 57.6823  \n",
      "<<<iteration:[880/914] - total_loss: 57.6579  \n",
      "<<<iteration:[900/914] - total_loss: 57.6413  \n",
      "\n",
      "epoch:9/100 - Train Loss: 57.6413, Val Loss: 57.7590\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.4346  \n",
      "<<<iteration:[40/914] - total_loss: 57.5327  \n",
      "<<<iteration:[60/914] - total_loss: 57.5743  \n",
      "<<<iteration:[80/914] - total_loss: 57.5418  \n",
      "<<<iteration:[100/914] - total_loss: 57.5367  \n",
      "<<<iteration:[120/914] - total_loss: 57.5382  \n",
      "<<<iteration:[140/914] - total_loss: 57.5571  \n",
      "<<<iteration:[160/914] - total_loss: 57.5750  \n",
      "<<<iteration:[180/914] - total_loss: 57.5678  \n",
      "<<<iteration:[200/914] - total_loss: 57.5456  \n",
      "<<<iteration:[220/914] - total_loss: 57.5799  \n",
      "<<<iteration:[240/914] - total_loss: 57.5362  \n",
      "<<<iteration:[260/914] - total_loss: 57.5090  \n",
      "<<<iteration:[280/914] - total_loss: 57.5482  \n",
      "<<<iteration:[300/914] - total_loss: 57.5118  \n",
      "<<<iteration:[320/914] - total_loss: 57.5348  \n",
      "<<<iteration:[340/914] - total_loss: 57.5548  \n",
      "<<<iteration:[360/914] - total_loss: 57.5808  \n",
      "<<<iteration:[380/914] - total_loss: 57.5345  \n",
      "<<<iteration:[400/914] - total_loss: 57.5812  \n",
      "<<<iteration:[420/914] - total_loss: 57.5025  \n",
      "<<<iteration:[440/914] - total_loss: 57.5508  \n",
      "<<<iteration:[460/914] - total_loss: 57.5242  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/914] - total_loss: 57.5034  \n",
      "<<<iteration:[500/914] - total_loss: 57.5857  \n",
      "<<<iteration:[520/914] - total_loss: 57.5454  \n",
      "<<<iteration:[540/914] - total_loss: 57.5285  \n",
      "<<<iteration:[560/914] - total_loss: 57.5390  \n",
      "<<<iteration:[580/914] - total_loss: 57.5357  \n",
      "<<<iteration:[600/914] - total_loss: 57.4900  \n",
      "<<<iteration:[620/914] - total_loss: 57.5336  \n",
      "<<<iteration:[640/914] - total_loss: 57.5648  \n",
      "<<<iteration:[660/914] - total_loss: 57.5733  \n",
      "<<<iteration:[680/914] - total_loss: 57.5688  \n",
      "<<<iteration:[700/914] - total_loss: 57.5679  \n",
      "<<<iteration:[720/914] - total_loss: 57.5659  \n",
      "<<<iteration:[740/914] - total_loss: 57.5474  \n",
      "<<<iteration:[760/914] - total_loss: 57.5303  \n",
      "<<<iteration:[780/914] - total_loss: 57.6007  \n",
      "<<<iteration:[800/914] - total_loss: 57.5728  \n",
      "<<<iteration:[820/914] - total_loss: 57.5337  \n",
      "<<<iteration:[840/914] - total_loss: 57.5138  \n",
      "<<<iteration:[860/914] - total_loss: 57.4938  \n",
      "<<<iteration:[880/914] - total_loss: 57.5094  \n",
      "<<<iteration:[900/914] - total_loss: 57.5140  \n",
      "\n",
      "epoch:10/100 - Train Loss: 57.5445, Val Loss: 57.7446\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.2899  \n",
      "<<<iteration:[40/914] - total_loss: 57.4380  \n",
      "<<<iteration:[60/914] - total_loss: 57.4195  \n",
      "<<<iteration:[80/914] - total_loss: 57.4491  \n",
      "<<<iteration:[100/914] - total_loss: 57.4120  \n",
      "<<<iteration:[120/914] - total_loss: 57.4482  \n",
      "<<<iteration:[140/914] - total_loss: 57.4118  \n",
      "<<<iteration:[160/914] - total_loss: 57.4431  \n",
      "<<<iteration:[180/914] - total_loss: 57.4167  \n",
      "<<<iteration:[200/914] - total_loss: 57.4564  \n",
      "<<<iteration:[220/914] - total_loss: 57.4158  \n",
      "<<<iteration:[240/914] - total_loss: 57.5021  \n",
      "<<<iteration:[260/914] - total_loss: 57.4082  \n",
      "<<<iteration:[280/914] - total_loss: 57.4614  \n",
      "<<<iteration:[300/914] - total_loss: 57.4973  \n",
      "<<<iteration:[320/914] - total_loss: 57.4601  \n",
      "<<<iteration:[340/914] - total_loss: 57.4052  \n",
      "<<<iteration:[360/914] - total_loss: 57.4415  \n",
      "<<<iteration:[380/914] - total_loss: 57.4491  \n",
      "<<<iteration:[400/914] - total_loss: 57.4512  \n",
      "<<<iteration:[420/914] - total_loss: 57.4811  \n",
      "<<<iteration:[440/914] - total_loss: 57.4308  \n",
      "<<<iteration:[460/914] - total_loss: 57.3666  \n",
      "<<<iteration:[480/914] - total_loss: 57.4671  \n",
      "<<<iteration:[500/914] - total_loss: 57.4137  \n",
      "<<<iteration:[520/914] - total_loss: 57.4140  \n",
      "<<<iteration:[540/914] - total_loss: 57.4200  \n",
      "<<<iteration:[560/914] - total_loss: 57.4244  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[580/914] - total_loss: 57.3951  \n",
      "<<<iteration:[600/914] - total_loss: 57.4213  \n",
      "<<<iteration:[620/914] - total_loss: 57.3916  \n",
      "<<<iteration:[640/914] - total_loss: 57.4268  \n",
      "<<<iteration:[660/914] - total_loss: 57.4248  \n",
      "<<<iteration:[680/914] - total_loss: 57.3897  \n",
      "<<<iteration:[700/914] - total_loss: 57.4409  \n",
      "<<<iteration:[720/914] - total_loss: 57.4090  \n",
      "<<<iteration:[740/914] - total_loss: 57.3971  \n",
      "<<<iteration:[760/914] - total_loss: 57.3740  \n",
      "<<<iteration:[780/914] - total_loss: 57.3640  \n",
      "<<<iteration:[800/914] - total_loss: 57.3414  \n",
      "<<<iteration:[820/914] - total_loss: 57.3663  \n",
      "<<<iteration:[840/914] - total_loss: 57.4623  \n",
      "<<<iteration:[860/914] - total_loss: 57.4064  \n",
      "<<<iteration:[880/914] - total_loss: 57.3403  \n",
      "<<<iteration:[900/914] - total_loss: 57.4242  \n",
      "\n",
      "epoch:11/100 - Train Loss: 57.4219, Val Loss: 57.7482\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 60.1735  \n",
      "<<<iteration:[40/914] - total_loss: 57.2612  \n",
      "<<<iteration:[60/914] - total_loss: 57.3166  \n",
      "<<<iteration:[80/914] - total_loss: 57.2987  \n",
      "<<<iteration:[100/914] - total_loss: 57.3204  \n",
      "<<<iteration:[120/914] - total_loss: 57.3123  \n",
      "<<<iteration:[140/914] - total_loss: 57.2904  \n",
      "<<<iteration:[160/914] - total_loss: 57.2637  \n",
      "<<<iteration:[180/914] - total_loss: 57.2729  \n",
      "<<<iteration:[200/914] - total_loss: 57.2723  \n",
      "<<<iteration:[220/914] - total_loss: 57.2999  \n",
      "<<<iteration:[240/914] - total_loss: 57.2221  \n",
      "<<<iteration:[260/914] - total_loss: 57.2528  \n",
      "<<<iteration:[280/914] - total_loss: 57.2577  \n",
      "<<<iteration:[300/914] - total_loss: 57.2659  \n",
      "<<<iteration:[320/914] - total_loss: 57.3034  \n",
      "<<<iteration:[340/914] - total_loss: 57.3120  \n",
      "<<<iteration:[360/914] - total_loss: 57.2968  \n",
      "<<<iteration:[380/914] - total_loss: 57.3070  \n",
      "<<<iteration:[400/914] - total_loss: 57.2935  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[420/914] - total_loss: 57.3049  \n",
      "<<<iteration:[440/914] - total_loss: 57.2754  \n",
      "<<<iteration:[460/914] - total_loss: 57.2828  \n",
      "<<<iteration:[480/914] - total_loss: 57.2906  \n",
      "<<<iteration:[500/914] - total_loss: 57.2704  \n",
      "<<<iteration:[520/914] - total_loss: 57.2950  \n",
      "<<<iteration:[540/914] - total_loss: 57.2282  \n",
      "<<<iteration:[560/914] - total_loss: 57.2675  \n",
      "<<<iteration:[580/914] - total_loss: 57.2824  \n",
      "<<<iteration:[600/914] - total_loss: 57.3063  \n",
      "<<<iteration:[620/914] - total_loss: 57.2760  \n",
      "<<<iteration:[640/914] - total_loss: 57.2688  \n",
      "<<<iteration:[660/914] - total_loss: 57.2617  \n",
      "<<<iteration:[680/914] - total_loss: 57.2027  \n",
      "<<<iteration:[700/914] - total_loss: 57.2473  \n",
      "<<<iteration:[720/914] - total_loss: 57.3009  \n",
      "<<<iteration:[740/914] - total_loss: 57.2841  \n",
      "<<<iteration:[760/914] - total_loss: 57.2002  \n",
      "<<<iteration:[780/914] - total_loss: 57.2755  \n",
      "<<<iteration:[800/914] - total_loss: 57.3143  \n",
      "<<<iteration:[820/914] - total_loss: 57.2523  \n",
      "<<<iteration:[840/914] - total_loss: 57.2595  \n",
      "<<<iteration:[860/914] - total_loss: 57.2643  \n",
      "<<<iteration:[880/914] - total_loss: 57.2444  \n",
      "<<<iteration:[900/914] - total_loss: 57.2990  \n",
      "\n",
      "epoch:12/100 - Train Loss: 57.2768, Val Loss: 57.7443\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.9975  \n",
      "<<<iteration:[40/914] - total_loss: 57.1464  \n",
      "<<<iteration:[60/914] - total_loss: 57.1195  \n",
      "<<<iteration:[80/914] - total_loss: 57.0808  \n",
      "<<<iteration:[100/914] - total_loss: 57.0945  \n",
      "<<<iteration:[120/914] - total_loss: 57.1285  \n",
      "<<<iteration:[140/914] - total_loss: 57.0982  \n",
      "<<<iteration:[160/914] - total_loss: 57.1478  \n",
      "<<<iteration:[180/914] - total_loss: 57.1517  \n",
      "<<<iteration:[200/914] - total_loss: 57.1564  \n",
      "<<<iteration:[220/914] - total_loss: 57.1022  \n",
      "<<<iteration:[240/914] - total_loss: 57.1404  \n",
      "<<<iteration:[260/914] - total_loss: 57.1754  \n",
      "<<<iteration:[280/914] - total_loss: 57.1479  \n",
      "<<<iteration:[300/914] - total_loss: 57.0769  \n",
      "<<<iteration:[320/914] - total_loss: 57.1805  \n",
      "<<<iteration:[340/914] - total_loss: 57.1005  \n",
      "<<<iteration:[360/914] - total_loss: 57.1331  \n",
      "<<<iteration:[380/914] - total_loss: 57.0939  \n",
      "<<<iteration:[400/914] - total_loss: 57.0462  \n",
      "<<<iteration:[420/914] - total_loss: 57.0628  \n",
      "<<<iteration:[440/914] - total_loss: 57.1291  \n",
      "<<<iteration:[460/914] - total_loss: 57.1495  \n",
      "<<<iteration:[480/914] - total_loss: 57.1227  \n",
      "<<<iteration:[500/914] - total_loss: 57.0883  \n",
      "<<<iteration:[520/914] - total_loss: 57.1170  \n",
      "<<<iteration:[540/914] - total_loss: 57.0664  \n",
      "<<<iteration:[560/914] - total_loss: 57.1356  \n",
      "<<<iteration:[580/914] - total_loss: 57.0345  \n",
      "<<<iteration:[600/914] - total_loss: 57.1138  \n",
      "<<<iteration:[620/914] - total_loss: 57.0958  \n",
      "<<<iteration:[640/914] - total_loss: 57.0951  \n",
      "<<<iteration:[660/914] - total_loss: 57.1249  \n",
      "<<<iteration:[680/914] - total_loss: 57.1845  \n",
      "<<<iteration:[700/914] - total_loss: 57.2128  \n",
      "<<<iteration:[720/914] - total_loss: 57.1184  \n",
      "<<<iteration:[740/914] - total_loss: 57.0362  \n",
      "<<<iteration:[760/914] - total_loss: 57.1193  \n",
      "<<<iteration:[780/914] - total_loss: 57.1032  \n",
      "<<<iteration:[800/914] - total_loss: 57.0731  \n",
      "<<<iteration:[820/914] - total_loss: 57.1099  \n",
      "<<<iteration:[840/914] - total_loss: 57.0708  \n",
      "<<<iteration:[860/914] - total_loss: 57.0925  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[880/914] - total_loss: 57.1289  \n",
      "<<<iteration:[900/914] - total_loss: 57.1015  \n",
      "\n",
      "epoch:13/100 - Train Loss: 57.1139, Val Loss: 57.7421\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.8806  \n",
      "<<<iteration:[40/914] - total_loss: 57.0267  \n",
      "<<<iteration:[60/914] - total_loss: 56.9016  \n",
      "<<<iteration:[80/914] - total_loss: 56.9058  \n",
      "<<<iteration:[100/914] - total_loss: 56.9414  \n",
      "<<<iteration:[120/914] - total_loss: 56.9584  \n",
      "<<<iteration:[140/914] - total_loss: 56.9699  \n",
      "<<<iteration:[160/914] - total_loss: 56.9354  \n",
      "<<<iteration:[180/914] - total_loss: 56.9411  \n",
      "<<<iteration:[200/914] - total_loss: 56.9136  \n",
      "<<<iteration:[220/914] - total_loss: 56.9730  \n",
      "<<<iteration:[240/914] - total_loss: 56.9376  \n",
      "<<<iteration:[260/914] - total_loss: 56.9276  \n",
      "<<<iteration:[280/914] - total_loss: 56.9384  \n",
      "<<<iteration:[300/914] - total_loss: 56.9968  \n",
      "<<<iteration:[320/914] - total_loss: 56.9301  \n",
      "<<<iteration:[340/914] - total_loss: 56.9473  \n",
      "<<<iteration:[360/914] - total_loss: 56.9513  \n",
      "<<<iteration:[380/914] - total_loss: 56.9150  \n",
      "<<<iteration:[400/914] - total_loss: 56.9521  \n",
      "<<<iteration:[420/914] - total_loss: 57.0107  \n",
      "<<<iteration:[440/914] - total_loss: 56.9073  \n",
      "<<<iteration:[460/914] - total_loss: 56.9766  \n",
      "<<<iteration:[480/914] - total_loss: 56.9400  \n",
      "<<<iteration:[500/914] - total_loss: 56.8740  \n",
      "<<<iteration:[520/914] - total_loss: 56.9873  \n",
      "<<<iteration:[540/914] - total_loss: 56.9295  \n",
      "<<<iteration:[560/914] - total_loss: 56.9140  \n",
      "<<<iteration:[580/914] - total_loss: 56.9476  \n",
      "<<<iteration:[600/914] - total_loss: 56.9937  \n",
      "<<<iteration:[620/914] - total_loss: 56.9546  \n",
      "<<<iteration:[640/914] - total_loss: 56.9455  \n",
      "<<<iteration:[660/914] - total_loss: 56.9488  \n",
      "<<<iteration:[680/914] - total_loss: 56.9423  \n",
      "<<<iteration:[700/914] - total_loss: 56.9021  \n",
      "<<<iteration:[720/914] - total_loss: 56.9144  \n",
      "<<<iteration:[740/914] - total_loss: 57.0107  \n",
      "<<<iteration:[760/914] - total_loss: 56.9411  \n",
      "<<<iteration:[780/914] - total_loss: 56.9695  \n",
      "<<<iteration:[800/914] - total_loss: 56.9524  \n",
      "<<<iteration:[820/914] - total_loss: 56.9568  \n",
      "<<<iteration:[840/914] - total_loss: 57.0346  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[860/914] - total_loss: 56.8794  \n",
      "<<<iteration:[880/914] - total_loss: 56.9593  \n",
      "<<<iteration:[900/914] - total_loss: 56.9088  \n",
      "\n",
      "epoch:14/100 - Train Loss: 56.9503, Val Loss: 57.7405\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.6936  \n",
      "<<<iteration:[40/914] - total_loss: 56.8254  \n",
      "<<<iteration:[60/914] - total_loss: 56.8415  \n",
      "<<<iteration:[80/914] - total_loss: 56.7641  \n",
      "<<<iteration:[100/914] - total_loss: 56.8406  \n",
      "<<<iteration:[120/914] - total_loss: 56.7945  \n",
      "<<<iteration:[140/914] - total_loss: 56.8396  \n",
      "<<<iteration:[160/914] - total_loss: 56.7798  \n",
      "<<<iteration:[180/914] - total_loss: 56.8066  \n",
      "<<<iteration:[200/914] - total_loss: 56.8304  \n",
      "<<<iteration:[220/914] - total_loss: 56.8176  \n",
      "<<<iteration:[240/914] - total_loss: 56.7643  \n",
      "<<<iteration:[260/914] - total_loss: 56.7064  \n",
      "<<<iteration:[280/914] - total_loss: 56.7422  \n",
      "<<<iteration:[300/914] - total_loss: 56.8224  \n",
      "<<<iteration:[320/914] - total_loss: 56.7876  \n",
      "<<<iteration:[340/914] - total_loss: 56.7660  \n",
      "<<<iteration:[360/914] - total_loss: 56.7991  \n",
      "<<<iteration:[380/914] - total_loss: 56.8305  \n",
      "<<<iteration:[400/914] - total_loss: 56.8518  \n",
      "<<<iteration:[420/914] - total_loss: 56.7877  \n",
      "<<<iteration:[440/914] - total_loss: 56.7554  \n",
      "<<<iteration:[460/914] - total_loss: 56.7883  \n",
      "<<<iteration:[480/914] - total_loss: 56.8167  \n",
      "<<<iteration:[500/914] - total_loss: 56.7772  \n",
      "<<<iteration:[520/914] - total_loss: 56.7877  \n",
      "<<<iteration:[540/914] - total_loss: 56.8076  \n",
      "<<<iteration:[560/914] - total_loss: 56.7588  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[580/914] - total_loss: 56.8196  \n",
      "<<<iteration:[600/914] - total_loss: 56.7153  \n",
      "<<<iteration:[620/914] - total_loss: 56.7658  \n",
      "<<<iteration:[640/914] - total_loss: 56.7283  \n",
      "<<<iteration:[660/914] - total_loss: 56.7897  \n",
      "<<<iteration:[680/914] - total_loss: 56.7897  \n",
      "<<<iteration:[700/914] - total_loss: 56.7528  \n",
      "<<<iteration:[720/914] - total_loss: 56.7973  \n",
      "<<<iteration:[740/914] - total_loss: 56.7757  \n",
      "<<<iteration:[760/914] - total_loss: 56.7571  \n",
      "<<<iteration:[780/914] - total_loss: 56.7548  \n",
      "<<<iteration:[800/914] - total_loss: 56.7193  \n",
      "<<<iteration:[820/914] - total_loss: 56.7415  \n",
      "<<<iteration:[840/914] - total_loss: 56.7718  \n",
      "<<<iteration:[860/914] - total_loss: 56.7957  \n",
      "<<<iteration:[880/914] - total_loss: 56.7790  \n",
      "<<<iteration:[900/914] - total_loss: 56.8303  \n",
      "\n",
      "epoch:15/100 - Train Loss: 56.7878, Val Loss: 57.7430\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.4426  \n",
      "<<<iteration:[40/914] - total_loss: 56.6786  \n",
      "<<<iteration:[60/914] - total_loss: 56.6111  \n",
      "<<<iteration:[80/914] - total_loss: 56.5797  \n",
      "<<<iteration:[100/914] - total_loss: 56.5671  \n",
      "<<<iteration:[120/914] - total_loss: 56.5862  \n",
      "<<<iteration:[140/914] - total_loss: 56.5935  \n",
      "<<<iteration:[160/914] - total_loss: 56.6004  \n",
      "<<<iteration:[180/914] - total_loss: 56.6594  \n",
      "<<<iteration:[200/914] - total_loss: 56.6541  \n",
      "<<<iteration:[220/914] - total_loss: 56.6625  \n",
      "<<<iteration:[240/914] - total_loss: 56.6528  \n",
      "<<<iteration:[260/914] - total_loss: 56.5561  \n",
      "<<<iteration:[280/914] - total_loss: 56.6361  \n",
      "<<<iteration:[300/914] - total_loss: 56.7103  \n",
      "<<<iteration:[320/914] - total_loss: 56.6352  \n",
      "<<<iteration:[340/914] - total_loss: 56.6045  \n",
      "<<<iteration:[360/914] - total_loss: 56.5887  \n",
      "<<<iteration:[380/914] - total_loss: 56.5630  \n",
      "<<<iteration:[400/914] - total_loss: 56.6946  \n",
      "<<<iteration:[420/914] - total_loss: 56.6209  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[440/914] - total_loss: 56.6091  \n",
      "<<<iteration:[460/914] - total_loss: 56.5555  \n",
      "<<<iteration:[480/914] - total_loss: 56.6259  \n",
      "<<<iteration:[500/914] - total_loss: 56.6098  \n",
      "<<<iteration:[520/914] - total_loss: 56.6436  \n",
      "<<<iteration:[540/914] - total_loss: 56.6548  \n",
      "<<<iteration:[560/914] - total_loss: 56.5847  \n",
      "<<<iteration:[580/914] - total_loss: 56.6290  \n",
      "<<<iteration:[600/914] - total_loss: 56.6276  \n",
      "<<<iteration:[620/914] - total_loss: 56.5995  \n",
      "<<<iteration:[640/914] - total_loss: 56.6750  \n",
      "<<<iteration:[660/914] - total_loss: 56.6156  \n",
      "<<<iteration:[680/914] - total_loss: 56.6519  \n",
      "<<<iteration:[700/914] - total_loss: 56.6656  \n",
      "<<<iteration:[720/914] - total_loss: 56.6097  \n",
      "<<<iteration:[740/914] - total_loss: 56.6646  \n",
      "<<<iteration:[760/914] - total_loss: 56.6766  \n",
      "<<<iteration:[780/914] - total_loss: 56.6127  \n",
      "<<<iteration:[800/914] - total_loss: 56.6163  \n",
      "<<<iteration:[820/914] - total_loss: 56.6253  \n",
      "<<<iteration:[840/914] - total_loss: 56.6634  \n",
      "<<<iteration:[860/914] - total_loss: 56.6365  \n",
      "<<<iteration:[880/914] - total_loss: 56.5575  \n",
      "<<<iteration:[900/914] - total_loss: 56.6397  \n",
      "\n",
      "epoch:16/100 - Train Loss: 56.6250, Val Loss: 57.7382\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.3248  \n",
      "<<<iteration:[40/914] - total_loss: 56.4548  \n",
      "<<<iteration:[60/914] - total_loss: 56.4611  \n",
      "<<<iteration:[80/914] - total_loss: 56.4858  \n",
      "<<<iteration:[100/914] - total_loss: 56.4851  \n",
      "<<<iteration:[120/914] - total_loss: 56.3883  \n",
      "<<<iteration:[140/914] - total_loss: 56.4650  \n",
      "<<<iteration:[160/914] - total_loss: 56.4830  \n",
      "<<<iteration:[180/914] - total_loss: 56.4460  \n",
      "<<<iteration:[200/914] - total_loss: 56.5032  \n",
      "<<<iteration:[220/914] - total_loss: 56.4246  \n",
      "<<<iteration:[240/914] - total_loss: 56.5257  \n",
      "<<<iteration:[260/914] - total_loss: 56.4330  \n",
      "<<<iteration:[280/914] - total_loss: 56.4929  \n",
      "<<<iteration:[300/914] - total_loss: 56.4805  \n",
      "<<<iteration:[320/914] - total_loss: 56.4768  \n",
      "<<<iteration:[340/914] - total_loss: 56.4973  \n",
      "<<<iteration:[360/914] - total_loss: 56.4526  \n",
      "<<<iteration:[380/914] - total_loss: 56.4494  \n",
      "<<<iteration:[400/914] - total_loss: 56.4729  \n",
      "<<<iteration:[420/914] - total_loss: 56.4763  \n",
      "<<<iteration:[440/914] - total_loss: 56.4813  \n",
      "<<<iteration:[460/914] - total_loss: 56.4690  \n",
      "<<<iteration:[480/914] - total_loss: 56.4513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/914] - total_loss: 56.4934  \n",
      "<<<iteration:[520/914] - total_loss: 56.5030  \n",
      "<<<iteration:[540/914] - total_loss: 56.5011  \n",
      "<<<iteration:[560/914] - total_loss: 56.4405  \n",
      "<<<iteration:[580/914] - total_loss: 56.4646  \n",
      "<<<iteration:[600/914] - total_loss: 56.5018  \n",
      "<<<iteration:[620/914] - total_loss: 56.4603  \n",
      "<<<iteration:[640/914] - total_loss: 56.4978  \n",
      "<<<iteration:[660/914] - total_loss: 56.5740  \n",
      "<<<iteration:[680/914] - total_loss: 56.4658  \n",
      "<<<iteration:[700/914] - total_loss: 56.4482  \n",
      "<<<iteration:[720/914] - total_loss: 56.5061  \n",
      "<<<iteration:[740/914] - total_loss: 56.4576  \n",
      "<<<iteration:[760/914] - total_loss: 56.4592  \n",
      "<<<iteration:[780/914] - total_loss: 56.4554  \n",
      "<<<iteration:[800/914] - total_loss: 56.4574  \n",
      "<<<iteration:[820/914] - total_loss: 56.5273  \n",
      "<<<iteration:[840/914] - total_loss: 56.4818  \n",
      "<<<iteration:[860/914] - total_loss: 56.4397  \n",
      "<<<iteration:[880/914] - total_loss: 56.4850  \n",
      "<<<iteration:[900/914] - total_loss: 56.4801  \n",
      "\n",
      "epoch:17/100 - Train Loss: 56.4749, Val Loss: 57.7329\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.1947  \n",
      "<<<iteration:[40/914] - total_loss: 56.3823  \n",
      "<<<iteration:[60/914] - total_loss: 56.2929  \n",
      "<<<iteration:[80/914] - total_loss: 56.3429  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/914] - total_loss: 56.2736  \n",
      "<<<iteration:[120/914] - total_loss: 56.3498  \n",
      "<<<iteration:[140/914] - total_loss: 56.3286  \n",
      "<<<iteration:[160/914] - total_loss: 56.3767  \n",
      "<<<iteration:[180/914] - total_loss: 56.3104  \n",
      "<<<iteration:[200/914] - total_loss: 56.3653  \n",
      "<<<iteration:[220/914] - total_loss: 56.3097  \n",
      "<<<iteration:[240/914] - total_loss: 56.3787  \n",
      "<<<iteration:[260/914] - total_loss: 56.3424  \n",
      "<<<iteration:[280/914] - total_loss: 56.3105  \n",
      "<<<iteration:[300/914] - total_loss: 56.3205  \n",
      "<<<iteration:[320/914] - total_loss: 56.2933  \n",
      "<<<iteration:[340/914] - total_loss: 56.3504  \n",
      "<<<iteration:[360/914] - total_loss: 56.3300  \n",
      "<<<iteration:[380/914] - total_loss: 56.3539  \n",
      "<<<iteration:[400/914] - total_loss: 56.3700  \n",
      "<<<iteration:[420/914] - total_loss: 56.3518  \n",
      "<<<iteration:[440/914] - total_loss: 56.2927  \n",
      "<<<iteration:[460/914] - total_loss: 56.3384  \n",
      "<<<iteration:[480/914] - total_loss: 56.3504  \n",
      "<<<iteration:[500/914] - total_loss: 56.3515  \n",
      "<<<iteration:[520/914] - total_loss: 56.3643  \n",
      "<<<iteration:[540/914] - total_loss: 56.3225  \n",
      "<<<iteration:[560/914] - total_loss: 56.3409  \n",
      "<<<iteration:[580/914] - total_loss: 56.3491  \n",
      "<<<iteration:[600/914] - total_loss: 56.3388  \n",
      "<<<iteration:[620/914] - total_loss: 56.2591  \n",
      "<<<iteration:[640/914] - total_loss: 56.3475  \n",
      "<<<iteration:[660/914] - total_loss: 56.3988  \n",
      "<<<iteration:[680/914] - total_loss: 56.3048  \n",
      "<<<iteration:[700/914] - total_loss: 56.2872  \n",
      "<<<iteration:[720/914] - total_loss: 56.3408  \n",
      "<<<iteration:[740/914] - total_loss: 56.2929  \n",
      "<<<iteration:[760/914] - total_loss: 56.2640  \n",
      "<<<iteration:[780/914] - total_loss: 56.3112  \n",
      "<<<iteration:[800/914] - total_loss: 56.2953  \n",
      "<<<iteration:[820/914] - total_loss: 56.3275  \n",
      "<<<iteration:[840/914] - total_loss: 56.2802  \n",
      "<<<iteration:[860/914] - total_loss: 56.3140  \n",
      "<<<iteration:[880/914] - total_loss: 56.3003  \n",
      "<<<iteration:[900/914] - total_loss: 56.3359  \n",
      "\n",
      "epoch:18/100 - Train Loss: 56.3292, Val Loss: 57.7548\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 59.0891  \n",
      "<<<iteration:[40/914] - total_loss: 56.1934  \n",
      "<<<iteration:[60/914] - total_loss: 56.1297  \n",
      "<<<iteration:[80/914] - total_loss: 56.2319  \n",
      "<<<iteration:[100/914] - total_loss: 56.1733  \n",
      "<<<iteration:[120/914] - total_loss: 56.2227  \n",
      "<<<iteration:[140/914] - total_loss: 56.1788  \n",
      "<<<iteration:[160/914] - total_loss: 56.2473  \n",
      "<<<iteration:[180/914] - total_loss: 56.2283  \n",
      "<<<iteration:[200/914] - total_loss: 56.2215  \n",
      "<<<iteration:[220/914] - total_loss: 56.1748  \n",
      "<<<iteration:[240/914] - total_loss: 56.1835  \n",
      "<<<iteration:[260/914] - total_loss: 56.2126  \n",
      "<<<iteration:[280/914] - total_loss: 56.1853  \n",
      "<<<iteration:[300/914] - total_loss: 56.2180  \n",
      "<<<iteration:[320/914] - total_loss: 56.1047  \n",
      "<<<iteration:[340/914] - total_loss: 56.2312  \n",
      "<<<iteration:[360/914] - total_loss: 56.1770  \n",
      "<<<iteration:[380/914] - total_loss: 56.1959  \n",
      "<<<iteration:[400/914] - total_loss: 56.1866  \n",
      "<<<iteration:[420/914] - total_loss: 56.1918  \n",
      "<<<iteration:[440/914] - total_loss: 56.1626  \n",
      "<<<iteration:[460/914] - total_loss: 56.1888  \n",
      "<<<iteration:[480/914] - total_loss: 56.1661  \n",
      "<<<iteration:[500/914] - total_loss: 56.2556  \n",
      "<<<iteration:[520/914] - total_loss: 56.2355  \n",
      "<<<iteration:[540/914] - total_loss: 56.1778  \n",
      "<<<iteration:[560/914] - total_loss: 56.2323  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[580/914] - total_loss: 56.1753  \n",
      "<<<iteration:[600/914] - total_loss: 56.1471  \n",
      "<<<iteration:[620/914] - total_loss: 56.1988  \n",
      "<<<iteration:[640/914] - total_loss: 56.1942  \n",
      "<<<iteration:[660/914] - total_loss: 56.2110  \n",
      "<<<iteration:[680/914] - total_loss: 56.2190  \n",
      "<<<iteration:[700/914] - total_loss: 56.2101  \n",
      "<<<iteration:[720/914] - total_loss: 56.1576  \n",
      "<<<iteration:[740/914] - total_loss: 56.1813  \n",
      "<<<iteration:[760/914] - total_loss: 56.1705  \n",
      "<<<iteration:[780/914] - total_loss: 56.1720  \n",
      "<<<iteration:[800/914] - total_loss: 56.1275  \n",
      "<<<iteration:[820/914] - total_loss: 56.1869  \n",
      "<<<iteration:[840/914] - total_loss: 56.2045  \n",
      "<<<iteration:[860/914] - total_loss: 56.2293  \n",
      "<<<iteration:[880/914] - total_loss: 56.2499  \n",
      "<<<iteration:[900/914] - total_loss: 56.1571  \n",
      "\n",
      "epoch:19/100 - Train Loss: 56.1951, Val Loss: 57.7406\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.9021  \n",
      "<<<iteration:[40/914] - total_loss: 56.1393  \n",
      "<<<iteration:[60/914] - total_loss: 56.0862  \n",
      "<<<iteration:[80/914] - total_loss: 56.1086  \n",
      "<<<iteration:[100/914] - total_loss: 56.0958  \n",
      "<<<iteration:[120/914] - total_loss: 56.1087  \n",
      "<<<iteration:[140/914] - total_loss: 56.0628  \n",
      "<<<iteration:[160/914] - total_loss: 56.0438  \n",
      "<<<iteration:[180/914] - total_loss: 56.1039  \n",
      "<<<iteration:[200/914] - total_loss: 56.1010  \n",
      "<<<iteration:[220/914] - total_loss: 56.0815  \n",
      "<<<iteration:[240/914] - total_loss: 56.0596  \n",
      "<<<iteration:[260/914] - total_loss: 56.0067  \n",
      "<<<iteration:[280/914] - total_loss: 56.0437  \n",
      "<<<iteration:[300/914] - total_loss: 56.0573  \n",
      "<<<iteration:[320/914] - total_loss: 56.0851  \n",
      "<<<iteration:[340/914] - total_loss: 56.0786  \n",
      "<<<iteration:[360/914] - total_loss: 56.0609  \n",
      "<<<iteration:[380/914] - total_loss: 56.0870  \n",
      "<<<iteration:[400/914] - total_loss: 56.0548  \n",
      "<<<iteration:[420/914] - total_loss: 56.0797  \n",
      "<<<iteration:[440/914] - total_loss: 56.0062  \n",
      "<<<iteration:[460/914] - total_loss: 56.0880  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/914] - total_loss: 56.1041  \n",
      "<<<iteration:[500/914] - total_loss: 56.0283  \n",
      "<<<iteration:[520/914] - total_loss: 56.0765  \n",
      "<<<iteration:[540/914] - total_loss: 56.0458  \n",
      "<<<iteration:[560/914] - total_loss: 56.0631  \n",
      "<<<iteration:[580/914] - total_loss: 56.0681  \n",
      "<<<iteration:[600/914] - total_loss: 56.1122  \n",
      "<<<iteration:[620/914] - total_loss: 56.0747  \n",
      "<<<iteration:[640/914] - total_loss: 56.0772  \n",
      "<<<iteration:[660/914] - total_loss: 56.1316  \n",
      "<<<iteration:[680/914] - total_loss: 56.0727  \n",
      "<<<iteration:[700/914] - total_loss: 56.1076  \n",
      "<<<iteration:[720/914] - total_loss: 56.0915  \n",
      "<<<iteration:[740/914] - total_loss: 56.0454  \n",
      "<<<iteration:[760/914] - total_loss: 56.0898  \n",
      "<<<iteration:[780/914] - total_loss: 56.1245  \n",
      "<<<iteration:[800/914] - total_loss: 56.1283  \n",
      "<<<iteration:[820/914] - total_loss: 56.1742  \n",
      "<<<iteration:[840/914] - total_loss: 56.0842  \n",
      "<<<iteration:[860/914] - total_loss: 56.1063  \n",
      "<<<iteration:[880/914] - total_loss: 56.1384  \n",
      "<<<iteration:[900/914] - total_loss: 56.1194  \n",
      "\n",
      "epoch:20/100 - Train Loss: 56.0853, Val Loss: 57.7279\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.8442  \n",
      "<<<iteration:[40/914] - total_loss: 56.0298  \n",
      "<<<iteration:[60/914] - total_loss: 55.9748  \n",
      "<<<iteration:[80/914] - total_loss: 55.9655  \n",
      "<<<iteration:[100/914] - total_loss: 56.0127  \n",
      "<<<iteration:[120/914] - total_loss: 55.9871  \n",
      "<<<iteration:[140/914] - total_loss: 55.9372  \n",
      "<<<iteration:[160/914] - total_loss: 55.9416  \n",
      "<<<iteration:[180/914] - total_loss: 55.9758  \n",
      "<<<iteration:[200/914] - total_loss: 55.9585  \n",
      "<<<iteration:[220/914] - total_loss: 56.0096  \n",
      "<<<iteration:[240/914] - total_loss: 55.9764  \n",
      "<<<iteration:[260/914] - total_loss: 55.9952  \n",
      "<<<iteration:[280/914] - total_loss: 55.9920  \n",
      "<<<iteration:[300/914] - total_loss: 56.0145  \n",
      "<<<iteration:[320/914] - total_loss: 55.9718  \n",
      "<<<iteration:[340/914] - total_loss: 56.0084  \n",
      "<<<iteration:[360/914] - total_loss: 55.9896  \n",
      "<<<iteration:[380/914] - total_loss: 55.9837  \n",
      "<<<iteration:[400/914] - total_loss: 55.9901  \n",
      "<<<iteration:[420/914] - total_loss: 55.9946  \n",
      "<<<iteration:[440/914] - total_loss: 56.0262  \n",
      "<<<iteration:[460/914] - total_loss: 55.9976  \n",
      "<<<iteration:[480/914] - total_loss: 55.9802  \n",
      "<<<iteration:[500/914] - total_loss: 55.9747  \n",
      "<<<iteration:[520/914] - total_loss: 56.0430  \n",
      "<<<iteration:[540/914] - total_loss: 55.9579  \n",
      "<<<iteration:[560/914] - total_loss: 56.0146  \n",
      "<<<iteration:[580/914] - total_loss: 55.9883  \n",
      "<<<iteration:[600/914] - total_loss: 55.9777  \n",
      "<<<iteration:[620/914] - total_loss: 55.9845  \n",
      "<<<iteration:[640/914] - total_loss: 56.0774  \n",
      "<<<iteration:[660/914] - total_loss: 55.9530  \n",
      "<<<iteration:[680/914] - total_loss: 56.0226  \n",
      "<<<iteration:[700/914] - total_loss: 55.9546  \n",
      "<<<iteration:[720/914] - total_loss: 56.0534  \n",
      "<<<iteration:[740/914] - total_loss: 55.9983  \n",
      "<<<iteration:[760/914] - total_loss: 55.9924  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[780/914] - total_loss: 56.1193  \n",
      "<<<iteration:[800/914] - total_loss: 56.0446  \n",
      "<<<iteration:[820/914] - total_loss: 56.0023  \n",
      "<<<iteration:[840/914] - total_loss: 56.0550  \n",
      "<<<iteration:[860/914] - total_loss: 56.0489  \n",
      "<<<iteration:[880/914] - total_loss: 56.0161  \n",
      "<<<iteration:[900/914] - total_loss: 55.9854  \n",
      "\n",
      "epoch:21/100 - Train Loss: 55.9999, Val Loss: 57.7205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/914] - total_loss: 58.7322  \n",
      "<<<iteration:[40/914] - total_loss: 55.9526  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/914] - total_loss: 55.9445  \n",
      "<<<iteration:[80/914] - total_loss: 55.9968  \n",
      "<<<iteration:[100/914] - total_loss: 55.9217  \n",
      "<<<iteration:[120/914] - total_loss: 55.9345  \n",
      "<<<iteration:[140/914] - total_loss: 55.9142  \n",
      "<<<iteration:[160/914] - total_loss: 55.8844  \n",
      "<<<iteration:[180/914] - total_loss: 55.9136  \n",
      "<<<iteration:[200/914] - total_loss: 55.9164  \n",
      "<<<iteration:[220/914] - total_loss: 55.8809  \n",
      "<<<iteration:[240/914] - total_loss: 55.9001  \n",
      "<<<iteration:[260/914] - total_loss: 55.8822  \n",
      "<<<iteration:[280/914] - total_loss: 55.8986  \n",
      "<<<iteration:[300/914] - total_loss: 55.9272  \n",
      "<<<iteration:[320/914] - total_loss: 55.9681  \n",
      "<<<iteration:[340/914] - total_loss: 55.9438  \n",
      "<<<iteration:[360/914] - total_loss: 55.9316  \n",
      "<<<iteration:[380/914] - total_loss: 55.9573  \n",
      "<<<iteration:[400/914] - total_loss: 55.9794  \n",
      "<<<iteration:[420/914] - total_loss: 55.9052  \n",
      "<<<iteration:[440/914] - total_loss: 55.9452  \n",
      "<<<iteration:[460/914] - total_loss: 55.9050  \n",
      "<<<iteration:[480/914] - total_loss: 55.9495  \n",
      "<<<iteration:[500/914] - total_loss: 55.9247  \n",
      "<<<iteration:[520/914] - total_loss: 55.9243  \n",
      "<<<iteration:[540/914] - total_loss: 55.9513  \n",
      "<<<iteration:[560/914] - total_loss: 55.9685  \n",
      "<<<iteration:[580/914] - total_loss: 55.9600  \n",
      "<<<iteration:[600/914] - total_loss: 55.8908  \n",
      "<<<iteration:[620/914] - total_loss: 55.9320  \n",
      "<<<iteration:[640/914] - total_loss: 55.9015  \n",
      "<<<iteration:[660/914] - total_loss: 55.9827  \n",
      "<<<iteration:[680/914] - total_loss: 55.9235  \n",
      "<<<iteration:[700/914] - total_loss: 55.9069  \n",
      "<<<iteration:[720/914] - total_loss: 55.9312  \n",
      "<<<iteration:[740/914] - total_loss: 55.9318  \n",
      "<<<iteration:[760/914] - total_loss: 55.9648  \n",
      "<<<iteration:[780/914] - total_loss: 55.9394  \n",
      "<<<iteration:[800/914] - total_loss: 55.9062  \n",
      "<<<iteration:[820/914] - total_loss: 55.9027  \n",
      "<<<iteration:[840/914] - total_loss: 55.9641  \n",
      "<<<iteration:[860/914] - total_loss: 55.9561  \n",
      "<<<iteration:[880/914] - total_loss: 55.9376  \n",
      "<<<iteration:[900/914] - total_loss: 55.9149  \n",
      "\n",
      "epoch:22/100 - Train Loss: 55.9317, Val Loss: 57.7210\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.6902  \n",
      "<<<iteration:[40/914] - total_loss: 55.8765  \n",
      "<<<iteration:[60/914] - total_loss: 55.8720  \n",
      "<<<iteration:[80/914] - total_loss: 55.8628  \n",
      "<<<iteration:[100/914] - total_loss: 55.8645  \n",
      "<<<iteration:[120/914] - total_loss: 55.8699  \n",
      "<<<iteration:[140/914] - total_loss: 55.8857  \n",
      "<<<iteration:[160/914] - total_loss: 55.8609  \n",
      "<<<iteration:[180/914] - total_loss: 55.8887  \n",
      "<<<iteration:[200/914] - total_loss: 55.8832  \n",
      "<<<iteration:[220/914] - total_loss: 55.9154  \n",
      "<<<iteration:[240/914] - total_loss: 55.9054  \n",
      "<<<iteration:[260/914] - total_loss: 55.9062  \n",
      "<<<iteration:[280/914] - total_loss: 55.8731  \n",
      "<<<iteration:[300/914] - total_loss: 55.8656  \n",
      "<<<iteration:[320/914] - total_loss: 55.8689  \n",
      "<<<iteration:[340/914] - total_loss: 55.8919  \n",
      "<<<iteration:[360/914] - total_loss: 55.8799  \n",
      "<<<iteration:[380/914] - total_loss: 55.8525  \n",
      "<<<iteration:[400/914] - total_loss: 55.8829  \n",
      "<<<iteration:[420/914] - total_loss: 55.8860  \n",
      "<<<iteration:[440/914] - total_loss: 55.8420  \n",
      "<<<iteration:[460/914] - total_loss: 55.8268  \n",
      "<<<iteration:[480/914] - total_loss: 55.8389  \n",
      "<<<iteration:[500/914] - total_loss: 55.8964  \n",
      "<<<iteration:[520/914] - total_loss: 55.8285  \n",
      "<<<iteration:[540/914] - total_loss: 55.8707  \n",
      "<<<iteration:[560/914] - total_loss: 55.8775  \n",
      "<<<iteration:[580/914] - total_loss: 55.9368  \n",
      "<<<iteration:[600/914] - total_loss: 55.8706  \n",
      "<<<iteration:[620/914] - total_loss: 55.8861  \n",
      "<<<iteration:[640/914] - total_loss: 55.8737  \n",
      "<<<iteration:[660/914] - total_loss: 55.8853  \n",
      "<<<iteration:[680/914] - total_loss: 55.9170  \n",
      "<<<iteration:[700/914] - total_loss: 55.8285  \n",
      "<<<iteration:[720/914] - total_loss: 55.8652  \n",
      "<<<iteration:[740/914] - total_loss: 55.8796  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[760/914] - total_loss: 55.9010  \n",
      "<<<iteration:[780/914] - total_loss: 55.8918  \n",
      "<<<iteration:[800/914] - total_loss: 55.8684  \n",
      "<<<iteration:[820/914] - total_loss: 55.8724  \n",
      "<<<iteration:[840/914] - total_loss: 55.8669  \n",
      "<<<iteration:[860/914] - total_loss: 55.9067  \n",
      "<<<iteration:[880/914] - total_loss: 55.8830  \n",
      "<<<iteration:[900/914] - total_loss: 55.8338  \n",
      "\n",
      "epoch:23/100 - Train Loss: 55.8763, Val Loss: 57.7312\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.6238  \n",
      "<<<iteration:[40/914] - total_loss: 55.8452  \n",
      "<<<iteration:[60/914] - total_loss: 55.7994  \n",
      "<<<iteration:[80/914] - total_loss: 55.8367  \n",
      "<<<iteration:[100/914] - total_loss: 55.8314  \n",
      "<<<iteration:[120/914] - total_loss: 55.8612  \n",
      "<<<iteration:[140/914] - total_loss: 55.7886  \n",
      "<<<iteration:[160/914] - total_loss: 55.7753  \n",
      "<<<iteration:[180/914] - total_loss: 55.8130  \n",
      "<<<iteration:[200/914] - total_loss: 55.8045  \n",
      "<<<iteration:[220/914] - total_loss: 55.8350  \n",
      "<<<iteration:[240/914] - total_loss: 55.8021  \n",
      "<<<iteration:[260/914] - total_loss: 55.8264  \n",
      "<<<iteration:[280/914] - total_loss: 55.8412  \n",
      "<<<iteration:[300/914] - total_loss: 55.8350  \n",
      "<<<iteration:[320/914] - total_loss: 55.8632  \n",
      "<<<iteration:[340/914] - total_loss: 55.8378  \n",
      "<<<iteration:[360/914] - total_loss: 55.8254  \n",
      "<<<iteration:[380/914] - total_loss: 55.8397  \n",
      "<<<iteration:[400/914] - total_loss: 55.8053  \n",
      "<<<iteration:[420/914] - total_loss: 55.8493  \n",
      "<<<iteration:[440/914] - total_loss: 55.8134  \n",
      "<<<iteration:[460/914] - total_loss: 55.8066  \n",
      "<<<iteration:[480/914] - total_loss: 55.8342  \n",
      "<<<iteration:[500/914] - total_loss: 55.8558  \n",
      "<<<iteration:[520/914] - total_loss: 55.8490  \n",
      "<<<iteration:[540/914] - total_loss: 55.8308  \n",
      "<<<iteration:[560/914] - total_loss: 55.8228  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[580/914] - total_loss: 55.7934  \n",
      "<<<iteration:[600/914] - total_loss: 55.8460  \n",
      "<<<iteration:[620/914] - total_loss: 55.8524  \n",
      "<<<iteration:[640/914] - total_loss: 55.8185  \n",
      "<<<iteration:[660/914] - total_loss: 55.8086  \n",
      "<<<iteration:[680/914] - total_loss: 55.7928  \n",
      "<<<iteration:[700/914] - total_loss: 55.8562  \n",
      "<<<iteration:[720/914] - total_loss: 55.8352  \n",
      "<<<iteration:[740/914] - total_loss: 55.8766  \n",
      "<<<iteration:[760/914] - total_loss: 55.8152  \n",
      "<<<iteration:[780/914] - total_loss: 55.8469  \n",
      "<<<iteration:[800/914] - total_loss: 55.8762  \n",
      "<<<iteration:[820/914] - total_loss: 55.8961  \n",
      "<<<iteration:[840/914] - total_loss: 55.8646  \n",
      "<<<iteration:[860/914] - total_loss: 55.8313  \n",
      "<<<iteration:[880/914] - total_loss: 55.8535  \n",
      "<<<iteration:[900/914] - total_loss: 55.8829  \n",
      "\n",
      "epoch:24/100 - Train Loss: 55.8335, Val Loss: 57.7430\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.5694  \n",
      "<<<iteration:[40/914] - total_loss: 55.8117  \n",
      "<<<iteration:[60/914] - total_loss: 55.7754  \n",
      "<<<iteration:[80/914] - total_loss: 55.7094  \n",
      "<<<iteration:[100/914] - total_loss: 55.7663  \n",
      "<<<iteration:[120/914] - total_loss: 55.8356  \n",
      "<<<iteration:[140/914] - total_loss: 55.7435  \n",
      "<<<iteration:[160/914] - total_loss: 55.7997  \n",
      "<<<iteration:[180/914] - total_loss: 55.8452  \n",
      "<<<iteration:[200/914] - total_loss: 55.7783  \n",
      "<<<iteration:[220/914] - total_loss: 55.8201  \n",
      "<<<iteration:[240/914] - total_loss: 55.8021  \n",
      "<<<iteration:[260/914] - total_loss: 55.7569  \n",
      "<<<iteration:[280/914] - total_loss: 55.8062  \n",
      "<<<iteration:[300/914] - total_loss: 55.7387  \n",
      "<<<iteration:[320/914] - total_loss: 55.7795  \n",
      "<<<iteration:[340/914] - total_loss: 55.7391  \n",
      "<<<iteration:[360/914] - total_loss: 55.8001  \n",
      "<<<iteration:[380/914] - total_loss: 55.7713  \n",
      "<<<iteration:[400/914] - total_loss: 55.7833  \n",
      "<<<iteration:[420/914] - total_loss: 55.7823  \n",
      "<<<iteration:[440/914] - total_loss: 55.7693  \n",
      "<<<iteration:[460/914] - total_loss: 55.7989  \n",
      "<<<iteration:[480/914] - total_loss: 55.8307  \n",
      "<<<iteration:[500/914] - total_loss: 55.8039  \n",
      "<<<iteration:[520/914] - total_loss: 55.8080  \n",
      "<<<iteration:[540/914] - total_loss: 55.8200  \n",
      "<<<iteration:[560/914] - total_loss: 55.7959  \n",
      "<<<iteration:[580/914] - total_loss: 55.8115  \n",
      "<<<iteration:[600/914] - total_loss: 55.7782  \n",
      "<<<iteration:[620/914] - total_loss: 55.8165  \n",
      "<<<iteration:[640/914] - total_loss: 55.7548  \n",
      "<<<iteration:[660/914] - total_loss: 55.7740  \n",
      "<<<iteration:[680/914] - total_loss: 55.8652  \n",
      "<<<iteration:[700/914] - total_loss: 55.8239  \n",
      "<<<iteration:[720/914] - total_loss: 55.7897  \n",
      "<<<iteration:[740/914] - total_loss: 55.8537  \n",
      "<<<iteration:[760/914] - total_loss: 55.8248  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[780/914] - total_loss: 55.8239  \n",
      "<<<iteration:[800/914] - total_loss: 55.8077  \n",
      "<<<iteration:[820/914] - total_loss: 55.8226  \n",
      "<<<iteration:[840/914] - total_loss: 55.8592  \n",
      "<<<iteration:[860/914] - total_loss: 55.8164  \n",
      "<<<iteration:[880/914] - total_loss: 55.8529  \n",
      "<<<iteration:[900/914] - total_loss: 55.7837  \n",
      "\n",
      "epoch:25/100 - Train Loss: 55.7983, Val Loss: 57.7143\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.5560  \n",
      "<<<iteration:[40/914] - total_loss: 55.7679  \n",
      "<<<iteration:[60/914] - total_loss: 55.7776  \n",
      "<<<iteration:[80/914] - total_loss: 55.7550  \n",
      "<<<iteration:[100/914] - total_loss: 55.7588  \n",
      "<<<iteration:[120/914] - total_loss: 55.8018  \n",
      "<<<iteration:[140/914] - total_loss: 55.7231  \n",
      "<<<iteration:[160/914] - total_loss: 55.7387  \n",
      "<<<iteration:[180/914] - total_loss: 55.7348  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/914] - total_loss: 55.7749  \n",
      "<<<iteration:[220/914] - total_loss: 55.7326  \n",
      "<<<iteration:[240/914] - total_loss: 55.7689  \n",
      "<<<iteration:[260/914] - total_loss: 55.7921  \n",
      "<<<iteration:[280/914] - total_loss: 55.8166  \n",
      "<<<iteration:[300/914] - total_loss: 55.7538  \n",
      "<<<iteration:[320/914] - total_loss: 55.7611  \n",
      "<<<iteration:[340/914] - total_loss: 55.7400  \n",
      "<<<iteration:[360/914] - total_loss: 55.7758  \n",
      "<<<iteration:[380/914] - total_loss: 55.7768  \n",
      "<<<iteration:[400/914] - total_loss: 55.7170  \n",
      "<<<iteration:[420/914] - total_loss: 55.7237  \n",
      "<<<iteration:[440/914] - total_loss: 55.7894  \n",
      "<<<iteration:[460/914] - total_loss: 55.8134  \n",
      "<<<iteration:[480/914] - total_loss: 55.7741  \n",
      "<<<iteration:[500/914] - total_loss: 55.7427  \n",
      "<<<iteration:[520/914] - total_loss: 55.7830  \n",
      "<<<iteration:[540/914] - total_loss: 55.7439  \n",
      "<<<iteration:[560/914] - total_loss: 55.7960  \n",
      "<<<iteration:[580/914] - total_loss: 55.7956  \n",
      "<<<iteration:[600/914] - total_loss: 55.8115  \n",
      "<<<iteration:[620/914] - total_loss: 55.7471  \n",
      "<<<iteration:[640/914] - total_loss: 55.7828  \n",
      "<<<iteration:[660/914] - total_loss: 55.7941  \n",
      "<<<iteration:[680/914] - total_loss: 55.7579  \n",
      "<<<iteration:[700/914] - total_loss: 55.7924  \n",
      "<<<iteration:[720/914] - total_loss: 55.7601  \n",
      "<<<iteration:[740/914] - total_loss: 55.7937  \n",
      "<<<iteration:[760/914] - total_loss: 55.7723  \n",
      "<<<iteration:[780/914] - total_loss: 55.7868  \n",
      "<<<iteration:[800/914] - total_loss: 55.7788  \n",
      "<<<iteration:[820/914] - total_loss: 55.7361  \n",
      "<<<iteration:[840/914] - total_loss: 55.7050  \n",
      "<<<iteration:[860/914] - total_loss: 55.7586  \n",
      "<<<iteration:[880/914] - total_loss: 55.7700  \n",
      "<<<iteration:[900/914] - total_loss: 55.8039  \n",
      "\n",
      "epoch:26/100 - Train Loss: 55.7678, Val Loss: 57.7285\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.5192  \n",
      "<<<iteration:[40/914] - total_loss: 55.7248  \n",
      "<<<iteration:[60/914] - total_loss: 55.7126  \n",
      "<<<iteration:[80/914] - total_loss: 55.7770  \n",
      "<<<iteration:[100/914] - total_loss: 55.7145  \n",
      "<<<iteration:[120/914] - total_loss: 55.7259  \n",
      "<<<iteration:[140/914] - total_loss: 55.7534  \n",
      "<<<iteration:[160/914] - total_loss: 55.7102  \n",
      "<<<iteration:[180/914] - total_loss: 55.6638  \n",
      "<<<iteration:[200/914] - total_loss: 55.7301  \n",
      "<<<iteration:[220/914] - total_loss: 55.7063  \n",
      "<<<iteration:[240/914] - total_loss: 55.7680  \n",
      "<<<iteration:[260/914] - total_loss: 55.6943  \n",
      "<<<iteration:[280/914] - total_loss: 55.7032  \n",
      "<<<iteration:[300/914] - total_loss: 55.6698  \n",
      "<<<iteration:[320/914] - total_loss: 55.7175  \n",
      "<<<iteration:[340/914] - total_loss: 55.7267  \n",
      "<<<iteration:[360/914] - total_loss: 55.7608  \n",
      "<<<iteration:[380/914] - total_loss: 55.7130  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[400/914] - total_loss: 55.7190  \n",
      "<<<iteration:[420/914] - total_loss: 55.7070  \n",
      "<<<iteration:[440/914] - total_loss: 55.7369  \n",
      "<<<iteration:[460/914] - total_loss: 55.7499  \n",
      "<<<iteration:[480/914] - total_loss: 55.7134  \n",
      "<<<iteration:[500/914] - total_loss: 55.7352  \n",
      "<<<iteration:[520/914] - total_loss: 55.7417  \n",
      "<<<iteration:[540/914] - total_loss: 55.7256  \n",
      "<<<iteration:[560/914] - total_loss: 55.7103  \n",
      "<<<iteration:[580/914] - total_loss: 55.7749  \n",
      "<<<iteration:[600/914] - total_loss: 55.7171  \n",
      "<<<iteration:[620/914] - total_loss: 55.7252  \n",
      "<<<iteration:[640/914] - total_loss: 55.7729  \n",
      "<<<iteration:[660/914] - total_loss: 55.7089  \n",
      "<<<iteration:[680/914] - total_loss: 55.6976  \n",
      "<<<iteration:[700/914] - total_loss: 55.8082  \n",
      "<<<iteration:[720/914] - total_loss: 55.7355  \n",
      "<<<iteration:[740/914] - total_loss: 55.7426  \n",
      "<<<iteration:[760/914] - total_loss: 55.7604  \n",
      "<<<iteration:[780/914] - total_loss: 55.7259  \n",
      "<<<iteration:[800/914] - total_loss: 55.7279  \n",
      "<<<iteration:[820/914] - total_loss: 55.7083  \n",
      "<<<iteration:[840/914] - total_loss: 55.7433  \n",
      "<<<iteration:[860/914] - total_loss: 55.7475  \n",
      "<<<iteration:[880/914] - total_loss: 55.7354  \n",
      "<<<iteration:[900/914] - total_loss: 55.7411  \n",
      "\n",
      "epoch:27/100 - Train Loss: 55.7297, Val Loss: 57.7010\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.5004  \n",
      "<<<iteration:[40/914] - total_loss: 55.6805  \n",
      "<<<iteration:[60/914] - total_loss: 55.6895  \n",
      "<<<iteration:[80/914] - total_loss: 55.7555  \n",
      "<<<iteration:[100/914] - total_loss: 55.6783  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/914] - total_loss: 55.7109  \n",
      "<<<iteration:[140/914] - total_loss: 55.7247  \n",
      "<<<iteration:[160/914] - total_loss: 55.6421  \n",
      "<<<iteration:[180/914] - total_loss: 55.6451  \n",
      "<<<iteration:[200/914] - total_loss: 55.6822  \n",
      "<<<iteration:[220/914] - total_loss: 55.6769  \n",
      "<<<iteration:[240/914] - total_loss: 55.6790  \n",
      "<<<iteration:[260/914] - total_loss: 55.6861  \n",
      "<<<iteration:[280/914] - total_loss: 55.6539  \n",
      "<<<iteration:[300/914] - total_loss: 55.6932  \n",
      "<<<iteration:[320/914] - total_loss: 55.7074  \n",
      "<<<iteration:[340/914] - total_loss: 55.7115  \n",
      "<<<iteration:[360/914] - total_loss: 55.6980  \n",
      "<<<iteration:[380/914] - total_loss: 55.6750  \n",
      "<<<iteration:[400/914] - total_loss: 55.7144  \n",
      "<<<iteration:[420/914] - total_loss: 55.6959  \n",
      "<<<iteration:[440/914] - total_loss: 55.6789  \n",
      "<<<iteration:[460/914] - total_loss: 55.7024  \n",
      "<<<iteration:[480/914] - total_loss: 55.7149  \n",
      "<<<iteration:[500/914] - total_loss: 55.6986  \n",
      "<<<iteration:[520/914] - total_loss: 55.7141  \n",
      "<<<iteration:[540/914] - total_loss: 55.7023  \n",
      "<<<iteration:[560/914] - total_loss: 55.7279  \n",
      "<<<iteration:[580/914] - total_loss: 55.7309  \n",
      "<<<iteration:[600/914] - total_loss: 55.7239  \n",
      "<<<iteration:[620/914] - total_loss: 55.7549  \n",
      "<<<iteration:[640/914] - total_loss: 55.7071  \n",
      "<<<iteration:[660/914] - total_loss: 55.7147  \n",
      "<<<iteration:[680/914] - total_loss: 55.6818  \n",
      "<<<iteration:[700/914] - total_loss: 55.6880  \n",
      "<<<iteration:[720/914] - total_loss: 55.7098  \n",
      "<<<iteration:[740/914] - total_loss: 55.7232  \n",
      "<<<iteration:[760/914] - total_loss: 55.7092  \n",
      "<<<iteration:[780/914] - total_loss: 55.6934  \n",
      "<<<iteration:[800/914] - total_loss: 55.7275  \n",
      "<<<iteration:[820/914] - total_loss: 55.6822  \n",
      "<<<iteration:[840/914] - total_loss: 55.6657  \n",
      "<<<iteration:[860/914] - total_loss: 55.7349  \n",
      "<<<iteration:[880/914] - total_loss: 55.6968  \n",
      "<<<iteration:[900/914] - total_loss: 55.6801  \n",
      "\n",
      "epoch:28/100 - Train Loss: 55.6998, Val Loss: 57.7086\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.4183  \n",
      "<<<iteration:[40/914] - total_loss: 55.6816  \n",
      "<<<iteration:[60/914] - total_loss: 55.6519  \n",
      "<<<iteration:[80/914] - total_loss: 55.7093  \n",
      "<<<iteration:[100/914] - total_loss: 55.6857  \n",
      "<<<iteration:[120/914] - total_loss: 55.6463  \n",
      "<<<iteration:[140/914] - total_loss: 55.7235  \n",
      "<<<iteration:[160/914] - total_loss: 55.6147  \n",
      "<<<iteration:[180/914] - total_loss: 55.6693  \n",
      "<<<iteration:[200/914] - total_loss: 55.6755  \n",
      "<<<iteration:[220/914] - total_loss: 55.6801  \n",
      "<<<iteration:[240/914] - total_loss: 55.7086  \n",
      "<<<iteration:[260/914] - total_loss: 55.6398  \n",
      "<<<iteration:[280/914] - total_loss: 55.6542  \n",
      "<<<iteration:[300/914] - total_loss: 55.6880  \n",
      "<<<iteration:[320/914] - total_loss: 55.6690  \n",
      "<<<iteration:[340/914] - total_loss: 55.7062  \n",
      "<<<iteration:[360/914] - total_loss: 55.6875  \n",
      "<<<iteration:[380/914] - total_loss: 55.6877  \n",
      "<<<iteration:[400/914] - total_loss: 55.6676  \n",
      "<<<iteration:[420/914] - total_loss: 55.6472  \n",
      "<<<iteration:[440/914] - total_loss: 55.6788  \n",
      "<<<iteration:[460/914] - total_loss: 55.6347  \n",
      "<<<iteration:[480/914] - total_loss: 55.6132  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/914] - total_loss: 55.6601  \n",
      "<<<iteration:[520/914] - total_loss: 55.6652  \n",
      "<<<iteration:[540/914] - total_loss: 55.6605  \n",
      "<<<iteration:[560/914] - total_loss: 55.6965  \n",
      "<<<iteration:[580/914] - total_loss: 55.6502  \n",
      "<<<iteration:[600/914] - total_loss: 55.6943  \n",
      "<<<iteration:[620/914] - total_loss: 55.6951  \n",
      "<<<iteration:[640/914] - total_loss: 55.6830  \n",
      "<<<iteration:[660/914] - total_loss: 55.6643  \n",
      "<<<iteration:[680/914] - total_loss: 55.7250  \n",
      "<<<iteration:[700/914] - total_loss: 55.7255  \n",
      "<<<iteration:[720/914] - total_loss: 55.6729  \n",
      "<<<iteration:[740/914] - total_loss: 55.6563  \n",
      "<<<iteration:[760/914] - total_loss: 55.6622  \n",
      "<<<iteration:[780/914] - total_loss: 55.6712  \n",
      "<<<iteration:[800/914] - total_loss: 55.6759  \n",
      "<<<iteration:[820/914] - total_loss: 55.6887  \n",
      "<<<iteration:[840/914] - total_loss: 55.6593  \n",
      "<<<iteration:[860/914] - total_loss: 55.6572  \n",
      "<<<iteration:[880/914] - total_loss: 55.6691  \n",
      "<<<iteration:[900/914] - total_loss: 55.6642  \n",
      "\n",
      "epoch:29/100 - Train Loss: 55.6731, Val Loss: 57.6950\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.4123  \n",
      "<<<iteration:[40/914] - total_loss: 55.6104  \n",
      "<<<iteration:[60/914] - total_loss: 55.6546  \n",
      "<<<iteration:[80/914] - total_loss: 55.6650  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/914] - total_loss: 55.5958  \n",
      "<<<iteration:[120/914] - total_loss: 55.6127  \n",
      "<<<iteration:[140/914] - total_loss: 55.6408  \n",
      "<<<iteration:[160/914] - total_loss: 55.5947  \n",
      "<<<iteration:[180/914] - total_loss: 55.6747  \n",
      "<<<iteration:[200/914] - total_loss: 55.6205  \n",
      "<<<iteration:[220/914] - total_loss: 55.5862  \n",
      "<<<iteration:[240/914] - total_loss: 55.6013  \n",
      "<<<iteration:[260/914] - total_loss: 55.6285  \n",
      "<<<iteration:[280/914] - total_loss: 55.6534  \n",
      "<<<iteration:[300/914] - total_loss: 55.6357  \n",
      "<<<iteration:[320/914] - total_loss: 55.6499  \n",
      "<<<iteration:[340/914] - total_loss: 55.6402  \n",
      "<<<iteration:[360/914] - total_loss: 55.6583  \n",
      "<<<iteration:[380/914] - total_loss: 55.6678  \n",
      "<<<iteration:[400/914] - total_loss: 55.6530  \n",
      "<<<iteration:[420/914] - total_loss: 55.6680  \n",
      "<<<iteration:[440/914] - total_loss: 55.6811  \n",
      "<<<iteration:[460/914] - total_loss: 55.6529  \n",
      "<<<iteration:[480/914] - total_loss: 55.6278  \n",
      "<<<iteration:[500/914] - total_loss: 55.5828  \n",
      "<<<iteration:[520/914] - total_loss: 55.6410  \n",
      "<<<iteration:[540/914] - total_loss: 55.6347  \n",
      "<<<iteration:[560/914] - total_loss: 55.6787  \n",
      "<<<iteration:[580/914] - total_loss: 55.6320  \n",
      "<<<iteration:[600/914] - total_loss: 55.6428  \n",
      "<<<iteration:[620/914] - total_loss: 55.6224  \n",
      "<<<iteration:[640/914] - total_loss: 55.5875  \n",
      "<<<iteration:[660/914] - total_loss: 55.5959  \n",
      "<<<iteration:[680/914] - total_loss: 55.6493  \n",
      "<<<iteration:[700/914] - total_loss: 55.6238  \n",
      "<<<iteration:[720/914] - total_loss: 55.7033  \n",
      "<<<iteration:[740/914] - total_loss: 55.6511  \n",
      "<<<iteration:[760/914] - total_loss: 55.6311  \n",
      "<<<iteration:[780/914] - total_loss: 55.6561  \n",
      "<<<iteration:[800/914] - total_loss: 55.6679  \n",
      "<<<iteration:[820/914] - total_loss: 55.6525  \n",
      "<<<iteration:[840/914] - total_loss: 55.6633  \n",
      "<<<iteration:[860/914] - total_loss: 55.6813  \n",
      "<<<iteration:[880/914] - total_loss: 55.6994  \n",
      "<<<iteration:[900/914] - total_loss: 55.6458  \n",
      "\n",
      "epoch:30/100 - Train Loss: 55.6421, Val Loss: 57.6966\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.3815  \n",
      "<<<iteration:[40/914] - total_loss: 55.6171  \n",
      "<<<iteration:[60/914] - total_loss: 55.6181  \n",
      "<<<iteration:[80/914] - total_loss: 55.6286  \n",
      "<<<iteration:[100/914] - total_loss: 55.6413  \n",
      "<<<iteration:[120/914] - total_loss: 55.6125  \n",
      "<<<iteration:[140/914] - total_loss: 55.6488  \n",
      "<<<iteration:[160/914] - total_loss: 55.6345  \n",
      "<<<iteration:[180/914] - total_loss: 55.6571  \n",
      "<<<iteration:[200/914] - total_loss: 55.6004  \n",
      "<<<iteration:[220/914] - total_loss: 55.6369  \n",
      "<<<iteration:[240/914] - total_loss: 55.6276  \n",
      "<<<iteration:[260/914] - total_loss: 55.6007  \n",
      "<<<iteration:[280/914] - total_loss: 55.5955  \n",
      "<<<iteration:[300/914] - total_loss: 55.6136  \n",
      "<<<iteration:[320/914] - total_loss: 55.6511  \n",
      "<<<iteration:[340/914] - total_loss: 55.6268  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[360/914] - total_loss: 55.6066  \n",
      "<<<iteration:[380/914] - total_loss: 55.5915  \n",
      "<<<iteration:[400/914] - total_loss: 55.5945  \n",
      "<<<iteration:[420/914] - total_loss: 55.6064  \n",
      "<<<iteration:[440/914] - total_loss: 55.6772  \n",
      "<<<iteration:[460/914] - total_loss: 55.6415  \n",
      "<<<iteration:[480/914] - total_loss: 55.6073  \n",
      "<<<iteration:[500/914] - total_loss: 55.6470  \n",
      "<<<iteration:[520/914] - total_loss: 55.6275  \n",
      "<<<iteration:[540/914] - total_loss: 55.6418  \n",
      "<<<iteration:[560/914] - total_loss: 55.6154  \n",
      "<<<iteration:[580/914] - total_loss: 55.6286  \n",
      "<<<iteration:[600/914] - total_loss: 55.6149  \n",
      "<<<iteration:[620/914] - total_loss: 55.6438  \n",
      "<<<iteration:[640/914] - total_loss: 55.6461  \n",
      "<<<iteration:[660/914] - total_loss: 55.6315  \n",
      "<<<iteration:[680/914] - total_loss: 55.6220  \n",
      "<<<iteration:[700/914] - total_loss: 55.5971  \n",
      "<<<iteration:[720/914] - total_loss: 55.6445  \n",
      "<<<iteration:[740/914] - total_loss: 55.6131  \n",
      "<<<iteration:[760/914] - total_loss: 55.6395  \n",
      "<<<iteration:[780/914] - total_loss: 55.6090  \n",
      "<<<iteration:[800/914] - total_loss: 55.5998  \n",
      "<<<iteration:[820/914] - total_loss: 55.6127  \n",
      "<<<iteration:[840/914] - total_loss: 55.6521  \n",
      "<<<iteration:[860/914] - total_loss: 55.5825  \n",
      "<<<iteration:[880/914] - total_loss: 55.6735  \n",
      "<<<iteration:[900/914] - total_loss: 55.6623  \n",
      "\n",
      "epoch:31/100 - Train Loss: 55.6255, Val Loss: 57.6999\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.3352  \n",
      "<<<iteration:[40/914] - total_loss: 55.6251  \n",
      "<<<iteration:[60/914] - total_loss: 55.6306  \n",
      "<<<iteration:[80/914] - total_loss: 55.5610  \n",
      "<<<iteration:[100/914] - total_loss: 55.5772  \n",
      "<<<iteration:[120/914] - total_loss: 55.6320  \n",
      "<<<iteration:[140/914] - total_loss: 55.6059  \n",
      "<<<iteration:[160/914] - total_loss: 55.5998  \n",
      "<<<iteration:[180/914] - total_loss: 55.6061  \n",
      "<<<iteration:[200/914] - total_loss: 55.5976  \n",
      "<<<iteration:[220/914] - total_loss: 55.5464  \n",
      "<<<iteration:[240/914] - total_loss: 55.5827  \n",
      "<<<iteration:[260/914] - total_loss: 55.5749  \n",
      "<<<iteration:[280/914] - total_loss: 55.6370  \n",
      "<<<iteration:[300/914] - total_loss: 55.5672  \n",
      "<<<iteration:[320/914] - total_loss: 55.5962  \n",
      "<<<iteration:[340/914] - total_loss: 55.5738  \n",
      "<<<iteration:[360/914] - total_loss: 55.6090  \n",
      "<<<iteration:[380/914] - total_loss: 55.6255  \n",
      "<<<iteration:[400/914] - total_loss: 55.6056  \n",
      "<<<iteration:[420/914] - total_loss: 55.6221  \n",
      "<<<iteration:[440/914] - total_loss: 55.5904  \n",
      "<<<iteration:[460/914] - total_loss: 55.6209  \n",
      "<<<iteration:[480/914] - total_loss: 55.6054  \n",
      "<<<iteration:[500/914] - total_loss: 55.5870  \n",
      "<<<iteration:[520/914] - total_loss: 55.6141  \n",
      "<<<iteration:[540/914] - total_loss: 55.6558  \n",
      "<<<iteration:[560/914] - total_loss: 55.5801  \n",
      "<<<iteration:[580/914] - total_loss: 55.6017  \n",
      "<<<iteration:[600/914] - total_loss: 55.6096  \n",
      "<<<iteration:[620/914] - total_loss: 55.5956  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[640/914] - total_loss: 55.6193  \n",
      "<<<iteration:[660/914] - total_loss: 55.6128  \n",
      "<<<iteration:[680/914] - total_loss: 55.5935  \n",
      "<<<iteration:[700/914] - total_loss: 55.6287  \n",
      "<<<iteration:[720/914] - total_loss: 55.6047  \n",
      "<<<iteration:[740/914] - total_loss: 55.6121  \n",
      "<<<iteration:[760/914] - total_loss: 55.6525  \n",
      "<<<iteration:[780/914] - total_loss: 55.5989  \n",
      "<<<iteration:[800/914] - total_loss: 55.6280  \n",
      "<<<iteration:[820/914] - total_loss: 55.6578  \n",
      "<<<iteration:[840/914] - total_loss: 55.6241  \n",
      "<<<iteration:[860/914] - total_loss: 55.6471  \n",
      "<<<iteration:[880/914] - total_loss: 55.6329  \n",
      "<<<iteration:[900/914] - total_loss: 55.5819  \n",
      "\n",
      "epoch:32/100 - Train Loss: 55.6063, Val Loss: 57.6916\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.3887  \n",
      "<<<iteration:[40/914] - total_loss: 55.5945  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/914] - total_loss: 55.5908  \n",
      "<<<iteration:[80/914] - total_loss: 55.5846  \n",
      "<<<iteration:[100/914] - total_loss: 55.5641  \n",
      "<<<iteration:[120/914] - total_loss: 55.6247  \n",
      "<<<iteration:[140/914] - total_loss: 55.5955  \n",
      "<<<iteration:[160/914] - total_loss: 55.6078  \n",
      "<<<iteration:[180/914] - total_loss: 55.5490  \n",
      "<<<iteration:[200/914] - total_loss: 55.6218  \n",
      "<<<iteration:[220/914] - total_loss: 55.5849  \n",
      "<<<iteration:[240/914] - total_loss: 55.5903  \n",
      "<<<iteration:[260/914] - total_loss: 55.5259  \n",
      "<<<iteration:[280/914] - total_loss: 55.5666  \n",
      "<<<iteration:[300/914] - total_loss: 55.5708  \n",
      "<<<iteration:[320/914] - total_loss: 55.5557  \n",
      "<<<iteration:[340/914] - total_loss: 55.5983  \n",
      "<<<iteration:[360/914] - total_loss: 55.5731  \n",
      "<<<iteration:[380/914] - total_loss: 55.5564  \n",
      "<<<iteration:[400/914] - total_loss: 55.6313  \n",
      "<<<iteration:[420/914] - total_loss: 55.5681  \n",
      "<<<iteration:[440/914] - total_loss: 55.5821  \n",
      "<<<iteration:[460/914] - total_loss: 55.5939  \n",
      "<<<iteration:[480/914] - total_loss: 55.5974  \n",
      "<<<iteration:[500/914] - total_loss: 55.5707  \n",
      "<<<iteration:[520/914] - total_loss: 55.5609  \n",
      "<<<iteration:[540/914] - total_loss: 55.6052  \n",
      "<<<iteration:[560/914] - total_loss: 55.5695  \n",
      "<<<iteration:[580/914] - total_loss: 55.5653  \n",
      "<<<iteration:[600/914] - total_loss: 55.6140  \n",
      "<<<iteration:[620/914] - total_loss: 55.5748  \n",
      "<<<iteration:[640/914] - total_loss: 55.6099  \n",
      "<<<iteration:[660/914] - total_loss: 55.5969  \n",
      "<<<iteration:[680/914] - total_loss: 55.6001  \n",
      "<<<iteration:[700/914] - total_loss: 55.6337  \n",
      "<<<iteration:[720/914] - total_loss: 55.6017  \n",
      "<<<iteration:[740/914] - total_loss: 55.5882  \n",
      "<<<iteration:[760/914] - total_loss: 55.5436  \n",
      "<<<iteration:[780/914] - total_loss: 55.5616  \n",
      "<<<iteration:[800/914] - total_loss: 55.5880  \n",
      "<<<iteration:[820/914] - total_loss: 55.6105  \n",
      "<<<iteration:[840/914] - total_loss: 55.6381  \n",
      "<<<iteration:[860/914] - total_loss: 55.5643  \n",
      "<<<iteration:[880/914] - total_loss: 55.5759  \n",
      "<<<iteration:[900/914] - total_loss: 55.5638  \n",
      "\n",
      "epoch:33/100 - Train Loss: 55.5873, Val Loss: 57.6899\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.3351  \n",
      "<<<iteration:[40/914] - total_loss: 55.5729  \n",
      "<<<iteration:[60/914] - total_loss: 55.5831  \n",
      "<<<iteration:[80/914] - total_loss: 55.5389  \n",
      "<<<iteration:[100/914] - total_loss: 55.6097  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/914] - total_loss: 55.5839  \n",
      "<<<iteration:[140/914] - total_loss: 55.6268  \n",
      "<<<iteration:[160/914] - total_loss: 55.5480  \n",
      "<<<iteration:[180/914] - total_loss: 55.5677  \n",
      "<<<iteration:[200/914] - total_loss: 55.5191  \n",
      "<<<iteration:[220/914] - total_loss: 55.5489  \n",
      "<<<iteration:[240/914] - total_loss: 55.5369  \n",
      "<<<iteration:[260/914] - total_loss: 55.5575  \n",
      "<<<iteration:[280/914] - total_loss: 55.5549  \n",
      "<<<iteration:[300/914] - total_loss: 55.5640  \n",
      "<<<iteration:[320/914] - total_loss: 55.5653  \n",
      "<<<iteration:[340/914] - total_loss: 55.5452  \n",
      "<<<iteration:[360/914] - total_loss: 55.5687  \n",
      "<<<iteration:[380/914] - total_loss: 55.6047  \n",
      "<<<iteration:[400/914] - total_loss: 55.5332  \n",
      "<<<iteration:[420/914] - total_loss: 55.5589  \n",
      "<<<iteration:[440/914] - total_loss: 55.5692  \n",
      "<<<iteration:[460/914] - total_loss: 55.5234  \n",
      "<<<iteration:[480/914] - total_loss: 55.5621  \n",
      "<<<iteration:[500/914] - total_loss: 55.5446  \n",
      "<<<iteration:[520/914] - total_loss: 55.5444  \n",
      "<<<iteration:[540/914] - total_loss: 55.5829  \n",
      "<<<iteration:[560/914] - total_loss: 55.5653  \n",
      "<<<iteration:[580/914] - total_loss: 55.5759  \n",
      "<<<iteration:[600/914] - total_loss: 55.5416  \n",
      "<<<iteration:[620/914] - total_loss: 55.5530  \n",
      "<<<iteration:[640/914] - total_loss: 55.6035  \n",
      "<<<iteration:[660/914] - total_loss: 55.5669  \n",
      "<<<iteration:[680/914] - total_loss: 55.5871  \n",
      "<<<iteration:[700/914] - total_loss: 55.5357  \n",
      "<<<iteration:[720/914] - total_loss: 55.5676  \n",
      "<<<iteration:[740/914] - total_loss: 55.5944  \n",
      "<<<iteration:[760/914] - total_loss: 55.5779  \n",
      "<<<iteration:[780/914] - total_loss: 55.5559  \n",
      "<<<iteration:[800/914] - total_loss: 55.5857  \n",
      "<<<iteration:[820/914] - total_loss: 55.5849  \n",
      "<<<iteration:[840/914] - total_loss: 55.5754  \n",
      "<<<iteration:[860/914] - total_loss: 55.5400  \n",
      "<<<iteration:[880/914] - total_loss: 55.5802  \n",
      "<<<iteration:[900/914] - total_loss: 55.5600  \n",
      "\n",
      "epoch:34/100 - Train Loss: 55.5643, Val Loss: 57.6625\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2990  \n",
      "<<<iteration:[40/914] - total_loss: 55.5770  \n",
      "<<<iteration:[60/914] - total_loss: 55.5529  \n",
      "<<<iteration:[80/914] - total_loss: 55.5541  \n",
      "<<<iteration:[100/914] - total_loss: 55.5518  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/914] - total_loss: 55.5406  \n",
      "<<<iteration:[140/914] - total_loss: 55.4797  \n",
      "<<<iteration:[160/914] - total_loss: 55.5517  \n",
      "<<<iteration:[180/914] - total_loss: 55.5135  \n",
      "<<<iteration:[200/914] - total_loss: 55.5549  \n",
      "<<<iteration:[220/914] - total_loss: 55.5409  \n",
      "<<<iteration:[240/914] - total_loss: 55.5332  \n",
      "<<<iteration:[260/914] - total_loss: 55.5453  \n",
      "<<<iteration:[280/914] - total_loss: 55.5149  \n",
      "<<<iteration:[300/914] - total_loss: 55.5354  \n",
      "<<<iteration:[320/914] - total_loss: 55.5479  \n",
      "<<<iteration:[340/914] - total_loss: 55.5490  \n",
      "<<<iteration:[360/914] - total_loss: 55.5400  \n",
      "<<<iteration:[380/914] - total_loss: 55.5559  \n",
      "<<<iteration:[400/914] - total_loss: 55.5175  \n",
      "<<<iteration:[420/914] - total_loss: 55.5502  \n",
      "<<<iteration:[440/914] - total_loss: 55.5614  \n",
      "<<<iteration:[460/914] - total_loss: 55.5389  \n",
      "<<<iteration:[480/914] - total_loss: 55.5285  \n",
      "<<<iteration:[500/914] - total_loss: 55.5258  \n",
      "<<<iteration:[520/914] - total_loss: 55.5529  \n",
      "<<<iteration:[540/914] - total_loss: 55.5440  \n",
      "<<<iteration:[560/914] - total_loss: 55.5349  \n",
      "<<<iteration:[580/914] - total_loss: 55.5218  \n",
      "<<<iteration:[600/914] - total_loss: 55.5606  \n",
      "<<<iteration:[620/914] - total_loss: 55.5217  \n",
      "<<<iteration:[640/914] - total_loss: 55.5510  \n",
      "<<<iteration:[660/914] - total_loss: 55.5583  \n",
      "<<<iteration:[680/914] - total_loss: 55.5386  \n",
      "<<<iteration:[700/914] - total_loss: 55.5702  \n",
      "<<<iteration:[720/914] - total_loss: 55.5519  \n",
      "<<<iteration:[740/914] - total_loss: 55.5462  \n",
      "<<<iteration:[760/914] - total_loss: 55.5442  \n",
      "<<<iteration:[780/914] - total_loss: 55.5644  \n",
      "<<<iteration:[800/914] - total_loss: 55.5845  \n",
      "<<<iteration:[820/914] - total_loss: 55.5719  \n",
      "<<<iteration:[840/914] - total_loss: 55.6232  \n",
      "<<<iteration:[860/914] - total_loss: 55.5841  \n",
      "<<<iteration:[880/914] - total_loss: 55.5754  \n",
      "<<<iteration:[900/914] - total_loss: 55.5896  \n",
      "\n",
      "epoch:35/100 - Train Loss: 55.5482, Val Loss: 57.6547\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2872  \n",
      "<<<iteration:[40/914] - total_loss: 55.5402  \n",
      "<<<iteration:[60/914] - total_loss: 55.4883  \n",
      "<<<iteration:[80/914] - total_loss: 55.5502  \n",
      "<<<iteration:[100/914] - total_loss: 55.5155  \n",
      "<<<iteration:[120/914] - total_loss: 55.5505  \n",
      "<<<iteration:[140/914] - total_loss: 55.5191  \n",
      "<<<iteration:[160/914] - total_loss: 55.5058  \n",
      "<<<iteration:[180/914] - total_loss: 55.5201  \n",
      "<<<iteration:[200/914] - total_loss: 55.5431  \n",
      "<<<iteration:[220/914] - total_loss: 55.5150  \n",
      "<<<iteration:[240/914] - total_loss: 55.5009  \n",
      "<<<iteration:[260/914] - total_loss: 55.5531  \n",
      "<<<iteration:[280/914] - total_loss: 55.5190  \n",
      "<<<iteration:[300/914] - total_loss: 55.5348  \n",
      "<<<iteration:[320/914] - total_loss: 55.5425  \n",
      "<<<iteration:[340/914] - total_loss: 55.5336  \n",
      "<<<iteration:[360/914] - total_loss: 55.5109  \n",
      "<<<iteration:[380/914] - total_loss: 55.5354  \n",
      "<<<iteration:[400/914] - total_loss: 55.4910  \n",
      "<<<iteration:[420/914] - total_loss: 55.5435  \n",
      "<<<iteration:[440/914] - total_loss: 55.5836  \n",
      "<<<iteration:[460/914] - total_loss: 55.5880  \n",
      "<<<iteration:[480/914] - total_loss: 55.5522  \n",
      "<<<iteration:[500/914] - total_loss: 55.5682  \n",
      "<<<iteration:[520/914] - total_loss: 55.5437  \n",
      "<<<iteration:[540/914] - total_loss: 55.5639  \n",
      "<<<iteration:[560/914] - total_loss: 55.5700  \n",
      "<<<iteration:[580/914] - total_loss: 55.5693  \n",
      "<<<iteration:[600/914] - total_loss: 55.5715  \n",
      "<<<iteration:[620/914] - total_loss: 55.5452  \n",
      "<<<iteration:[640/914] - total_loss: 55.5452  \n",
      "<<<iteration:[660/914] - total_loss: 55.5282  \n",
      "<<<iteration:[680/914] - total_loss: 55.5686  \n",
      "<<<iteration:[700/914] - total_loss: 55.5130  \n",
      "<<<iteration:[720/914] - total_loss: 55.5501  \n",
      "<<<iteration:[740/914] - total_loss: 55.5111  \n",
      "<<<iteration:[760/914] - total_loss: 55.5396  \n",
      "<<<iteration:[780/914] - total_loss: 55.5415  \n",
      "<<<iteration:[800/914] - total_loss: 55.5315  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[820/914] - total_loss: 55.5404  \n",
      "<<<iteration:[840/914] - total_loss: 55.5490  \n",
      "<<<iteration:[860/914] - total_loss: 55.5475  \n",
      "<<<iteration:[880/914] - total_loss: 55.5521  \n",
      "<<<iteration:[900/914] - total_loss: 55.5279  \n",
      "\n",
      "epoch:36/100 - Train Loss: 55.5380, Val Loss: 57.7085\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2565  \n",
      "<<<iteration:[40/914] - total_loss: 55.4944  \n",
      "<<<iteration:[60/914] - total_loss: 55.4947  \n",
      "<<<iteration:[80/914] - total_loss: 55.5148  \n",
      "<<<iteration:[100/914] - total_loss: 55.5158  \n",
      "<<<iteration:[120/914] - total_loss: 55.5226  \n",
      "<<<iteration:[140/914] - total_loss: 55.4923  \n",
      "<<<iteration:[160/914] - total_loss: 55.5354  \n",
      "<<<iteration:[180/914] - total_loss: 55.5114  \n",
      "<<<iteration:[200/914] - total_loss: 55.4943  \n",
      "<<<iteration:[220/914] - total_loss: 55.5608  \n",
      "<<<iteration:[240/914] - total_loss: 55.4995  \n",
      "<<<iteration:[260/914] - total_loss: 55.5292  \n",
      "<<<iteration:[280/914] - total_loss: 55.5648  \n",
      "<<<iteration:[300/914] - total_loss: 55.4795  \n",
      "<<<iteration:[320/914] - total_loss: 55.5294  \n",
      "<<<iteration:[340/914] - total_loss: 55.5306  \n",
      "<<<iteration:[360/914] - total_loss: 55.5032  \n",
      "<<<iteration:[380/914] - total_loss: 55.5204  \n",
      "<<<iteration:[400/914] - total_loss: 55.5040  \n",
      "<<<iteration:[420/914] - total_loss: 55.5156  \n",
      "<<<iteration:[440/914] - total_loss: 55.5156  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[460/914] - total_loss: 55.5402  \n",
      "<<<iteration:[480/914] - total_loss: 55.5291  \n",
      "<<<iteration:[500/914] - total_loss: 55.5177  \n",
      "<<<iteration:[520/914] - total_loss: 55.5600  \n",
      "<<<iteration:[540/914] - total_loss: 55.5241  \n",
      "<<<iteration:[560/914] - total_loss: 55.5402  \n",
      "<<<iteration:[580/914] - total_loss: 55.5391  \n",
      "<<<iteration:[600/914] - total_loss: 55.5037  \n",
      "<<<iteration:[620/914] - total_loss: 55.5054  \n",
      "<<<iteration:[640/914] - total_loss: 55.5153  \n",
      "<<<iteration:[660/914] - total_loss: 55.5348  \n",
      "<<<iteration:[680/914] - total_loss: 55.5127  \n",
      "<<<iteration:[700/914] - total_loss: 55.5240  \n",
      "<<<iteration:[720/914] - total_loss: 55.5345  \n",
      "<<<iteration:[740/914] - total_loss: 55.5339  \n",
      "<<<iteration:[760/914] - total_loss: 55.4953  \n",
      "<<<iteration:[780/914] - total_loss: 55.5398  \n",
      "<<<iteration:[800/914] - total_loss: 55.5169  \n",
      "<<<iteration:[820/914] - total_loss: 55.5341  \n",
      "<<<iteration:[840/914] - total_loss: 55.5231  \n",
      "<<<iteration:[860/914] - total_loss: 55.4872  \n",
      "<<<iteration:[880/914] - total_loss: 55.5347  \n",
      "<<<iteration:[900/914] - total_loss: 55.5245  \n",
      "\n",
      "epoch:37/100 - Train Loss: 55.5193, Val Loss: 57.6886\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2900  \n",
      "<<<iteration:[40/914] - total_loss: 55.4861  \n",
      "<<<iteration:[60/914] - total_loss: 55.5474  \n",
      "<<<iteration:[80/914] - total_loss: 55.5109  \n",
      "<<<iteration:[100/914] - total_loss: 55.5207  \n",
      "<<<iteration:[120/914] - total_loss: 55.4922  \n",
      "<<<iteration:[140/914] - total_loss: 55.4692  \n",
      "<<<iteration:[160/914] - total_loss: 55.4517  \n",
      "<<<iteration:[180/914] - total_loss: 55.4961  \n",
      "<<<iteration:[200/914] - total_loss: 55.4730  \n",
      "<<<iteration:[220/914] - total_loss: 55.4777  \n",
      "<<<iteration:[240/914] - total_loss: 55.5062  \n",
      "<<<iteration:[260/914] - total_loss: 55.4965  \n",
      "<<<iteration:[280/914] - total_loss: 55.4589  \n",
      "<<<iteration:[300/914] - total_loss: 55.5075  \n",
      "<<<iteration:[320/914] - total_loss: 55.4821  \n",
      "<<<iteration:[340/914] - total_loss: 55.5297  \n",
      "<<<iteration:[360/914] - total_loss: 55.5238  \n",
      "<<<iteration:[380/914] - total_loss: 55.5231  \n",
      "<<<iteration:[400/914] - total_loss: 55.5058  \n",
      "<<<iteration:[420/914] - total_loss: 55.4808  \n",
      "<<<iteration:[440/914] - total_loss: 55.5048  \n",
      "<<<iteration:[460/914] - total_loss: 55.5132  \n",
      "<<<iteration:[480/914] - total_loss: 55.5256  \n",
      "<<<iteration:[500/914] - total_loss: 55.5125  \n",
      "<<<iteration:[520/914] - total_loss: 55.4683  \n",
      "<<<iteration:[540/914] - total_loss: 55.5363  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[560/914] - total_loss: 55.5130  \n",
      "<<<iteration:[580/914] - total_loss: 55.5295  \n",
      "<<<iteration:[600/914] - total_loss: 55.5238  \n",
      "<<<iteration:[620/914] - total_loss: 55.5003  \n",
      "<<<iteration:[640/914] - total_loss: 55.5272  \n",
      "<<<iteration:[660/914] - total_loss: 55.5766  \n",
      "<<<iteration:[680/914] - total_loss: 55.4830  \n",
      "<<<iteration:[700/914] - total_loss: 55.5179  \n",
      "<<<iteration:[720/914] - total_loss: 55.5781  \n",
      "<<<iteration:[740/914] - total_loss: 55.4711  \n",
      "<<<iteration:[760/914] - total_loss: 55.4874  \n",
      "<<<iteration:[780/914] - total_loss: 55.5504  \n",
      "<<<iteration:[800/914] - total_loss: 55.5538  \n",
      "<<<iteration:[820/914] - total_loss: 55.5444  \n",
      "<<<iteration:[840/914] - total_loss: 55.4783  \n",
      "<<<iteration:[860/914] - total_loss: 55.5175  \n",
      "<<<iteration:[880/914] - total_loss: 55.5459  \n",
      "<<<iteration:[900/914] - total_loss: 55.5491  \n",
      "\n",
      "epoch:38/100 - Train Loss: 55.5103, Val Loss: 57.7035\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2923  \n",
      "<<<iteration:[40/914] - total_loss: 55.4817  \n",
      "<<<iteration:[60/914] - total_loss: 55.4810  \n",
      "<<<iteration:[80/914] - total_loss: 55.4504  \n",
      "<<<iteration:[100/914] - total_loss: 55.5172  \n",
      "<<<iteration:[120/914] - total_loss: 55.4926  \n",
      "<<<iteration:[140/914] - total_loss: 55.5322  \n",
      "<<<iteration:[160/914] - total_loss: 55.5595  \n",
      "<<<iteration:[180/914] - total_loss: 55.5139  \n",
      "<<<iteration:[200/914] - total_loss: 55.4846  \n",
      "<<<iteration:[220/914] - total_loss: 55.4943  \n",
      "<<<iteration:[240/914] - total_loss: 55.4700  \n",
      "<<<iteration:[260/914] - total_loss: 55.4873  \n",
      "<<<iteration:[280/914] - total_loss: 55.4891  \n",
      "<<<iteration:[300/914] - total_loss: 55.4978  \n",
      "<<<iteration:[320/914] - total_loss: 55.4794  \n",
      "<<<iteration:[340/914] - total_loss: 55.4705  \n",
      "<<<iteration:[360/914] - total_loss: 55.4686  \n",
      "<<<iteration:[380/914] - total_loss: 55.4711  \n",
      "<<<iteration:[400/914] - total_loss: 55.4958  \n",
      "<<<iteration:[420/914] - total_loss: 55.5101  \n",
      "<<<iteration:[440/914] - total_loss: 55.4778  \n",
      "<<<iteration:[460/914] - total_loss: 55.4769  \n",
      "<<<iteration:[480/914] - total_loss: 55.4779  \n",
      "<<<iteration:[500/914] - total_loss: 55.4981  \n",
      "<<<iteration:[520/914] - total_loss: 55.5297  \n",
      "<<<iteration:[540/914] - total_loss: 55.5160  \n",
      "<<<iteration:[560/914] - total_loss: 55.5245  \n",
      "<<<iteration:[580/914] - total_loss: 55.4856  \n",
      "<<<iteration:[600/914] - total_loss: 55.5056  \n",
      "<<<iteration:[620/914] - total_loss: 55.4598  \n",
      "<<<iteration:[640/914] - total_loss: 55.4950  \n",
      "<<<iteration:[660/914] - total_loss: 55.5281  \n",
      "<<<iteration:[680/914] - total_loss: 55.5323  \n",
      "<<<iteration:[700/914] - total_loss: 55.5037  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[720/914] - total_loss: 55.4727  \n",
      "<<<iteration:[740/914] - total_loss: 55.5095  \n",
      "<<<iteration:[760/914] - total_loss: 55.5195  \n",
      "<<<iteration:[780/914] - total_loss: 55.4808  \n",
      "<<<iteration:[800/914] - total_loss: 55.5163  \n",
      "<<<iteration:[820/914] - total_loss: 55.4624  \n",
      "<<<iteration:[840/914] - total_loss: 55.4963  \n",
      "<<<iteration:[860/914] - total_loss: 55.5062  \n",
      "<<<iteration:[880/914] - total_loss: 55.4856  \n",
      "<<<iteration:[900/914] - total_loss: 55.4979  \n",
      "\n",
      "epoch:39/100 - Train Loss: 55.4960, Val Loss: 57.6650\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2600  \n",
      "<<<iteration:[40/914] - total_loss: 55.4709  \n",
      "<<<iteration:[60/914] - total_loss: 55.4847  \n",
      "<<<iteration:[80/914] - total_loss: 55.4342  \n",
      "<<<iteration:[100/914] - total_loss: 55.4519  \n",
      "<<<iteration:[120/914] - total_loss: 55.4198  \n",
      "<<<iteration:[140/914] - total_loss: 55.4827  \n",
      "<<<iteration:[160/914] - total_loss: 55.4525  \n",
      "<<<iteration:[180/914] - total_loss: 55.4529  \n",
      "<<<iteration:[200/914] - total_loss: 55.4796  \n",
      "<<<iteration:[220/914] - total_loss: 55.4849  \n",
      "<<<iteration:[240/914] - total_loss: 55.4967  \n",
      "<<<iteration:[260/914] - total_loss: 55.4750  \n",
      "<<<iteration:[280/914] - total_loss: 55.4385  \n",
      "<<<iteration:[300/914] - total_loss: 55.4597  \n",
      "<<<iteration:[320/914] - total_loss: 55.4620  \n",
      "<<<iteration:[340/914] - total_loss: 55.4676  \n",
      "<<<iteration:[360/914] - total_loss: 55.4933  \n",
      "<<<iteration:[380/914] - total_loss: 55.4816  \n",
      "<<<iteration:[400/914] - total_loss: 55.4618  \n",
      "<<<iteration:[420/914] - total_loss: 55.4630  \n",
      "<<<iteration:[440/914] - total_loss: 55.4466  \n",
      "<<<iteration:[460/914] - total_loss: 55.4301  \n",
      "<<<iteration:[480/914] - total_loss: 55.4640  \n",
      "<<<iteration:[500/914] - total_loss: 55.4734  \n",
      "<<<iteration:[520/914] - total_loss: 55.4509  \n",
      "<<<iteration:[540/914] - total_loss: 55.4574  \n",
      "<<<iteration:[560/914] - total_loss: 55.4458  \n",
      "<<<iteration:[580/914] - total_loss: 55.4537  \n",
      "<<<iteration:[600/914] - total_loss: 55.4908  \n",
      "<<<iteration:[620/914] - total_loss: 55.4570  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[640/914] - total_loss: 55.5113  \n",
      "<<<iteration:[660/914] - total_loss: 55.4601  \n",
      "<<<iteration:[680/914] - total_loss: 55.4843  \n",
      "<<<iteration:[700/914] - total_loss: 55.4733  \n",
      "<<<iteration:[720/914] - total_loss: 55.5168  \n",
      "<<<iteration:[740/914] - total_loss: 55.4699  \n",
      "<<<iteration:[760/914] - total_loss: 55.4884  \n",
      "<<<iteration:[780/914] - total_loss: 55.5221  \n",
      "<<<iteration:[800/914] - total_loss: 55.4727  \n",
      "<<<iteration:[820/914] - total_loss: 55.5212  \n",
      "<<<iteration:[840/914] - total_loss: 55.4915  \n",
      "<<<iteration:[860/914] - total_loss: 55.4683  \n",
      "<<<iteration:[880/914] - total_loss: 55.4682  \n",
      "<<<iteration:[900/914] - total_loss: 55.5431  \n",
      "\n",
      "epoch:40/100 - Train Loss: 55.4725, Val Loss: 57.6806\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2739  \n",
      "<<<iteration:[40/914] - total_loss: 55.4872  \n",
      "<<<iteration:[60/914] - total_loss: 55.4595  \n",
      "<<<iteration:[80/914] - total_loss: 55.4577  \n",
      "<<<iteration:[100/914] - total_loss: 55.4281  \n",
      "<<<iteration:[120/914] - total_loss: 55.4527  \n",
      "<<<iteration:[140/914] - total_loss: 55.4720  \n",
      "<<<iteration:[160/914] - total_loss: 55.5009  \n",
      "<<<iteration:[180/914] - total_loss: 55.4522  \n",
      "<<<iteration:[200/914] - total_loss: 55.4777  \n",
      "<<<iteration:[220/914] - total_loss: 55.4580  \n",
      "<<<iteration:[240/914] - total_loss: 55.4260  \n",
      "<<<iteration:[260/914] - total_loss: 55.4438  \n",
      "<<<iteration:[280/914] - total_loss: 55.4332  \n",
      "<<<iteration:[300/914] - total_loss: 55.4896  \n",
      "<<<iteration:[320/914] - total_loss: 55.4586  \n",
      "<<<iteration:[340/914] - total_loss: 55.4548  \n",
      "<<<iteration:[360/914] - total_loss: 55.4642  \n",
      "<<<iteration:[380/914] - total_loss: 55.4483  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[400/914] - total_loss: 55.4423  \n",
      "<<<iteration:[420/914] - total_loss: 55.4465  \n",
      "<<<iteration:[440/914] - total_loss: 55.4429  \n",
      "<<<iteration:[460/914] - total_loss: 55.4660  \n",
      "<<<iteration:[480/914] - total_loss: 55.4395  \n",
      "<<<iteration:[500/914] - total_loss: 55.4720  \n",
      "<<<iteration:[520/914] - total_loss: 55.4355  \n",
      "<<<iteration:[540/914] - total_loss: 55.4791  \n",
      "<<<iteration:[560/914] - total_loss: 55.4800  \n",
      "<<<iteration:[580/914] - total_loss: 55.4407  \n",
      "<<<iteration:[600/914] - total_loss: 55.4822  \n",
      "<<<iteration:[620/914] - total_loss: 55.4873  \n",
      "<<<iteration:[640/914] - total_loss: 55.5050  \n",
      "<<<iteration:[660/914] - total_loss: 55.4542  \n",
      "<<<iteration:[680/914] - total_loss: 55.4675  \n",
      "<<<iteration:[700/914] - total_loss: 55.4323  \n",
      "<<<iteration:[720/914] - total_loss: 55.4609  \n",
      "<<<iteration:[740/914] - total_loss: 55.5023  \n",
      "<<<iteration:[760/914] - total_loss: 55.4919  \n",
      "<<<iteration:[780/914] - total_loss: 55.4565  \n",
      "<<<iteration:[800/914] - total_loss: 55.4729  \n",
      "<<<iteration:[820/914] - total_loss: 55.4523  \n",
      "<<<iteration:[840/914] - total_loss: 55.4530  \n",
      "<<<iteration:[860/914] - total_loss: 55.4392  \n",
      "<<<iteration:[880/914] - total_loss: 55.4617  \n",
      "<<<iteration:[900/914] - total_loss: 55.4695  \n",
      "\n",
      "epoch:41/100 - Train Loss: 55.4627, Val Loss: 57.6695\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2305  \n",
      "<<<iteration:[40/914] - total_loss: 55.4479  \n",
      "<<<iteration:[60/914] - total_loss: 55.4729  \n",
      "<<<iteration:[80/914] - total_loss: 55.4454  \n",
      "<<<iteration:[100/914] - total_loss: 55.4126  \n",
      "<<<iteration:[120/914] - total_loss: 55.4719  \n",
      "<<<iteration:[140/914] - total_loss: 55.4528  \n",
      "<<<iteration:[160/914] - total_loss: 55.4602  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/914] - total_loss: 55.3997  \n",
      "<<<iteration:[200/914] - total_loss: 55.4330  \n",
      "<<<iteration:[220/914] - total_loss: 55.3901  \n",
      "<<<iteration:[240/914] - total_loss: 55.4185  \n",
      "<<<iteration:[260/914] - total_loss: 55.4149  \n",
      "<<<iteration:[280/914] - total_loss: 55.4045  \n",
      "<<<iteration:[300/914] - total_loss: 55.4370  \n",
      "<<<iteration:[320/914] - total_loss: 55.4425  \n",
      "<<<iteration:[340/914] - total_loss: 55.4560  \n",
      "<<<iteration:[360/914] - total_loss: 55.4980  \n",
      "<<<iteration:[380/914] - total_loss: 55.4742  \n",
      "<<<iteration:[400/914] - total_loss: 55.4417  \n",
      "<<<iteration:[420/914] - total_loss: 55.4773  \n",
      "<<<iteration:[440/914] - total_loss: 55.4417  \n",
      "<<<iteration:[460/914] - total_loss: 55.4621  \n",
      "<<<iteration:[480/914] - total_loss: 55.4619  \n",
      "<<<iteration:[500/914] - total_loss: 55.4461  \n",
      "<<<iteration:[520/914] - total_loss: 55.4552  \n",
      "<<<iteration:[540/914] - total_loss: 55.4691  \n",
      "<<<iteration:[560/914] - total_loss: 55.4353  \n",
      "<<<iteration:[580/914] - total_loss: 55.4377  \n",
      "<<<iteration:[600/914] - total_loss: 55.4565  \n",
      "<<<iteration:[620/914] - total_loss: 55.4377  \n",
      "<<<iteration:[640/914] - total_loss: 55.4477  \n",
      "<<<iteration:[660/914] - total_loss: 55.4651  \n",
      "<<<iteration:[680/914] - total_loss: 55.5075  \n",
      "<<<iteration:[700/914] - total_loss: 55.4759  \n",
      "<<<iteration:[720/914] - total_loss: 55.4918  \n",
      "<<<iteration:[740/914] - total_loss: 55.4060  \n",
      "<<<iteration:[760/914] - total_loss: 55.4710  \n",
      "<<<iteration:[780/914] - total_loss: 55.4561  \n",
      "<<<iteration:[800/914] - total_loss: 55.4450  \n",
      "<<<iteration:[820/914] - total_loss: 55.4570  \n",
      "<<<iteration:[840/914] - total_loss: 55.4887  \n",
      "<<<iteration:[860/914] - total_loss: 55.4697  \n",
      "<<<iteration:[880/914] - total_loss: 55.4500  \n",
      "<<<iteration:[900/914] - total_loss: 55.4746  \n",
      "\n",
      "epoch:42/100 - Train Loss: 55.4514, Val Loss: 57.6654\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.2117  \n",
      "<<<iteration:[40/914] - total_loss: 55.3920  \n",
      "<<<iteration:[60/914] - total_loss: 55.4330  \n",
      "<<<iteration:[80/914] - total_loss: 55.4708  \n",
      "<<<iteration:[100/914] - total_loss: 55.4449  \n",
      "<<<iteration:[120/914] - total_loss: 55.4017  \n",
      "<<<iteration:[140/914] - total_loss: 55.4135  \n",
      "<<<iteration:[160/914] - total_loss: 55.4216  \n",
      "<<<iteration:[180/914] - total_loss: 55.4170  \n",
      "<<<iteration:[200/914] - total_loss: 55.4354  \n",
      "<<<iteration:[220/914] - total_loss: 55.4291  \n",
      "<<<iteration:[240/914] - total_loss: 55.4507  \n",
      "<<<iteration:[260/914] - total_loss: 55.3980  \n",
      "<<<iteration:[280/914] - total_loss: 55.4426  \n",
      "<<<iteration:[300/914] - total_loss: 55.4417  \n",
      "<<<iteration:[320/914] - total_loss: 55.4053  \n",
      "<<<iteration:[340/914] - total_loss: 55.4071  \n",
      "<<<iteration:[360/914] - total_loss: 55.4394  \n",
      "<<<iteration:[380/914] - total_loss: 55.4279  \n",
      "<<<iteration:[400/914] - total_loss: 55.4541  \n",
      "<<<iteration:[420/914] - total_loss: 55.4209  \n",
      "<<<iteration:[440/914] - total_loss: 55.4194  \n",
      "<<<iteration:[460/914] - total_loss: 55.3981  \n",
      "<<<iteration:[480/914] - total_loss: 55.4324  \n",
      "<<<iteration:[500/914] - total_loss: 55.4219  \n",
      "<<<iteration:[520/914] - total_loss: 55.3760  \n",
      "<<<iteration:[540/914] - total_loss: 55.3912  \n",
      "<<<iteration:[560/914] - total_loss: 55.4004  \n",
      "<<<iteration:[580/914] - total_loss: 55.4119  \n",
      "<<<iteration:[600/914] - total_loss: 55.4281  \n",
      "<<<iteration:[620/914] - total_loss: 55.4102  \n",
      "<<<iteration:[640/914] - total_loss: 55.4485  \n",
      "<<<iteration:[660/914] - total_loss: 55.4586  \n",
      "<<<iteration:[680/914] - total_loss: 55.4594  \n",
      "<<<iteration:[700/914] - total_loss: 55.4404  \n",
      "<<<iteration:[720/914] - total_loss: 55.4430  \n",
      "<<<iteration:[740/914] - total_loss: 55.4502  \n",
      "<<<iteration:[760/914] - total_loss: 55.4397  \n",
      "<<<iteration:[780/914] - total_loss: 55.4564  \n",
      "<<<iteration:[800/914] - total_loss: 55.4610  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[820/914] - total_loss: 55.4612  \n",
      "<<<iteration:[840/914] - total_loss: 55.4513  \n",
      "<<<iteration:[860/914] - total_loss: 55.4531  \n",
      "<<<iteration:[880/914] - total_loss: 55.4351  \n",
      "<<<iteration:[900/914] - total_loss: 55.4475  \n",
      "\n",
      "epoch:43/100 - Train Loss: 55.4308, Val Loss: 57.6773\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.1573  \n",
      "<<<iteration:[40/914] - total_loss: 55.3999  \n",
      "<<<iteration:[60/914] - total_loss: 55.3945  \n",
      "<<<iteration:[80/914] - total_loss: 55.3792  \n",
      "<<<iteration:[100/914] - total_loss: 55.4046  \n",
      "<<<iteration:[120/914] - total_loss: 55.4105  \n",
      "<<<iteration:[140/914] - total_loss: 55.3838  \n",
      "<<<iteration:[160/914] - total_loss: 55.3957  \n",
      "<<<iteration:[180/914] - total_loss: 55.4118  \n",
      "<<<iteration:[200/914] - total_loss: 55.4047  \n",
      "<<<iteration:[220/914] - total_loss: 55.4300  \n",
      "<<<iteration:[240/914] - total_loss: 55.4213  \n",
      "<<<iteration:[260/914] - total_loss: 55.3965  \n",
      "<<<iteration:[280/914] - total_loss: 55.4005  \n",
      "<<<iteration:[300/914] - total_loss: 55.4015  \n",
      "<<<iteration:[320/914] - total_loss: 55.3762  \n",
      "<<<iteration:[340/914] - total_loss: 55.3931  \n",
      "<<<iteration:[360/914] - total_loss: 55.4023  \n",
      "<<<iteration:[380/914] - total_loss: 55.4099  \n",
      "<<<iteration:[400/914] - total_loss: 55.3737  \n",
      "<<<iteration:[420/914] - total_loss: 55.4135  \n",
      "<<<iteration:[440/914] - total_loss: 55.4374  \n",
      "<<<iteration:[460/914] - total_loss: 55.3810  \n",
      "<<<iteration:[480/914] - total_loss: 55.3959  \n",
      "<<<iteration:[500/914] - total_loss: 55.3843  \n",
      "<<<iteration:[520/914] - total_loss: 55.3778  \n",
      "<<<iteration:[540/914] - total_loss: 55.3955  \n",
      "<<<iteration:[560/914] - total_loss: 55.3869  \n",
      "<<<iteration:[580/914] - total_loss: 55.3960  \n",
      "<<<iteration:[600/914] - total_loss: 55.3961  \n",
      "<<<iteration:[620/914] - total_loss: 55.4303  \n",
      "<<<iteration:[640/914] - total_loss: 55.3775  \n",
      "<<<iteration:[660/914] - total_loss: 55.4337  \n",
      "<<<iteration:[680/914] - total_loss: 55.4407  \n",
      "<<<iteration:[700/914] - total_loss: 55.4226  \n",
      "<<<iteration:[720/914] - total_loss: 55.4163  \n",
      "<<<iteration:[740/914] - total_loss: 55.4324  \n",
      "<<<iteration:[760/914] - total_loss: 55.4055  \n",
      "<<<iteration:[780/914] - total_loss: 55.4260  \n",
      "<<<iteration:[800/914] - total_loss: 55.4320  \n",
      "<<<iteration:[820/914] - total_loss: 55.4408  \n",
      "<<<iteration:[840/914] - total_loss: 55.4186  \n",
      "<<<iteration:[860/914] - total_loss: 55.4067  \n",
      "<<<iteration:[880/914] - total_loss: 55.4196  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[900/914] - total_loss: 55.4882  \n",
      "\n",
      "epoch:44/100 - Train Loss: 55.4081, Val Loss: 57.6787\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.1427  \n",
      "<<<iteration:[40/914] - total_loss: 55.3556  \n",
      "<<<iteration:[60/914] - total_loss: 55.3909  \n",
      "<<<iteration:[80/914] - total_loss: 55.3744  \n",
      "<<<iteration:[100/914] - total_loss: 55.3528  \n",
      "<<<iteration:[120/914] - total_loss: 55.3673  \n",
      "<<<iteration:[140/914] - total_loss: 55.3877  \n",
      "<<<iteration:[160/914] - total_loss: 55.3930  \n",
      "<<<iteration:[180/914] - total_loss: 55.4010  \n",
      "<<<iteration:[200/914] - total_loss: 55.4121  \n",
      "<<<iteration:[220/914] - total_loss: 55.3866  \n",
      "<<<iteration:[240/914] - total_loss: 55.3817  \n",
      "<<<iteration:[260/914] - total_loss: 55.3843  \n",
      "<<<iteration:[280/914] - total_loss: 55.3785  \n",
      "<<<iteration:[300/914] - total_loss: 55.3967  \n",
      "<<<iteration:[320/914] - total_loss: 55.4166  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/914] - total_loss: 55.4292  \n",
      "<<<iteration:[360/914] - total_loss: 55.3715  \n",
      "<<<iteration:[380/914] - total_loss: 55.4010  \n",
      "<<<iteration:[400/914] - total_loss: 55.4242  \n",
      "<<<iteration:[420/914] - total_loss: 55.3730  \n",
      "<<<iteration:[440/914] - total_loss: 55.3647  \n",
      "<<<iteration:[460/914] - total_loss: 55.3808  \n",
      "<<<iteration:[480/914] - total_loss: 55.4339  \n",
      "<<<iteration:[500/914] - total_loss: 55.4009  \n",
      "<<<iteration:[520/914] - total_loss: 55.3919  \n",
      "<<<iteration:[540/914] - total_loss: 55.3984  \n",
      "<<<iteration:[560/914] - total_loss: 55.4236  \n",
      "<<<iteration:[580/914] - total_loss: 55.4191  \n",
      "<<<iteration:[600/914] - total_loss: 55.4403  \n",
      "<<<iteration:[620/914] - total_loss: 55.4020  \n",
      "<<<iteration:[640/914] - total_loss: 55.3631  \n",
      "<<<iteration:[660/914] - total_loss: 55.3822  \n",
      "<<<iteration:[680/914] - total_loss: 55.3939  \n",
      "<<<iteration:[700/914] - total_loss: 55.3737  \n",
      "<<<iteration:[720/914] - total_loss: 55.3636  \n",
      "<<<iteration:[740/914] - total_loss: 55.3796  \n",
      "<<<iteration:[760/914] - total_loss: 55.3813  \n",
      "<<<iteration:[780/914] - total_loss: 55.3845  \n",
      "<<<iteration:[800/914] - total_loss: 55.4062  \n",
      "<<<iteration:[820/914] - total_loss: 55.3720  \n",
      "<<<iteration:[840/914] - total_loss: 55.4081  \n",
      "<<<iteration:[860/914] - total_loss: 55.3941  \n",
      "<<<iteration:[880/914] - total_loss: 55.3582  \n",
      "<<<iteration:[900/914] - total_loss: 55.4079  \n",
      "\n",
      "epoch:45/100 - Train Loss: 55.3909, Val Loss: 57.6417\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.1530  \n",
      "<<<iteration:[40/914] - total_loss: 55.3797  \n",
      "<<<iteration:[60/914] - total_loss: 55.3858  \n",
      "<<<iteration:[80/914] - total_loss: 55.3378  \n",
      "<<<iteration:[100/914] - total_loss: 55.3626  \n",
      "<<<iteration:[120/914] - total_loss: 55.3938  \n",
      "<<<iteration:[140/914] - total_loss: 55.3506  \n",
      "<<<iteration:[160/914] - total_loss: 55.3815  \n",
      "<<<iteration:[180/914] - total_loss: 55.3863  \n",
      "<<<iteration:[200/914] - total_loss: 55.3334  \n",
      "<<<iteration:[220/914] - total_loss: 55.3855  \n",
      "<<<iteration:[240/914] - total_loss: 55.3478  \n",
      "<<<iteration:[260/914] - total_loss: 55.3916  \n",
      "<<<iteration:[280/914] - total_loss: 55.3826  \n",
      "<<<iteration:[300/914] - total_loss: 55.3668  \n",
      "<<<iteration:[320/914] - total_loss: 55.3857  \n",
      "<<<iteration:[340/914] - total_loss: 55.3864  \n",
      "<<<iteration:[360/914] - total_loss: 55.4131  \n",
      "<<<iteration:[380/914] - total_loss: 55.3822  \n",
      "<<<iteration:[400/914] - total_loss: 55.3975  \n",
      "<<<iteration:[420/914] - total_loss: 55.3625  \n",
      "<<<iteration:[440/914] - total_loss: 55.4141  \n",
      "<<<iteration:[460/914] - total_loss: 55.3877  \n",
      "<<<iteration:[480/914] - total_loss: 55.3660  \n",
      "<<<iteration:[500/914] - total_loss: 55.3681  \n",
      "<<<iteration:[520/914] - total_loss: 55.3949  \n",
      "<<<iteration:[540/914] - total_loss: 55.4228  \n",
      "<<<iteration:[560/914] - total_loss: 55.3863  \n",
      "<<<iteration:[580/914] - total_loss: 55.4030  \n",
      "<<<iteration:[600/914] - total_loss: 55.3376  \n",
      "<<<iteration:[620/914] - total_loss: 55.3835  \n",
      "<<<iteration:[640/914] - total_loss: 55.4088  \n",
      "<<<iteration:[660/914] - total_loss: 55.4015  \n",
      "<<<iteration:[680/914] - total_loss: 55.3813  \n",
      "<<<iteration:[700/914] - total_loss: 55.3886  \n",
      "<<<iteration:[720/914] - total_loss: 55.3976  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[740/914] - total_loss: 55.4048  \n",
      "<<<iteration:[760/914] - total_loss: 55.3709  \n",
      "<<<iteration:[780/914] - total_loss: 55.3952  \n",
      "<<<iteration:[800/914] - total_loss: 55.3652  \n",
      "<<<iteration:[820/914] - total_loss: 55.4115  \n",
      "<<<iteration:[840/914] - total_loss: 55.3818  \n",
      "<<<iteration:[860/914] - total_loss: 55.4184  \n",
      "<<<iteration:[880/914] - total_loss: 55.3394  \n",
      "<<<iteration:[900/914] - total_loss: 55.3859  \n",
      "\n",
      "epoch:46/100 - Train Loss: 55.3825, Val Loss: 57.6546\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.1517  \n",
      "<<<iteration:[40/914] - total_loss: 55.3381  \n",
      "<<<iteration:[60/914] - total_loss: 55.3436  \n",
      "<<<iteration:[80/914] - total_loss: 55.3617  \n",
      "<<<iteration:[100/914] - total_loss: 55.3927  \n",
      "<<<iteration:[120/914] - total_loss: 55.3794  \n",
      "<<<iteration:[140/914] - total_loss: 55.3729  \n",
      "<<<iteration:[160/914] - total_loss: 55.3743  \n",
      "<<<iteration:[180/914] - total_loss: 55.3509  \n",
      "<<<iteration:[200/914] - total_loss: 55.3832  \n",
      "<<<iteration:[220/914] - total_loss: 55.3937  \n",
      "<<<iteration:[240/914] - total_loss: 55.3965  \n",
      "<<<iteration:[260/914] - total_loss: 55.3676  \n",
      "<<<iteration:[280/914] - total_loss: 55.3581  \n",
      "<<<iteration:[300/914] - total_loss: 55.3883  \n",
      "<<<iteration:[320/914] - total_loss: 55.3671  \n",
      "<<<iteration:[340/914] - total_loss: 55.3672  \n",
      "<<<iteration:[360/914] - total_loss: 55.3415  \n",
      "<<<iteration:[380/914] - total_loss: 55.3385  \n",
      "<<<iteration:[400/914] - total_loss: 55.3322  \n",
      "<<<iteration:[420/914] - total_loss: 55.3593  \n",
      "<<<iteration:[440/914] - total_loss: 55.3572  \n",
      "<<<iteration:[460/914] - total_loss: 55.3567  \n",
      "<<<iteration:[480/914] - total_loss: 55.3928  \n",
      "<<<iteration:[500/914] - total_loss: 55.3306  \n",
      "<<<iteration:[520/914] - total_loss: 55.3884  \n",
      "<<<iteration:[540/914] - total_loss: 55.3813  \n",
      "<<<iteration:[560/914] - total_loss: 55.3365  \n",
      "<<<iteration:[580/914] - total_loss: 55.3586  \n",
      "<<<iteration:[600/914] - total_loss: 55.3894  \n",
      "<<<iteration:[620/914] - total_loss: 55.3563  \n",
      "<<<iteration:[640/914] - total_loss: 55.4012  \n",
      "<<<iteration:[660/914] - total_loss: 55.3719  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[680/914] - total_loss: 55.3754  \n",
      "<<<iteration:[700/914] - total_loss: 55.4210  \n",
      "<<<iteration:[720/914] - total_loss: 55.3892  \n",
      "<<<iteration:[740/914] - total_loss: 55.3536  \n",
      "<<<iteration:[760/914] - total_loss: 55.3864  \n",
      "<<<iteration:[780/914] - total_loss: 55.3639  \n",
      "<<<iteration:[800/914] - total_loss: 55.3649  \n",
      "<<<iteration:[820/914] - total_loss: 55.3668  \n",
      "<<<iteration:[840/914] - total_loss: 55.3590  \n",
      "<<<iteration:[860/914] - total_loss: 55.3667  \n",
      "<<<iteration:[880/914] - total_loss: 55.3619  \n",
      "<<<iteration:[900/914] - total_loss: 55.3421  \n",
      "\n",
      "epoch:47/100 - Train Loss: 55.3678, Val Loss: 57.6526\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.1457  \n",
      "<<<iteration:[40/914] - total_loss: 55.3395  \n",
      "<<<iteration:[60/914] - total_loss: 55.3284  \n",
      "<<<iteration:[80/914] - total_loss: 55.3033  \n",
      "<<<iteration:[100/914] - total_loss: 55.3511  \n",
      "<<<iteration:[120/914] - total_loss: 55.3278  \n",
      "<<<iteration:[140/914] - total_loss: 55.3324  \n",
      "<<<iteration:[160/914] - total_loss: 55.3497  \n",
      "<<<iteration:[180/914] - total_loss: 55.3327  \n",
      "<<<iteration:[200/914] - total_loss: 55.3259  \n",
      "<<<iteration:[220/914] - total_loss: 55.3173  \n",
      "<<<iteration:[240/914] - total_loss: 55.2981  \n",
      "<<<iteration:[260/914] - total_loss: 55.3452  \n",
      "<<<iteration:[280/914] - total_loss: 55.3522  \n",
      "<<<iteration:[300/914] - total_loss: 55.3438  \n",
      "<<<iteration:[320/914] - total_loss: 55.3314  \n",
      "<<<iteration:[340/914] - total_loss: 55.3456  \n",
      "<<<iteration:[360/914] - total_loss: 55.3273  \n",
      "<<<iteration:[380/914] - total_loss: 55.3443  \n",
      "<<<iteration:[400/914] - total_loss: 55.3675  \n",
      "<<<iteration:[420/914] - total_loss: 55.3703  \n",
      "<<<iteration:[440/914] - total_loss: 55.3220  \n",
      "<<<iteration:[460/914] - total_loss: 55.3857  \n",
      "<<<iteration:[480/914] - total_loss: 55.3386  \n",
      "<<<iteration:[500/914] - total_loss: 55.3818  \n",
      "<<<iteration:[520/914] - total_loss: 55.3483  \n",
      "<<<iteration:[540/914] - total_loss: 55.3295  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[560/914] - total_loss: 55.3547  \n",
      "<<<iteration:[580/914] - total_loss: 55.3486  \n",
      "<<<iteration:[600/914] - total_loss: 55.3440  \n",
      "<<<iteration:[620/914] - total_loss: 55.3827  \n",
      "<<<iteration:[640/914] - total_loss: 55.3603  \n",
      "<<<iteration:[660/914] - total_loss: 55.4031  \n",
      "<<<iteration:[680/914] - total_loss: 55.3689  \n",
      "<<<iteration:[700/914] - total_loss: 55.3535  \n",
      "<<<iteration:[720/914] - total_loss: 55.3587  \n",
      "<<<iteration:[740/914] - total_loss: 55.3755  \n",
      "<<<iteration:[760/914] - total_loss: 55.3411  \n",
      "<<<iteration:[780/914] - total_loss: 55.3443  \n",
      "<<<iteration:[800/914] - total_loss: 55.3897  \n",
      "<<<iteration:[820/914] - total_loss: 55.3566  \n",
      "<<<iteration:[840/914] - total_loss: 55.3796  \n",
      "<<<iteration:[860/914] - total_loss: 55.3722  \n",
      "<<<iteration:[880/914] - total_loss: 55.3367  \n",
      "<<<iteration:[900/914] - total_loss: 55.3691  \n",
      "\n",
      "epoch:48/100 - Train Loss: 55.3505, Val Loss: 57.6559\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.0771  \n",
      "<<<iteration:[40/914] - total_loss: 55.3333  \n",
      "<<<iteration:[60/914] - total_loss: 55.3480  \n",
      "<<<iteration:[80/914] - total_loss: 55.3066  \n",
      "<<<iteration:[100/914] - total_loss: 55.2819  \n",
      "<<<iteration:[120/914] - total_loss: 55.2746  \n",
      "<<<iteration:[140/914] - total_loss: 55.3011  \n",
      "<<<iteration:[160/914] - total_loss: 55.3437  \n",
      "<<<iteration:[180/914] - total_loss: 55.3275  \n",
      "<<<iteration:[200/914] - total_loss: 55.3573  \n",
      "<<<iteration:[220/914] - total_loss: 55.3026  \n",
      "<<<iteration:[240/914] - total_loss: 55.3207  \n",
      "<<<iteration:[260/914] - total_loss: 55.3228  \n",
      "<<<iteration:[280/914] - total_loss: 55.2794  \n",
      "<<<iteration:[300/914] - total_loss: 55.3031  \n",
      "<<<iteration:[320/914] - total_loss: 55.3140  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/914] - total_loss: 55.3405  \n",
      "<<<iteration:[360/914] - total_loss: 55.3872  \n",
      "<<<iteration:[380/914] - total_loss: 55.3564  \n",
      "<<<iteration:[400/914] - total_loss: 55.2886  \n",
      "<<<iteration:[420/914] - total_loss: 55.3156  \n",
      "<<<iteration:[440/914] - total_loss: 55.3614  \n",
      "<<<iteration:[460/914] - total_loss: 55.3445  \n",
      "<<<iteration:[480/914] - total_loss: 55.3305  \n",
      "<<<iteration:[500/914] - total_loss: 55.3254  \n",
      "<<<iteration:[520/914] - total_loss: 55.3339  \n",
      "<<<iteration:[540/914] - total_loss: 55.3198  \n",
      "<<<iteration:[560/914] - total_loss: 55.3587  \n",
      "<<<iteration:[580/914] - total_loss: 55.3320  \n",
      "<<<iteration:[600/914] - total_loss: 55.3429  \n",
      "<<<iteration:[620/914] - total_loss: 55.3454  \n",
      "<<<iteration:[640/914] - total_loss: 55.2957  \n",
      "<<<iteration:[660/914] - total_loss: 55.3165  \n",
      "<<<iteration:[680/914] - total_loss: 55.3098  \n",
      "<<<iteration:[700/914] - total_loss: 55.3336  \n",
      "<<<iteration:[720/914] - total_loss: 55.3297  \n",
      "<<<iteration:[740/914] - total_loss: 55.3422  \n",
      "<<<iteration:[760/914] - total_loss: 55.3731  \n",
      "<<<iteration:[780/914] - total_loss: 55.3263  \n",
      "<<<iteration:[800/914] - total_loss: 55.3325  \n",
      "<<<iteration:[820/914] - total_loss: 55.2925  \n",
      "<<<iteration:[840/914] - total_loss: 55.3158  \n",
      "<<<iteration:[860/914] - total_loss: 55.3412  \n",
      "<<<iteration:[880/914] - total_loss: 55.3167  \n",
      "<<<iteration:[900/914] - total_loss: 55.3088  \n",
      "\n",
      "epoch:49/100 - Train Loss: 55.3256, Val Loss: 57.6379\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.0401  \n",
      "<<<iteration:[40/914] - total_loss: 55.2681  \n",
      "<<<iteration:[60/914] - total_loss: 55.3042  \n",
      "<<<iteration:[80/914] - total_loss: 55.3176  \n",
      "<<<iteration:[100/914] - total_loss: 55.3054  \n",
      "<<<iteration:[120/914] - total_loss: 55.3356  \n",
      "<<<iteration:[140/914] - total_loss: 55.3289  \n",
      "<<<iteration:[160/914] - total_loss: 55.3019  \n",
      "<<<iteration:[180/914] - total_loss: 55.2950  \n",
      "<<<iteration:[200/914] - total_loss: 55.3034  \n",
      "<<<iteration:[220/914] - total_loss: 55.3428  \n",
      "<<<iteration:[240/914] - total_loss: 55.3151  \n",
      "<<<iteration:[260/914] - total_loss: 55.3162  \n",
      "<<<iteration:[280/914] - total_loss: 55.2572  \n",
      "<<<iteration:[300/914] - total_loss: 55.2583  \n",
      "<<<iteration:[320/914] - total_loss: 55.2833  \n",
      "<<<iteration:[340/914] - total_loss: 55.2722  \n",
      "<<<iteration:[360/914] - total_loss: 55.3183  \n",
      "<<<iteration:[380/914] - total_loss: 55.3123  \n",
      "<<<iteration:[400/914] - total_loss: 55.3074  \n",
      "<<<iteration:[420/914] - total_loss: 55.2987  \n",
      "<<<iteration:[440/914] - total_loss: 55.3210  \n",
      "<<<iteration:[460/914] - total_loss: 55.3182  \n",
      "<<<iteration:[480/914] - total_loss: 55.2937  \n",
      "<<<iteration:[500/914] - total_loss: 55.2961  \n",
      "<<<iteration:[520/914] - total_loss: 55.2890  \n",
      "<<<iteration:[540/914] - total_loss: 55.3235  \n",
      "<<<iteration:[560/914] - total_loss: 55.3204  \n",
      "<<<iteration:[580/914] - total_loss: 55.2567  \n",
      "<<<iteration:[600/914] - total_loss: 55.2887  \n",
      "<<<iteration:[620/914] - total_loss: 55.3292  \n",
      "<<<iteration:[640/914] - total_loss: 55.3229  \n",
      "<<<iteration:[660/914] - total_loss: 55.3310  \n",
      "<<<iteration:[680/914] - total_loss: 55.3131  \n",
      "<<<iteration:[700/914] - total_loss: 55.3210  \n",
      "<<<iteration:[720/914] - total_loss: 55.3028  \n",
      "<<<iteration:[740/914] - total_loss: 55.3475  \n",
      "<<<iteration:[760/914] - total_loss: 55.3333  \n",
      "<<<iteration:[780/914] - total_loss: 55.3376  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[800/914] - total_loss: 55.3556  \n",
      "<<<iteration:[820/914] - total_loss: 55.3308  \n",
      "<<<iteration:[840/914] - total_loss: 55.2830  \n",
      "<<<iteration:[860/914] - total_loss: 55.3608  \n",
      "<<<iteration:[880/914] - total_loss: 55.3070  \n",
      "<<<iteration:[900/914] - total_loss: 55.3554  \n",
      "\n",
      "epoch:50/100 - Train Loss: 55.3100, Val Loss: 57.6214\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.0034  \n",
      "<<<iteration:[40/914] - total_loss: 55.3020  \n",
      "<<<iteration:[60/914] - total_loss: 55.2528  \n",
      "<<<iteration:[80/914] - total_loss: 55.3091  \n",
      "<<<iteration:[100/914] - total_loss: 55.2951  \n",
      "<<<iteration:[120/914] - total_loss: 55.3353  \n",
      "<<<iteration:[140/914] - total_loss: 55.2818  \n",
      "<<<iteration:[160/914] - total_loss: 55.3120  \n",
      "<<<iteration:[180/914] - total_loss: 55.2631  \n",
      "<<<iteration:[200/914] - total_loss: 55.3106  \n",
      "<<<iteration:[220/914] - total_loss: 55.2653  \n",
      "<<<iteration:[240/914] - total_loss: 55.2458  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/914] - total_loss: 55.2445  \n",
      "<<<iteration:[280/914] - total_loss: 55.3370  \n",
      "<<<iteration:[300/914] - total_loss: 55.3094  \n",
      "<<<iteration:[320/914] - total_loss: 55.2991  \n",
      "<<<iteration:[340/914] - total_loss: 55.3161  \n",
      "<<<iteration:[360/914] - total_loss: 55.2663  \n",
      "<<<iteration:[380/914] - total_loss: 55.3033  \n",
      "<<<iteration:[400/914] - total_loss: 55.2804  \n",
      "<<<iteration:[420/914] - total_loss: 55.2687  \n",
      "<<<iteration:[440/914] - total_loss: 55.2474  \n",
      "<<<iteration:[460/914] - total_loss: 55.2818  \n",
      "<<<iteration:[480/914] - total_loss: 55.3092  \n",
      "<<<iteration:[500/914] - total_loss: 55.3111  \n",
      "<<<iteration:[520/914] - total_loss: 55.3050  \n",
      "<<<iteration:[540/914] - total_loss: 55.2985  \n",
      "<<<iteration:[560/914] - total_loss: 55.2701  \n",
      "<<<iteration:[580/914] - total_loss: 55.2437  \n",
      "<<<iteration:[600/914] - total_loss: 55.3066  \n",
      "<<<iteration:[620/914] - total_loss: 55.2870  \n",
      "<<<iteration:[640/914] - total_loss: 55.3077  \n",
      "<<<iteration:[660/914] - total_loss: 55.3121  \n",
      "<<<iteration:[680/914] - total_loss: 55.3195  \n",
      "<<<iteration:[700/914] - total_loss: 55.2840  \n",
      "<<<iteration:[720/914] - total_loss: 55.2794  \n",
      "<<<iteration:[740/914] - total_loss: 55.2831  \n",
      "<<<iteration:[760/914] - total_loss: 55.2689  \n",
      "<<<iteration:[780/914] - total_loss: 55.2771  \n",
      "<<<iteration:[800/914] - total_loss: 55.3019  \n",
      "<<<iteration:[820/914] - total_loss: 55.3102  \n",
      "<<<iteration:[840/914] - total_loss: 55.2970  \n",
      "<<<iteration:[860/914] - total_loss: 55.3633  \n",
      "<<<iteration:[880/914] - total_loss: 55.2627  \n",
      "<<<iteration:[900/914] - total_loss: 55.2930  \n",
      "\n",
      "epoch:51/100 - Train Loss: 55.2904, Val Loss: 57.6186\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.0423  \n",
      "<<<iteration:[40/914] - total_loss: 55.2476  \n",
      "<<<iteration:[60/914] - total_loss: 55.2891  \n",
      "<<<iteration:[80/914] - total_loss: 55.2450  \n",
      "<<<iteration:[100/914] - total_loss: 55.2582  \n",
      "<<<iteration:[120/914] - total_loss: 55.2769  \n",
      "<<<iteration:[140/914] - total_loss: 55.2782  \n",
      "<<<iteration:[160/914] - total_loss: 55.2501  \n",
      "<<<iteration:[180/914] - total_loss: 55.2523  \n",
      "<<<iteration:[200/914] - total_loss: 55.3105  \n",
      "<<<iteration:[220/914] - total_loss: 55.2663  \n",
      "<<<iteration:[240/914] - total_loss: 55.2736  \n",
      "<<<iteration:[260/914] - total_loss: 55.2544  \n",
      "<<<iteration:[280/914] - total_loss: 55.2395  \n",
      "<<<iteration:[300/914] - total_loss: 55.2867  \n",
      "<<<iteration:[320/914] - total_loss: 55.2628  \n",
      "<<<iteration:[340/914] - total_loss: 55.2385  \n",
      "<<<iteration:[360/914] - total_loss: 55.3393  \n",
      "<<<iteration:[380/914] - total_loss: 55.2752  \n",
      "<<<iteration:[400/914] - total_loss: 55.2622  \n",
      "<<<iteration:[420/914] - total_loss: 55.2776  \n",
      "<<<iteration:[440/914] - total_loss: 55.2950  \n",
      "<<<iteration:[460/914] - total_loss: 55.2757  \n",
      "<<<iteration:[480/914] - total_loss: 55.3428  \n",
      "<<<iteration:[500/914] - total_loss: 55.3144  \n",
      "<<<iteration:[520/914] - total_loss: 55.2800  \n",
      "<<<iteration:[540/914] - total_loss: 55.3093  \n",
      "<<<iteration:[560/914] - total_loss: 55.2728  \n",
      "<<<iteration:[580/914] - total_loss: 55.3097  \n",
      "<<<iteration:[600/914] - total_loss: 55.2731  \n",
      "<<<iteration:[620/914] - total_loss: 55.2480  \n",
      "<<<iteration:[640/914] - total_loss: 55.2485  \n",
      "<<<iteration:[660/914] - total_loss: 55.2924  \n",
      "<<<iteration:[680/914] - total_loss: 55.2387  \n",
      "<<<iteration:[700/914] - total_loss: 55.3293  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[720/914] - total_loss: 55.2687  \n",
      "<<<iteration:[740/914] - total_loss: 55.3151  \n",
      "<<<iteration:[760/914] - total_loss: 55.3359  \n",
      "<<<iteration:[780/914] - total_loss: 55.3170  \n",
      "<<<iteration:[800/914] - total_loss: 55.2565  \n",
      "<<<iteration:[820/914] - total_loss: 55.3165  \n",
      "<<<iteration:[840/914] - total_loss: 55.2691  \n",
      "<<<iteration:[860/914] - total_loss: 55.3073  \n",
      "<<<iteration:[880/914] - total_loss: 55.2841  \n",
      "<<<iteration:[900/914] - total_loss: 55.3118  \n",
      "\n",
      "epoch:52/100 - Train Loss: 55.2820, Val Loss: 57.6436\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 58.0263  \n",
      "<<<iteration:[40/914] - total_loss: 55.2831  \n",
      "<<<iteration:[60/914] - total_loss: 55.3012  \n",
      "<<<iteration:[80/914] - total_loss: 55.2541  \n",
      "<<<iteration:[100/914] - total_loss: 55.2248  \n",
      "<<<iteration:[120/914] - total_loss: 55.2860  \n",
      "<<<iteration:[140/914] - total_loss: 55.2589  \n",
      "<<<iteration:[160/914] - total_loss: 55.2566  \n",
      "<<<iteration:[180/914] - total_loss: 55.2540  \n",
      "<<<iteration:[200/914] - total_loss: 55.2514  \n",
      "<<<iteration:[220/914] - total_loss: 55.2389  \n",
      "<<<iteration:[240/914] - total_loss: 55.2629  \n",
      "<<<iteration:[260/914] - total_loss: 55.2500  \n",
      "<<<iteration:[280/914] - total_loss: 55.2452  \n",
      "<<<iteration:[300/914] - total_loss: 55.2331  \n",
      "<<<iteration:[320/914] - total_loss: 55.2485  \n",
      "<<<iteration:[340/914] - total_loss: 55.2475  \n",
      "<<<iteration:[360/914] - total_loss: 55.2617  \n",
      "<<<iteration:[380/914] - total_loss: 55.2883  \n",
      "<<<iteration:[400/914] - total_loss: 55.2918  \n",
      "<<<iteration:[420/914] - total_loss: 55.2526  \n",
      "<<<iteration:[440/914] - total_loss: 55.2320  \n",
      "<<<iteration:[460/914] - total_loss: 55.2838  \n",
      "<<<iteration:[480/914] - total_loss: 55.2809  \n",
      "<<<iteration:[500/914] - total_loss: 55.2319  \n",
      "<<<iteration:[520/914] - total_loss: 55.2559  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[540/914] - total_loss: 55.2397  \n",
      "<<<iteration:[560/914] - total_loss: 55.2602  \n",
      "<<<iteration:[580/914] - total_loss: 55.2502  \n",
      "<<<iteration:[600/914] - total_loss: 55.2407  \n",
      "<<<iteration:[620/914] - total_loss: 55.2677  \n",
      "<<<iteration:[640/914] - total_loss: 55.2703  \n",
      "<<<iteration:[660/914] - total_loss: 55.2604  \n",
      "<<<iteration:[680/914] - total_loss: 55.2528  \n",
      "<<<iteration:[700/914] - total_loss: 55.2367  \n",
      "<<<iteration:[720/914] - total_loss: 55.2473  \n",
      "<<<iteration:[740/914] - total_loss: 55.2619  \n",
      "<<<iteration:[760/914] - total_loss: 55.2806  \n",
      "<<<iteration:[780/914] - total_loss: 55.3061  \n",
      "<<<iteration:[800/914] - total_loss: 55.2974  \n",
      "<<<iteration:[820/914] - total_loss: 55.2879  \n",
      "<<<iteration:[840/914] - total_loss: 55.2509  \n",
      "<<<iteration:[860/914] - total_loss: 55.2729  \n",
      "<<<iteration:[880/914] - total_loss: 55.2549  \n",
      "<<<iteration:[900/914] - total_loss: 55.2818  \n",
      "\n",
      "epoch:53/100 - Train Loss: 55.2616, Val Loss: 57.6340\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.9813  \n",
      "<<<iteration:[40/914] - total_loss: 55.2589  \n",
      "<<<iteration:[60/914] - total_loss: 55.2301  \n",
      "<<<iteration:[80/914] - total_loss: 55.2259  \n",
      "<<<iteration:[100/914] - total_loss: 55.2048  \n",
      "<<<iteration:[120/914] - total_loss: 55.2573  \n",
      "<<<iteration:[140/914] - total_loss: 55.2132  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/914] - total_loss: 55.2155  \n",
      "<<<iteration:[180/914] - total_loss: 55.2392  \n",
      "<<<iteration:[200/914] - total_loss: 55.2142  \n",
      "<<<iteration:[220/914] - total_loss: 55.1905  \n",
      "<<<iteration:[240/914] - total_loss: 55.2281  \n",
      "<<<iteration:[260/914] - total_loss: 55.2260  \n",
      "<<<iteration:[280/914] - total_loss: 55.2175  \n",
      "<<<iteration:[300/914] - total_loss: 55.2713  \n",
      "<<<iteration:[320/914] - total_loss: 55.2042  \n",
      "<<<iteration:[340/914] - total_loss: 55.2671  \n",
      "<<<iteration:[360/914] - total_loss: 55.2640  \n",
      "<<<iteration:[380/914] - total_loss: 55.2519  \n",
      "<<<iteration:[400/914] - total_loss: 55.2427  \n",
      "<<<iteration:[420/914] - total_loss: 55.2176  \n",
      "<<<iteration:[440/914] - total_loss: 55.2572  \n",
      "<<<iteration:[460/914] - total_loss: 55.2559  \n",
      "<<<iteration:[480/914] - total_loss: 55.2381  \n",
      "<<<iteration:[500/914] - total_loss: 55.2744  \n",
      "<<<iteration:[520/914] - total_loss: 55.2376  \n",
      "<<<iteration:[540/914] - total_loss: 55.2534  \n",
      "<<<iteration:[560/914] - total_loss: 55.2584  \n",
      "<<<iteration:[580/914] - total_loss: 55.2008  \n",
      "<<<iteration:[600/914] - total_loss: 55.2425  \n",
      "<<<iteration:[620/914] - total_loss: 55.2283  \n",
      "<<<iteration:[640/914] - total_loss: 55.2362  \n",
      "<<<iteration:[660/914] - total_loss: 55.2434  \n",
      "<<<iteration:[680/914] - total_loss: 55.2600  \n",
      "<<<iteration:[700/914] - total_loss: 55.2190  \n",
      "<<<iteration:[720/914] - total_loss: 55.2231  \n",
      "<<<iteration:[740/914] - total_loss: 55.2206  \n",
      "<<<iteration:[760/914] - total_loss: 55.2369  \n",
      "<<<iteration:[780/914] - total_loss: 55.2607  \n",
      "<<<iteration:[800/914] - total_loss: 55.2507  \n",
      "<<<iteration:[820/914] - total_loss: 55.2274  \n",
      "<<<iteration:[840/914] - total_loss: 55.2351  \n",
      "<<<iteration:[860/914] - total_loss: 55.2325  \n",
      "<<<iteration:[880/914] - total_loss: 55.2720  \n",
      "<<<iteration:[900/914] - total_loss: 55.2345  \n",
      "\n",
      "epoch:54/100 - Train Loss: 55.2374, Val Loss: 57.5959\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.9702  \n",
      "<<<iteration:[40/914] - total_loss: 55.2070  \n",
      "<<<iteration:[60/914] - total_loss: 55.1995  \n",
      "<<<iteration:[80/914] - total_loss: 55.2363  \n",
      "<<<iteration:[100/914] - total_loss: 55.1968  \n",
      "<<<iteration:[120/914] - total_loss: 55.2071  \n",
      "<<<iteration:[140/914] - total_loss: 55.2223  \n",
      "<<<iteration:[160/914] - total_loss: 55.2430  \n",
      "<<<iteration:[180/914] - total_loss: 55.2356  \n",
      "<<<iteration:[200/914] - total_loss: 55.2422  \n",
      "<<<iteration:[220/914] - total_loss: 55.1973  \n",
      "<<<iteration:[240/914] - total_loss: 55.2114  \n",
      "<<<iteration:[260/914] - total_loss: 55.2083  \n",
      "<<<iteration:[280/914] - total_loss: 55.1726  \n",
      "<<<iteration:[300/914] - total_loss: 55.2221  \n",
      "<<<iteration:[320/914] - total_loss: 55.1988  \n",
      "<<<iteration:[340/914] - total_loss: 55.2195  \n",
      "<<<iteration:[360/914] - total_loss: 55.2261  \n",
      "<<<iteration:[380/914] - total_loss: 55.1941  \n",
      "<<<iteration:[400/914] - total_loss: 55.2465  \n",
      "<<<iteration:[420/914] - total_loss: 55.2301  \n",
      "<<<iteration:[440/914] - total_loss: 55.2368  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[460/914] - total_loss: 55.1778  \n",
      "<<<iteration:[480/914] - total_loss: 55.2083  \n",
      "<<<iteration:[500/914] - total_loss: 55.2406  \n",
      "<<<iteration:[520/914] - total_loss: 55.2222  \n",
      "<<<iteration:[540/914] - total_loss: 55.2233  \n",
      "<<<iteration:[560/914] - total_loss: 55.2400  \n",
      "<<<iteration:[580/914] - total_loss: 55.2226  \n",
      "<<<iteration:[600/914] - total_loss: 55.2276  \n",
      "<<<iteration:[620/914] - total_loss: 55.2389  \n",
      "<<<iteration:[640/914] - total_loss: 55.1909  \n",
      "<<<iteration:[660/914] - total_loss: 55.2390  \n",
      "<<<iteration:[680/914] - total_loss: 55.2321  \n",
      "<<<iteration:[700/914] - total_loss: 55.2314  \n",
      "<<<iteration:[720/914] - total_loss: 55.1796  \n",
      "<<<iteration:[740/914] - total_loss: 55.2091  \n",
      "<<<iteration:[760/914] - total_loss: 55.2325  \n",
      "<<<iteration:[780/914] - total_loss: 55.2218  \n",
      "<<<iteration:[800/914] - total_loss: 55.1732  \n",
      "<<<iteration:[820/914] - total_loss: 55.2183  \n",
      "<<<iteration:[840/914] - total_loss: 55.2439  \n",
      "<<<iteration:[860/914] - total_loss: 55.2010  \n",
      "<<<iteration:[880/914] - total_loss: 55.1820  \n",
      "<<<iteration:[900/914] - total_loss: 55.2341  \n",
      "\n",
      "epoch:55/100 - Train Loss: 55.2174, Val Loss: 57.6229\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.9271  \n",
      "<<<iteration:[40/914] - total_loss: 55.1883  \n",
      "<<<iteration:[60/914] - total_loss: 55.1657  \n",
      "<<<iteration:[80/914] - total_loss: 55.1745  \n",
      "<<<iteration:[100/914] - total_loss: 55.1738  \n",
      "<<<iteration:[120/914] - total_loss: 55.1870  \n",
      "<<<iteration:[140/914] - total_loss: 55.1697  \n",
      "<<<iteration:[160/914] - total_loss: 55.2012  \n",
      "<<<iteration:[180/914] - total_loss: 55.1817  \n",
      "<<<iteration:[200/914] - total_loss: 55.2301  \n",
      "<<<iteration:[220/914] - total_loss: 55.2087  \n",
      "<<<iteration:[240/914] - total_loss: 55.1859  \n",
      "<<<iteration:[260/914] - total_loss: 55.1989  \n",
      "<<<iteration:[280/914] - total_loss: 55.2298  \n",
      "<<<iteration:[300/914] - total_loss: 55.1847  \n",
      "<<<iteration:[320/914] - total_loss: 55.1964  \n",
      "<<<iteration:[340/914] - total_loss: 55.1819  \n",
      "<<<iteration:[360/914] - total_loss: 55.1699  \n",
      "<<<iteration:[380/914] - total_loss: 55.2216  \n",
      "<<<iteration:[400/914] - total_loss: 55.2117  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[420/914] - total_loss: 55.2153  \n",
      "<<<iteration:[440/914] - total_loss: 55.2078  \n",
      "<<<iteration:[460/914] - total_loss: 55.1904  \n",
      "<<<iteration:[480/914] - total_loss: 55.1708  \n",
      "<<<iteration:[500/914] - total_loss: 55.1926  \n",
      "<<<iteration:[520/914] - total_loss: 55.1523  \n",
      "<<<iteration:[540/914] - total_loss: 55.2049  \n",
      "<<<iteration:[560/914] - total_loss: 55.1948  \n",
      "<<<iteration:[580/914] - total_loss: 55.1902  \n",
      "<<<iteration:[600/914] - total_loss: 55.1731  \n",
      "<<<iteration:[620/914] - total_loss: 55.2198  \n",
      "<<<iteration:[640/914] - total_loss: 55.2130  \n",
      "<<<iteration:[660/914] - total_loss: 55.2206  \n",
      "<<<iteration:[680/914] - total_loss: 55.2248  \n",
      "<<<iteration:[700/914] - total_loss: 55.2178  \n",
      "<<<iteration:[720/914] - total_loss: 55.1672  \n",
      "<<<iteration:[740/914] - total_loss: 55.2103  \n",
      "<<<iteration:[760/914] - total_loss: 55.2027  \n",
      "<<<iteration:[780/914] - total_loss: 55.2218  \n",
      "<<<iteration:[800/914] - total_loss: 55.2303  \n",
      "<<<iteration:[820/914] - total_loss: 55.2201  \n",
      "<<<iteration:[840/914] - total_loss: 55.2074  \n",
      "<<<iteration:[860/914] - total_loss: 55.2191  \n",
      "<<<iteration:[880/914] - total_loss: 55.2343  \n",
      "<<<iteration:[900/914] - total_loss: 55.2398  \n",
      "\n",
      "epoch:56/100 - Train Loss: 55.1996, Val Loss: 57.6017\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.9598  \n",
      "<<<iteration:[40/914] - total_loss: 55.1757  \n",
      "<<<iteration:[60/914] - total_loss: 55.1909  \n",
      "<<<iteration:[80/914] - total_loss: 55.2282  \n",
      "<<<iteration:[100/914] - total_loss: 55.1837  \n",
      "<<<iteration:[120/914] - total_loss: 55.1857  \n",
      "<<<iteration:[140/914] - total_loss: 55.1944  \n",
      "<<<iteration:[160/914] - total_loss: 55.1752  \n",
      "<<<iteration:[180/914] - total_loss: 55.1714  \n",
      "<<<iteration:[200/914] - total_loss: 55.1561  \n",
      "<<<iteration:[220/914] - total_loss: 55.1782  \n",
      "<<<iteration:[240/914] - total_loss: 55.1976  \n",
      "<<<iteration:[260/914] - total_loss: 55.1608  \n",
      "<<<iteration:[280/914] - total_loss: 55.1639  \n",
      "<<<iteration:[300/914] - total_loss: 55.1834  \n",
      "<<<iteration:[320/914] - total_loss: 55.1873  \n",
      "<<<iteration:[340/914] - total_loss: 55.2061  \n",
      "<<<iteration:[360/914] - total_loss: 55.1786  \n",
      "<<<iteration:[380/914] - total_loss: 55.1509  \n",
      "<<<iteration:[400/914] - total_loss: 55.1676  \n",
      "<<<iteration:[420/914] - total_loss: 55.1927  \n",
      "<<<iteration:[440/914] - total_loss: 55.1752  \n",
      "<<<iteration:[460/914] - total_loss: 55.2446  \n",
      "<<<iteration:[480/914] - total_loss: 55.1440  \n",
      "<<<iteration:[500/914] - total_loss: 55.2229  \n",
      "<<<iteration:[520/914] - total_loss: 55.1896  \n",
      "<<<iteration:[540/914] - total_loss: 55.1942  \n",
      "<<<iteration:[560/914] - total_loss: 55.1735  \n",
      "<<<iteration:[580/914] - total_loss: 55.1963  \n",
      "<<<iteration:[600/914] - total_loss: 55.1846  \n",
      "<<<iteration:[620/914] - total_loss: 55.1999  \n",
      "<<<iteration:[640/914] - total_loss: 55.2041  \n",
      "<<<iteration:[660/914] - total_loss: 55.2082  \n",
      "<<<iteration:[680/914] - total_loss: 55.1848  \n",
      "<<<iteration:[700/914] - total_loss: 55.1510  \n",
      "<<<iteration:[720/914] - total_loss: 55.1838  \n",
      "<<<iteration:[740/914] - total_loss: 55.1874  \n",
      "<<<iteration:[760/914] - total_loss: 55.1545  \n",
      "<<<iteration:[780/914] - total_loss: 55.1461  \n",
      "<<<iteration:[800/914] - total_loss: 55.1855  \n",
      "<<<iteration:[820/914] - total_loss: 55.1723  \n",
      "<<<iteration:[840/914] - total_loss: 55.1974  \n",
      "<<<iteration:[860/914] - total_loss: 55.1904  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[880/914] - total_loss: 55.2056  \n",
      "<<<iteration:[900/914] - total_loss: 55.1900  \n",
      "\n",
      "epoch:57/100 - Train Loss: 55.1859, Val Loss: 57.6069\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.9306  \n",
      "<<<iteration:[40/914] - total_loss: 55.1715  \n",
      "<<<iteration:[60/914] - total_loss: 55.1578  \n",
      "<<<iteration:[80/914] - total_loss: 55.1424  \n",
      "<<<iteration:[100/914] - total_loss: 55.1479  \n",
      "<<<iteration:[120/914] - total_loss: 55.1468  \n",
      "<<<iteration:[140/914] - total_loss: 55.1767  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/914] - total_loss: 55.1323  \n",
      "<<<iteration:[180/914] - total_loss: 55.1956  \n",
      "<<<iteration:[200/914] - total_loss: 55.1953  \n",
      "<<<iteration:[220/914] - total_loss: 55.1646  \n",
      "<<<iteration:[240/914] - total_loss: 55.1319  \n",
      "<<<iteration:[260/914] - total_loss: 55.1652  \n",
      "<<<iteration:[280/914] - total_loss: 55.1345  \n",
      "<<<iteration:[300/914] - total_loss: 55.1587  \n",
      "<<<iteration:[320/914] - total_loss: 55.1651  \n",
      "<<<iteration:[340/914] - total_loss: 55.1561  \n",
      "<<<iteration:[360/914] - total_loss: 55.1599  \n",
      "<<<iteration:[380/914] - total_loss: 55.1524  \n",
      "<<<iteration:[400/914] - total_loss: 55.1616  \n",
      "<<<iteration:[420/914] - total_loss: 55.1786  \n",
      "<<<iteration:[440/914] - total_loss: 55.1444  \n",
      "<<<iteration:[460/914] - total_loss: 55.1743  \n",
      "<<<iteration:[480/914] - total_loss: 55.1820  \n",
      "<<<iteration:[500/914] - total_loss: 55.1749  \n",
      "<<<iteration:[520/914] - total_loss: 55.1496  \n",
      "<<<iteration:[540/914] - total_loss: 55.1498  \n",
      "<<<iteration:[560/914] - total_loss: 55.1525  \n",
      "<<<iteration:[580/914] - total_loss: 55.1407  \n",
      "<<<iteration:[600/914] - total_loss: 55.1498  \n",
      "<<<iteration:[620/914] - total_loss: 55.1535  \n",
      "<<<iteration:[640/914] - total_loss: 55.1428  \n",
      "<<<iteration:[660/914] - total_loss: 55.2145  \n",
      "<<<iteration:[680/914] - total_loss: 55.1621  \n",
      "<<<iteration:[700/914] - total_loss: 55.1773  \n",
      "<<<iteration:[720/914] - total_loss: 55.1731  \n",
      "<<<iteration:[740/914] - total_loss: 55.1637  \n",
      "<<<iteration:[760/914] - total_loss: 55.1613  \n",
      "<<<iteration:[780/914] - total_loss: 55.1604  \n",
      "<<<iteration:[800/914] - total_loss: 55.1899  \n",
      "<<<iteration:[820/914] - total_loss: 55.1691  \n",
      "<<<iteration:[840/914] - total_loss: 55.1676  \n",
      "<<<iteration:[860/914] - total_loss: 55.1921  \n",
      "<<<iteration:[880/914] - total_loss: 55.1729  \n",
      "<<<iteration:[900/914] - total_loss: 55.1958  \n",
      "\n",
      "epoch:58/100 - Train Loss: 55.1642, Val Loss: 57.5924\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.8979  \n",
      "<<<iteration:[40/914] - total_loss: 55.1180  \n",
      "<<<iteration:[60/914] - total_loss: 55.1711  \n",
      "<<<iteration:[80/914] - total_loss: 55.1641  \n",
      "<<<iteration:[100/914] - total_loss: 55.1086  \n",
      "<<<iteration:[120/914] - total_loss: 55.1762  \n",
      "<<<iteration:[140/914] - total_loss: 55.1398  \n",
      "<<<iteration:[160/914] - total_loss: 55.1204  \n",
      "<<<iteration:[180/914] - total_loss: 55.1471  \n",
      "<<<iteration:[200/914] - total_loss: 55.1398  \n",
      "<<<iteration:[220/914] - total_loss: 55.1433  \n",
      "<<<iteration:[240/914] - total_loss: 55.1491  \n",
      "<<<iteration:[260/914] - total_loss: 55.1331  \n",
      "<<<iteration:[280/914] - total_loss: 55.1025  \n",
      "<<<iteration:[300/914] - total_loss: 55.1392  \n",
      "<<<iteration:[320/914] - total_loss: 55.1228  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/914] - total_loss: 55.1022  \n",
      "<<<iteration:[360/914] - total_loss: 55.1244  \n",
      "<<<iteration:[380/914] - total_loss: 55.1350  \n",
      "<<<iteration:[400/914] - total_loss: 55.1553  \n",
      "<<<iteration:[420/914] - total_loss: 55.1164  \n",
      "<<<iteration:[440/914] - total_loss: 55.1513  \n",
      "<<<iteration:[460/914] - total_loss: 55.1674  \n",
      "<<<iteration:[480/914] - total_loss: 55.1502  \n",
      "<<<iteration:[500/914] - total_loss: 55.1099  \n",
      "<<<iteration:[520/914] - total_loss: 55.1377  \n",
      "<<<iteration:[540/914] - total_loss: 55.1027  \n",
      "<<<iteration:[560/914] - total_loss: 55.1161  \n",
      "<<<iteration:[580/914] - total_loss: 55.1583  \n",
      "<<<iteration:[600/914] - total_loss: 55.1124  \n",
      "<<<iteration:[620/914] - total_loss: 55.1607  \n",
      "<<<iteration:[640/914] - total_loss: 55.1542  \n",
      "<<<iteration:[660/914] - total_loss: 55.1344  \n",
      "<<<iteration:[680/914] - total_loss: 55.1358  \n",
      "<<<iteration:[700/914] - total_loss: 55.1336  \n",
      "<<<iteration:[720/914] - total_loss: 55.1284  \n",
      "<<<iteration:[740/914] - total_loss: 55.1659  \n",
      "<<<iteration:[760/914] - total_loss: 55.1284  \n",
      "<<<iteration:[780/914] - total_loss: 55.1384  \n",
      "<<<iteration:[800/914] - total_loss: 55.1651  \n",
      "<<<iteration:[820/914] - total_loss: 55.1519  \n",
      "<<<iteration:[840/914] - total_loss: 55.1727  \n",
      "<<<iteration:[860/914] - total_loss: 55.1612  \n",
      "<<<iteration:[880/914] - total_loss: 55.1873  \n",
      "<<<iteration:[900/914] - total_loss: 55.1729  \n",
      "\n",
      "epoch:59/100 - Train Loss: 55.1417, Val Loss: 57.6037\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.9065  \n",
      "<<<iteration:[40/914] - total_loss: 55.1126  \n",
      "<<<iteration:[60/914] - total_loss: 55.1263  \n",
      "<<<iteration:[80/914] - total_loss: 55.1256  \n",
      "<<<iteration:[100/914] - total_loss: 55.1043  \n",
      "<<<iteration:[120/914] - total_loss: 55.1170  \n",
      "<<<iteration:[140/914] - total_loss: 55.1022  \n",
      "<<<iteration:[160/914] - total_loss: 55.0971  \n",
      "<<<iteration:[180/914] - total_loss: 55.0934  \n",
      "<<<iteration:[200/914] - total_loss: 55.1467  \n",
      "<<<iteration:[220/914] - total_loss: 55.1405  \n",
      "<<<iteration:[240/914] - total_loss: 55.1203  \n",
      "<<<iteration:[260/914] - total_loss: 55.1580  \n",
      "<<<iteration:[280/914] - total_loss: 55.1355  \n",
      "<<<iteration:[300/914] - total_loss: 55.1590  \n",
      "<<<iteration:[320/914] - total_loss: 55.0959  \n",
      "<<<iteration:[340/914] - total_loss: 55.0948  \n",
      "<<<iteration:[360/914] - total_loss: 55.1247  \n",
      "<<<iteration:[380/914] - total_loss: 55.0989  \n",
      "<<<iteration:[400/914] - total_loss: 55.1502  \n",
      "<<<iteration:[420/914] - total_loss: 55.1366  \n",
      "<<<iteration:[440/914] - total_loss: 55.1562  \n",
      "<<<iteration:[460/914] - total_loss: 55.1210  \n",
      "<<<iteration:[480/914] - total_loss: 55.1360  \n",
      "<<<iteration:[500/914] - total_loss: 55.1040  \n",
      "<<<iteration:[520/914] - total_loss: 55.1618  \n",
      "<<<iteration:[540/914] - total_loss: 55.1091  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[560/914] - total_loss: 55.1075  \n",
      "<<<iteration:[580/914] - total_loss: 55.1488  \n",
      "<<<iteration:[600/914] - total_loss: 55.1176  \n",
      "<<<iteration:[620/914] - total_loss: 55.1245  \n",
      "<<<iteration:[640/914] - total_loss: 55.1237  \n",
      "<<<iteration:[660/914] - total_loss: 55.0987  \n",
      "<<<iteration:[680/914] - total_loss: 55.1196  \n",
      "<<<iteration:[700/914] - total_loss: 55.1133  \n",
      "<<<iteration:[720/914] - total_loss: 55.1306  \n",
      "<<<iteration:[740/914] - total_loss: 55.1428  \n",
      "<<<iteration:[760/914] - total_loss: 55.1581  \n",
      "<<<iteration:[780/914] - total_loss: 55.1493  \n",
      "<<<iteration:[800/914] - total_loss: 55.1633  \n",
      "<<<iteration:[820/914] - total_loss: 55.1266  \n",
      "<<<iteration:[840/914] - total_loss: 55.1408  \n",
      "<<<iteration:[860/914] - total_loss: 55.1260  \n",
      "<<<iteration:[880/914] - total_loss: 55.1139  \n",
      "<<<iteration:[900/914] - total_loss: 55.1264  \n",
      "\n",
      "epoch:60/100 - Train Loss: 55.1274, Val Loss: 57.6222\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.8656  \n",
      "<<<iteration:[40/914] - total_loss: 55.0868  \n",
      "<<<iteration:[60/914] - total_loss: 55.1011  \n",
      "<<<iteration:[80/914] - total_loss: 55.1047  \n",
      "<<<iteration:[100/914] - total_loss: 55.1132  \n",
      "<<<iteration:[120/914] - total_loss: 55.0945  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/914] - total_loss: 55.1164  \n",
      "<<<iteration:[160/914] - total_loss: 55.1168  \n",
      "<<<iteration:[180/914] - total_loss: 55.0922  \n",
      "<<<iteration:[200/914] - total_loss: 55.1110  \n",
      "<<<iteration:[220/914] - total_loss: 55.1072  \n",
      "<<<iteration:[240/914] - total_loss: 55.1163  \n",
      "<<<iteration:[260/914] - total_loss: 55.1258  \n",
      "<<<iteration:[280/914] - total_loss: 55.1201  \n",
      "<<<iteration:[300/914] - total_loss: 55.1266  \n",
      "<<<iteration:[320/914] - total_loss: 55.0718  \n",
      "<<<iteration:[340/914] - total_loss: 55.1514  \n",
      "<<<iteration:[360/914] - total_loss: 55.1196  \n",
      "<<<iteration:[380/914] - total_loss: 55.1019  \n",
      "<<<iteration:[400/914] - total_loss: 55.0863  \n",
      "<<<iteration:[420/914] - total_loss: 55.1017  \n",
      "<<<iteration:[440/914] - total_loss: 55.0884  \n",
      "<<<iteration:[460/914] - total_loss: 55.0940  \n",
      "<<<iteration:[480/914] - total_loss: 55.1613  \n",
      "<<<iteration:[500/914] - total_loss: 55.1013  \n",
      "<<<iteration:[520/914] - total_loss: 55.0754  \n",
      "<<<iteration:[540/914] - total_loss: 55.1277  \n",
      "<<<iteration:[560/914] - total_loss: 55.0832  \n",
      "<<<iteration:[580/914] - total_loss: 55.1186  \n",
      "<<<iteration:[600/914] - total_loss: 55.0973  \n",
      "<<<iteration:[620/914] - total_loss: 55.1032  \n",
      "<<<iteration:[640/914] - total_loss: 55.1383  \n",
      "<<<iteration:[660/914] - total_loss: 55.1225  \n",
      "<<<iteration:[680/914] - total_loss: 55.1101  \n",
      "<<<iteration:[700/914] - total_loss: 55.1077  \n",
      "<<<iteration:[720/914] - total_loss: 55.1076  \n",
      "<<<iteration:[740/914] - total_loss: 55.0936  \n",
      "<<<iteration:[760/914] - total_loss: 55.0756  \n",
      "<<<iteration:[780/914] - total_loss: 55.1044  \n",
      "<<<iteration:[800/914] - total_loss: 55.1109  \n",
      "<<<iteration:[820/914] - total_loss: 55.0988  \n",
      "<<<iteration:[840/914] - total_loss: 55.1167  \n",
      "<<<iteration:[860/914] - total_loss: 55.0845  \n",
      "<<<iteration:[880/914] - total_loss: 55.0900  \n",
      "<<<iteration:[900/914] - total_loss: 55.1195  \n",
      "\n",
      "epoch:61/100 - Train Loss: 55.1070, Val Loss: 57.6001\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.8377  \n",
      "<<<iteration:[40/914] - total_loss: 55.0589  \n",
      "<<<iteration:[60/914] - total_loss: 55.0533  \n",
      "<<<iteration:[80/914] - total_loss: 55.0706  \n",
      "<<<iteration:[100/914] - total_loss: 55.1410  \n",
      "<<<iteration:[120/914] - total_loss: 55.0947  \n",
      "<<<iteration:[140/914] - total_loss: 55.0560  \n",
      "<<<iteration:[160/914] - total_loss: 55.0378  \n",
      "<<<iteration:[180/914] - total_loss: 55.0555  \n",
      "<<<iteration:[200/914] - total_loss: 55.0498  \n",
      "<<<iteration:[220/914] - total_loss: 55.0748  \n",
      "<<<iteration:[240/914] - total_loss: 55.0788  \n",
      "<<<iteration:[260/914] - total_loss: 55.0591  \n",
      "<<<iteration:[280/914] - total_loss: 55.0574  \n",
      "<<<iteration:[300/914] - total_loss: 55.0760  \n",
      "<<<iteration:[320/914] - total_loss: 55.0923  \n",
      "<<<iteration:[340/914] - total_loss: 55.0781  \n",
      "<<<iteration:[360/914] - total_loss: 55.0835  \n",
      "<<<iteration:[380/914] - total_loss: 55.0599  \n",
      "<<<iteration:[400/914] - total_loss: 55.1094  \n",
      "<<<iteration:[420/914] - total_loss: 55.1136  \n",
      "<<<iteration:[440/914] - total_loss: 55.1073  \n",
      "<<<iteration:[460/914] - total_loss: 55.0893  \n",
      "<<<iteration:[480/914] - total_loss: 55.0864  \n",
      "<<<iteration:[500/914] - total_loss: 55.0720  \n",
      "<<<iteration:[520/914] - total_loss: 55.0569  \n",
      "<<<iteration:[540/914] - total_loss: 55.0816  \n",
      "<<<iteration:[560/914] - total_loss: 55.0738  \n",
      "<<<iteration:[580/914] - total_loss: 55.0860  \n",
      "<<<iteration:[600/914] - total_loss: 55.0533  \n",
      "<<<iteration:[620/914] - total_loss: 55.0699  \n",
      "<<<iteration:[640/914] - total_loss: 55.1235  \n",
      "<<<iteration:[660/914] - total_loss: 55.0971  \n",
      "<<<iteration:[680/914] - total_loss: 55.0705  \n",
      "<<<iteration:[700/914] - total_loss: 55.0908  \n",
      "<<<iteration:[720/914] - total_loss: 55.0877  \n",
      "<<<iteration:[740/914] - total_loss: 55.0703  \n",
      "<<<iteration:[760/914] - total_loss: 55.1024  \n",
      "<<<iteration:[780/914] - total_loss: 55.0741  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[800/914] - total_loss: 55.1032  \n",
      "<<<iteration:[820/914] - total_loss: 55.0639  \n",
      "<<<iteration:[840/914] - total_loss: 55.0821  \n",
      "<<<iteration:[860/914] - total_loss: 55.1597  \n",
      "<<<iteration:[880/914] - total_loss: 55.1107  \n",
      "<<<iteration:[900/914] - total_loss: 55.1522  \n",
      "\n",
      "epoch:62/100 - Train Loss: 55.0832, Val Loss: 57.5904\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.8122  \n",
      "<<<iteration:[40/914] - total_loss: 55.1014  \n",
      "<<<iteration:[60/914] - total_loss: 55.0502  \n",
      "<<<iteration:[80/914] - total_loss: 55.0516  \n",
      "<<<iteration:[100/914] - total_loss: 55.0823  \n",
      "<<<iteration:[120/914] - total_loss: 55.0780  \n",
      "<<<iteration:[140/914] - total_loss: 55.0877  \n",
      "<<<iteration:[160/914] - total_loss: 55.0690  \n",
      "<<<iteration:[180/914] - total_loss: 55.0493  \n",
      "<<<iteration:[200/914] - total_loss: 55.0858  \n",
      "<<<iteration:[220/914] - total_loss: 55.0576  \n",
      "<<<iteration:[240/914] - total_loss: 55.0682  \n",
      "<<<iteration:[260/914] - total_loss: 55.0840  \n",
      "<<<iteration:[280/914] - total_loss: 55.0509  \n",
      "<<<iteration:[300/914] - total_loss: 55.0782  \n",
      "<<<iteration:[320/914] - total_loss: 55.0824  \n",
      "<<<iteration:[340/914] - total_loss: 55.1057  \n",
      "<<<iteration:[360/914] - total_loss: 55.0815  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[380/914] - total_loss: 55.0756  \n",
      "<<<iteration:[400/914] - total_loss: 55.0842  \n",
      "<<<iteration:[420/914] - total_loss: 55.0702  \n",
      "<<<iteration:[440/914] - total_loss: 55.0154  \n",
      "<<<iteration:[460/914] - total_loss: 55.0721  \n",
      "<<<iteration:[480/914] - total_loss: 55.0634  \n",
      "<<<iteration:[500/914] - total_loss: 55.0484  \n",
      "<<<iteration:[520/914] - total_loss: 55.0404  \n",
      "<<<iteration:[540/914] - total_loss: 55.0753  \n",
      "<<<iteration:[560/914] - total_loss: 55.0511  \n",
      "<<<iteration:[580/914] - total_loss: 55.0760  \n",
      "<<<iteration:[600/914] - total_loss: 55.0367  \n",
      "<<<iteration:[620/914] - total_loss: 55.0873  \n",
      "<<<iteration:[640/914] - total_loss: 55.0343  \n",
      "<<<iteration:[660/914] - total_loss: 55.0620  \n",
      "<<<iteration:[680/914] - total_loss: 55.0872  \n",
      "<<<iteration:[700/914] - total_loss: 55.0793  \n",
      "<<<iteration:[720/914] - total_loss: 55.0624  \n",
      "<<<iteration:[740/914] - total_loss: 55.0364  \n",
      "<<<iteration:[760/914] - total_loss: 55.0563  \n",
      "<<<iteration:[780/914] - total_loss: 55.0351  \n",
      "<<<iteration:[800/914] - total_loss: 55.0932  \n",
      "<<<iteration:[820/914] - total_loss: 55.0924  \n",
      "<<<iteration:[840/914] - total_loss: 55.1141  \n",
      "<<<iteration:[860/914] - total_loss: 55.0947  \n",
      "<<<iteration:[880/914] - total_loss: 55.0577  \n",
      "<<<iteration:[900/914] - total_loss: 55.0751  \n",
      "\n",
      "epoch:63/100 - Train Loss: 55.0683, Val Loss: 57.5705\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.7900  \n",
      "<<<iteration:[40/914] - total_loss: 55.0608  \n",
      "<<<iteration:[60/914] - total_loss: 55.0493  \n",
      "<<<iteration:[80/914] - total_loss: 55.0317  \n",
      "<<<iteration:[100/914] - total_loss: 55.0464  \n",
      "<<<iteration:[120/914] - total_loss: 55.0236  \n",
      "<<<iteration:[140/914] - total_loss: 55.0571  \n",
      "<<<iteration:[160/914] - total_loss: 55.0804  \n",
      "<<<iteration:[180/914] - total_loss: 55.0429  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/914] - total_loss: 55.0414  \n",
      "<<<iteration:[220/914] - total_loss: 55.0481  \n",
      "<<<iteration:[240/914] - total_loss: 55.0129  \n",
      "<<<iteration:[260/914] - total_loss: 55.0172  \n",
      "<<<iteration:[280/914] - total_loss: 55.0284  \n",
      "<<<iteration:[300/914] - total_loss: 55.0254  \n",
      "<<<iteration:[320/914] - total_loss: 55.0894  \n",
      "<<<iteration:[340/914] - total_loss: 55.0591  \n",
      "<<<iteration:[360/914] - total_loss: 55.0543  \n",
      "<<<iteration:[380/914] - total_loss: 55.0339  \n",
      "<<<iteration:[400/914] - total_loss: 55.0252  \n",
      "<<<iteration:[420/914] - total_loss: 55.0493  \n",
      "<<<iteration:[440/914] - total_loss: 55.0733  \n",
      "<<<iteration:[460/914] - total_loss: 55.0562  \n",
      "<<<iteration:[480/914] - total_loss: 55.0573  \n",
      "<<<iteration:[500/914] - total_loss: 55.0341  \n",
      "<<<iteration:[520/914] - total_loss: 55.1006  \n",
      "<<<iteration:[540/914] - total_loss: 55.1037  \n",
      "<<<iteration:[560/914] - total_loss: 55.0924  \n",
      "<<<iteration:[580/914] - total_loss: 55.1012  \n",
      "<<<iteration:[600/914] - total_loss: 55.0611  \n",
      "<<<iteration:[620/914] - total_loss: 55.0617  \n",
      "<<<iteration:[640/914] - total_loss: 55.0627  \n",
      "<<<iteration:[660/914] - total_loss: 55.0492  \n",
      "<<<iteration:[680/914] - total_loss: 55.0714  \n",
      "<<<iteration:[700/914] - total_loss: 55.0554  \n",
      "<<<iteration:[720/914] - total_loss: 55.0668  \n",
      "<<<iteration:[740/914] - total_loss: 55.0371  \n",
      "<<<iteration:[760/914] - total_loss: 55.0695  \n",
      "<<<iteration:[780/914] - total_loss: 55.0456  \n",
      "<<<iteration:[800/914] - total_loss: 55.0538  \n",
      "<<<iteration:[820/914] - total_loss: 55.0697  \n",
      "<<<iteration:[840/914] - total_loss: 55.1051  \n",
      "<<<iteration:[860/914] - total_loss: 55.0672  \n",
      "<<<iteration:[880/914] - total_loss: 55.0679  \n",
      "<<<iteration:[900/914] - total_loss: 55.0703  \n",
      "\n",
      "epoch:64/100 - Train Loss: 55.0566, Val Loss: 57.5856\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.8338  \n",
      "<<<iteration:[40/914] - total_loss: 55.0236  \n",
      "<<<iteration:[60/914] - total_loss: 55.0290  \n",
      "<<<iteration:[80/914] - total_loss: 55.0359  \n",
      "<<<iteration:[100/914] - total_loss: 55.0185  \n",
      "<<<iteration:[120/914] - total_loss: 55.0674  \n",
      "<<<iteration:[140/914] - total_loss: 55.0477  \n",
      "<<<iteration:[160/914] - total_loss: 55.0347  \n",
      "<<<iteration:[180/914] - total_loss: 55.0267  \n",
      "<<<iteration:[200/914] - total_loss: 55.0753  \n",
      "<<<iteration:[220/914] - total_loss: 55.0325  \n",
      "<<<iteration:[240/914] - total_loss: 55.0270  \n",
      "<<<iteration:[260/914] - total_loss: 55.0029  \n",
      "<<<iteration:[280/914] - total_loss: 55.0365  \n",
      "<<<iteration:[300/914] - total_loss: 55.0547  \n",
      "<<<iteration:[320/914] - total_loss: 55.0614  \n",
      "<<<iteration:[340/914] - total_loss: 55.0557  \n",
      "<<<iteration:[360/914] - total_loss: 55.0225  \n",
      "<<<iteration:[380/914] - total_loss: 55.0667  \n",
      "<<<iteration:[400/914] - total_loss: 55.0260  \n",
      "<<<iteration:[420/914] - total_loss: 55.0356  \n",
      "<<<iteration:[440/914] - total_loss: 55.0572  \n",
      "<<<iteration:[460/914] - total_loss: 55.0302  \n",
      "<<<iteration:[480/914] - total_loss: 54.9790  \n",
      "<<<iteration:[500/914] - total_loss: 55.0136  \n",
      "<<<iteration:[520/914] - total_loss: 54.9963  \n",
      "<<<iteration:[540/914] - total_loss: 55.0168  \n",
      "<<<iteration:[560/914] - total_loss: 55.0222  \n",
      "<<<iteration:[580/914] - total_loss: 55.0427  \n",
      "<<<iteration:[600/914] - total_loss: 55.0520  \n",
      "<<<iteration:[620/914] - total_loss: 55.0281  \n",
      "<<<iteration:[640/914] - total_loss: 55.0459  \n",
      "<<<iteration:[660/914] - total_loss: 55.0333  \n",
      "<<<iteration:[680/914] - total_loss: 55.0135  \n",
      "<<<iteration:[700/914] - total_loss: 55.0624  \n",
      "<<<iteration:[720/914] - total_loss: 55.0687  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[740/914] - total_loss: 55.0473  \n",
      "<<<iteration:[760/914] - total_loss: 55.0479  \n",
      "<<<iteration:[780/914] - total_loss: 55.0186  \n",
      "<<<iteration:[800/914] - total_loss: 55.0108  \n",
      "<<<iteration:[820/914] - total_loss: 55.0201  \n",
      "<<<iteration:[840/914] - total_loss: 55.0364  \n",
      "<<<iteration:[860/914] - total_loss: 55.0222  \n",
      "<<<iteration:[880/914] - total_loss: 55.0506  \n",
      "<<<iteration:[900/914] - total_loss: 55.0090  \n",
      "\n",
      "epoch:65/100 - Train Loss: 55.0355, Val Loss: 57.5734\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.7458  \n",
      "<<<iteration:[40/914] - total_loss: 55.0230  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/914] - total_loss: 55.0355  \n",
      "<<<iteration:[80/914] - total_loss: 55.0550  \n",
      "<<<iteration:[100/914] - total_loss: 55.0250  \n",
      "<<<iteration:[120/914] - total_loss: 55.0408  \n",
      "<<<iteration:[140/914] - total_loss: 54.9993  \n",
      "<<<iteration:[160/914] - total_loss: 55.0416  \n",
      "<<<iteration:[180/914] - total_loss: 55.0041  \n",
      "<<<iteration:[200/914] - total_loss: 55.0004  \n",
      "<<<iteration:[220/914] - total_loss: 55.0260  \n",
      "<<<iteration:[240/914] - total_loss: 55.0384  \n",
      "<<<iteration:[260/914] - total_loss: 54.9789  \n",
      "<<<iteration:[280/914] - total_loss: 54.9917  \n",
      "<<<iteration:[300/914] - total_loss: 54.9938  \n",
      "<<<iteration:[320/914] - total_loss: 55.0229  \n",
      "<<<iteration:[340/914] - total_loss: 55.0062  \n",
      "<<<iteration:[360/914] - total_loss: 55.0015  \n",
      "<<<iteration:[380/914] - total_loss: 54.9853  \n",
      "<<<iteration:[400/914] - total_loss: 55.0486  \n",
      "<<<iteration:[420/914] - total_loss: 55.0231  \n",
      "<<<iteration:[440/914] - total_loss: 55.0468  \n",
      "<<<iteration:[460/914] - total_loss: 55.0356  \n",
      "<<<iteration:[480/914] - total_loss: 55.0290  \n",
      "<<<iteration:[500/914] - total_loss: 55.0575  \n",
      "<<<iteration:[520/914] - total_loss: 55.0231  \n",
      "<<<iteration:[540/914] - total_loss: 55.0335  \n",
      "<<<iteration:[560/914] - total_loss: 55.0201  \n",
      "<<<iteration:[580/914] - total_loss: 54.9803  \n",
      "<<<iteration:[600/914] - total_loss: 54.9980  \n",
      "<<<iteration:[620/914] - total_loss: 55.0167  \n",
      "<<<iteration:[640/914] - total_loss: 55.0260  \n",
      "<<<iteration:[660/914] - total_loss: 55.0476  \n",
      "<<<iteration:[680/914] - total_loss: 55.0129  \n",
      "<<<iteration:[700/914] - total_loss: 54.9892  \n",
      "<<<iteration:[720/914] - total_loss: 55.0558  \n",
      "<<<iteration:[740/914] - total_loss: 55.0346  \n",
      "<<<iteration:[760/914] - total_loss: 54.9934  \n",
      "<<<iteration:[780/914] - total_loss: 55.0480  \n",
      "<<<iteration:[800/914] - total_loss: 55.0182  \n",
      "<<<iteration:[820/914] - total_loss: 55.0001  \n",
      "<<<iteration:[840/914] - total_loss: 55.0006  \n",
      "<<<iteration:[860/914] - total_loss: 55.0263  \n",
      "<<<iteration:[880/914] - total_loss: 54.9584  \n",
      "<<<iteration:[900/914] - total_loss: 55.0233  \n",
      "\n",
      "epoch:66/100 - Train Loss: 55.0178, Val Loss: 57.5655\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.7686  \n",
      "<<<iteration:[40/914] - total_loss: 54.9927  \n",
      "<<<iteration:[60/914] - total_loss: 54.9921  \n",
      "<<<iteration:[80/914] - total_loss: 55.0029  \n",
      "<<<iteration:[100/914] - total_loss: 54.9876  \n",
      "<<<iteration:[120/914] - total_loss: 55.0092  \n",
      "<<<iteration:[140/914] - total_loss: 55.0006  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/914] - total_loss: 54.9911  \n",
      "<<<iteration:[180/914] - total_loss: 55.0098  \n",
      "<<<iteration:[200/914] - total_loss: 55.0178  \n",
      "<<<iteration:[220/914] - total_loss: 54.9743  \n",
      "<<<iteration:[240/914] - total_loss: 55.0050  \n",
      "<<<iteration:[260/914] - total_loss: 54.9739  \n",
      "<<<iteration:[280/914] - total_loss: 55.0046  \n",
      "<<<iteration:[300/914] - total_loss: 54.9842  \n",
      "<<<iteration:[320/914] - total_loss: 54.9535  \n",
      "<<<iteration:[340/914] - total_loss: 54.9407  \n",
      "<<<iteration:[360/914] - total_loss: 54.9654  \n",
      "<<<iteration:[380/914] - total_loss: 54.9963  \n",
      "<<<iteration:[400/914] - total_loss: 54.9545  \n",
      "<<<iteration:[420/914] - total_loss: 54.9932  \n",
      "<<<iteration:[440/914] - total_loss: 55.0061  \n",
      "<<<iteration:[460/914] - total_loss: 54.9592  \n",
      "<<<iteration:[480/914] - total_loss: 55.0059  \n",
      "<<<iteration:[500/914] - total_loss: 54.9742  \n",
      "<<<iteration:[520/914] - total_loss: 54.9677  \n",
      "<<<iteration:[540/914] - total_loss: 55.0064  \n",
      "<<<iteration:[560/914] - total_loss: 54.9735  \n",
      "<<<iteration:[580/914] - total_loss: 54.9812  \n",
      "<<<iteration:[600/914] - total_loss: 55.0238  \n",
      "<<<iteration:[620/914] - total_loss: 54.9743  \n",
      "<<<iteration:[640/914] - total_loss: 55.0223  \n",
      "<<<iteration:[660/914] - total_loss: 54.9967  \n",
      "<<<iteration:[680/914] - total_loss: 55.0054  \n",
      "<<<iteration:[700/914] - total_loss: 55.0142  \n",
      "<<<iteration:[720/914] - total_loss: 55.0251  \n",
      "<<<iteration:[740/914] - total_loss: 54.9786  \n",
      "<<<iteration:[760/914] - total_loss: 55.0285  \n",
      "<<<iteration:[780/914] - total_loss: 55.0047  \n",
      "<<<iteration:[800/914] - total_loss: 54.9881  \n",
      "<<<iteration:[820/914] - total_loss: 54.9956  \n",
      "<<<iteration:[840/914] - total_loss: 54.9990  \n",
      "<<<iteration:[860/914] - total_loss: 55.0066  \n",
      "<<<iteration:[880/914] - total_loss: 54.9888  \n",
      "<<<iteration:[900/914] - total_loss: 54.9936  \n",
      "\n",
      "epoch:67/100 - Train Loss: 54.9929, Val Loss: 57.5605\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.7319  \n",
      "<<<iteration:[40/914] - total_loss: 54.9972  \n",
      "<<<iteration:[60/914] - total_loss: 54.9694  \n",
      "<<<iteration:[80/914] - total_loss: 54.9669  \n",
      "<<<iteration:[100/914] - total_loss: 54.9820  \n",
      "<<<iteration:[120/914] - total_loss: 54.9494  \n",
      "<<<iteration:[140/914] - total_loss: 54.9090  \n",
      "<<<iteration:[160/914] - total_loss: 54.9765  \n",
      "<<<iteration:[180/914] - total_loss: 54.9764  \n",
      "<<<iteration:[200/914] - total_loss: 54.9992  \n",
      "<<<iteration:[220/914] - total_loss: 54.9471  \n",
      "<<<iteration:[240/914] - total_loss: 54.9781  \n",
      "<<<iteration:[260/914] - total_loss: 54.9665  \n",
      "<<<iteration:[280/914] - total_loss: 54.9582  \n",
      "<<<iteration:[300/914] - total_loss: 54.9518  \n",
      "<<<iteration:[320/914] - total_loss: 54.9935  \n",
      "<<<iteration:[340/914] - total_loss: 54.9966  \n",
      "<<<iteration:[360/914] - total_loss: 54.9861  \n",
      "<<<iteration:[380/914] - total_loss: 54.9626  \n",
      "<<<iteration:[400/914] - total_loss: 54.9956  \n",
      "<<<iteration:[420/914] - total_loss: 55.0013  \n",
      "<<<iteration:[440/914] - total_loss: 54.9977  \n",
      "<<<iteration:[460/914] - total_loss: 55.0157  \n",
      "<<<iteration:[480/914] - total_loss: 54.9655  \n",
      "<<<iteration:[500/914] - total_loss: 54.9637  \n",
      "<<<iteration:[520/914] - total_loss: 54.9718  \n",
      "<<<iteration:[540/914] - total_loss: 54.9813  \n",
      "<<<iteration:[560/914] - total_loss: 54.9663  \n",
      "<<<iteration:[580/914] - total_loss: 54.9709  \n",
      "<<<iteration:[600/914] - total_loss: 54.9909  \n",
      "<<<iteration:[620/914] - total_loss: 54.9879  \n",
      "<<<iteration:[640/914] - total_loss: 54.9671  \n",
      "<<<iteration:[660/914] - total_loss: 55.0227  \n",
      "<<<iteration:[680/914] - total_loss: 54.9896  \n",
      "<<<iteration:[700/914] - total_loss: 55.0055  \n",
      "<<<iteration:[720/914] - total_loss: 54.9879  \n",
      "<<<iteration:[740/914] - total_loss: 54.9582  \n",
      "<<<iteration:[760/914] - total_loss: 54.9728  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[780/914] - total_loss: 54.9745  \n",
      "<<<iteration:[800/914] - total_loss: 54.9749  \n",
      "<<<iteration:[820/914] - total_loss: 55.0030  \n",
      "<<<iteration:[840/914] - total_loss: 54.9942  \n",
      "<<<iteration:[860/914] - total_loss: 54.9720  \n",
      "<<<iteration:[880/914] - total_loss: 54.9992  \n",
      "<<<iteration:[900/914] - total_loss: 54.9835  \n",
      "\n",
      "epoch:68/100 - Train Loss: 54.9788, Val Loss: 57.5880\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.7478  \n",
      "<<<iteration:[40/914] - total_loss: 54.9820  \n",
      "<<<iteration:[60/914] - total_loss: 54.9419  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/914] - total_loss: 54.9845  \n",
      "<<<iteration:[100/914] - total_loss: 54.9828  \n",
      "<<<iteration:[120/914] - total_loss: 54.9464  \n",
      "<<<iteration:[140/914] - total_loss: 54.9197  \n",
      "<<<iteration:[160/914] - total_loss: 54.9621  \n",
      "<<<iteration:[180/914] - total_loss: 54.9566  \n",
      "<<<iteration:[200/914] - total_loss: 54.9463  \n",
      "<<<iteration:[220/914] - total_loss: 55.0018  \n",
      "<<<iteration:[240/914] - total_loss: 54.9515  \n",
      "<<<iteration:[260/914] - total_loss: 54.9631  \n",
      "<<<iteration:[280/914] - total_loss: 54.9568  \n",
      "<<<iteration:[300/914] - total_loss: 54.9547  \n",
      "<<<iteration:[320/914] - total_loss: 54.9797  \n",
      "<<<iteration:[340/914] - total_loss: 54.9843  \n",
      "<<<iteration:[360/914] - total_loss: 54.9534  \n",
      "<<<iteration:[380/914] - total_loss: 54.9901  \n",
      "<<<iteration:[400/914] - total_loss: 54.9587  \n",
      "<<<iteration:[420/914] - total_loss: 54.9707  \n",
      "<<<iteration:[440/914] - total_loss: 54.9837  \n",
      "<<<iteration:[460/914] - total_loss: 54.9561  \n",
      "<<<iteration:[480/914] - total_loss: 54.9314  \n",
      "<<<iteration:[500/914] - total_loss: 54.9667  \n",
      "<<<iteration:[520/914] - total_loss: 54.9990  \n",
      "<<<iteration:[540/914] - total_loss: 54.9747  \n",
      "<<<iteration:[560/914] - total_loss: 54.9999  \n",
      "<<<iteration:[580/914] - total_loss: 54.9946  \n",
      "<<<iteration:[600/914] - total_loss: 54.9643  \n",
      "<<<iteration:[620/914] - total_loss: 54.9854  \n",
      "<<<iteration:[640/914] - total_loss: 55.0260  \n",
      "<<<iteration:[660/914] - total_loss: 55.0058  \n",
      "<<<iteration:[680/914] - total_loss: 54.9811  \n",
      "<<<iteration:[700/914] - total_loss: 54.9829  \n",
      "<<<iteration:[720/914] - total_loss: 54.9725  \n",
      "<<<iteration:[740/914] - total_loss: 54.9580  \n",
      "<<<iteration:[760/914] - total_loss: 54.9690  \n",
      "<<<iteration:[780/914] - total_loss: 54.9559  \n",
      "<<<iteration:[800/914] - total_loss: 54.9889  \n",
      "<<<iteration:[820/914] - total_loss: 54.9860  \n",
      "<<<iteration:[840/914] - total_loss: 54.9739  \n",
      "<<<iteration:[860/914] - total_loss: 54.9768  \n",
      "<<<iteration:[880/914] - total_loss: 54.9912  \n",
      "<<<iteration:[900/914] - total_loss: 54.9950  \n",
      "\n",
      "epoch:69/100 - Train Loss: 54.9742, Val Loss: 57.5739\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6946  \n",
      "<<<iteration:[40/914] - total_loss: 54.9837  \n",
      "<<<iteration:[60/914] - total_loss: 54.9642  \n",
      "<<<iteration:[80/914] - total_loss: 54.9376  \n",
      "<<<iteration:[100/914] - total_loss: 54.9913  \n",
      "<<<iteration:[120/914] - total_loss: 54.9176  \n",
      "<<<iteration:[140/914] - total_loss: 54.9698  \n",
      "<<<iteration:[160/914] - total_loss: 54.9182  \n",
      "<<<iteration:[180/914] - total_loss: 54.9551  \n",
      "<<<iteration:[200/914] - total_loss: 54.9691  \n",
      "<<<iteration:[220/914] - total_loss: 54.9642  \n",
      "<<<iteration:[240/914] - total_loss: 54.9295  \n",
      "<<<iteration:[260/914] - total_loss: 54.9362  \n",
      "<<<iteration:[280/914] - total_loss: 54.9639  \n",
      "<<<iteration:[300/914] - total_loss: 54.9741  \n",
      "<<<iteration:[320/914] - total_loss: 54.9932  \n",
      "<<<iteration:[340/914] - total_loss: 54.9496  \n",
      "<<<iteration:[360/914] - total_loss: 54.9832  \n",
      "<<<iteration:[380/914] - total_loss: 54.9162  \n",
      "<<<iteration:[400/914] - total_loss: 54.9420  \n",
      "<<<iteration:[420/914] - total_loss: 54.9528  \n",
      "<<<iteration:[440/914] - total_loss: 54.9780  \n",
      "<<<iteration:[460/914] - total_loss: 54.9571  \n",
      "<<<iteration:[480/914] - total_loss: 54.9930  \n",
      "<<<iteration:[500/914] - total_loss: 54.9782  \n",
      "<<<iteration:[520/914] - total_loss: 54.9557  \n",
      "<<<iteration:[540/914] - total_loss: 54.9692  \n",
      "<<<iteration:[560/914] - total_loss: 54.9606  \n",
      "<<<iteration:[580/914] - total_loss: 54.9670  \n",
      "<<<iteration:[600/914] - total_loss: 54.9340  \n",
      "<<<iteration:[620/914] - total_loss: 54.9256  \n",
      "<<<iteration:[640/914] - total_loss: 54.9287  \n",
      "<<<iteration:[660/914] - total_loss: 54.9428  \n",
      "<<<iteration:[680/914] - total_loss: 54.9544  \n",
      "<<<iteration:[700/914] - total_loss: 54.9663  \n",
      "<<<iteration:[720/914] - total_loss: 54.9537  \n",
      "<<<iteration:[740/914] - total_loss: 54.9747  \n",
      "<<<iteration:[760/914] - total_loss: 54.9633  \n",
      "<<<iteration:[780/914] - total_loss: 54.9365  \n",
      "<<<iteration:[800/914] - total_loss: 54.9722  \n",
      "<<<iteration:[820/914] - total_loss: 54.9665  \n",
      "<<<iteration:[840/914] - total_loss: 54.9676  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[860/914] - total_loss: 54.9625  \n",
      "<<<iteration:[880/914] - total_loss: 54.9563  \n",
      "<<<iteration:[900/914] - total_loss: 55.0010  \n",
      "\n",
      "epoch:70/100 - Train Loss: 54.9590, Val Loss: 57.5479\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6716  \n",
      "<<<iteration:[40/914] - total_loss: 54.9907  \n",
      "<<<iteration:[60/914] - total_loss: 54.9254  \n",
      "<<<iteration:[80/914] - total_loss: 54.9359  \n",
      "<<<iteration:[100/914] - total_loss: 54.9177  \n",
      "<<<iteration:[120/914] - total_loss: 54.9127  \n",
      "<<<iteration:[140/914] - total_loss: 54.9208  \n",
      "<<<iteration:[160/914] - total_loss: 54.9353  \n",
      "<<<iteration:[180/914] - total_loss: 54.9365  \n",
      "<<<iteration:[200/914] - total_loss: 54.8927  \n",
      "<<<iteration:[220/914] - total_loss: 54.9319  \n",
      "<<<iteration:[240/914] - total_loss: 54.8974  \n",
      "<<<iteration:[260/914] - total_loss: 54.9502  \n",
      "<<<iteration:[280/914] - total_loss: 54.9486  \n",
      "<<<iteration:[300/914] - total_loss: 54.9381  \n",
      "<<<iteration:[320/914] - total_loss: 54.9301  \n",
      "<<<iteration:[340/914] - total_loss: 54.9650  \n",
      "<<<iteration:[360/914] - total_loss: 54.9637  \n",
      "<<<iteration:[380/914] - total_loss: 54.9070  \n",
      "<<<iteration:[400/914] - total_loss: 54.9442  \n",
      "<<<iteration:[420/914] - total_loss: 54.9632  \n",
      "<<<iteration:[440/914] - total_loss: 54.9489  \n",
      "<<<iteration:[460/914] - total_loss: 54.9434  \n",
      "<<<iteration:[480/914] - total_loss: 54.9485  \n",
      "<<<iteration:[500/914] - total_loss: 54.9743  \n",
      "<<<iteration:[520/914] - total_loss: 54.9338  \n",
      "<<<iteration:[540/914] - total_loss: 54.9187  \n",
      "<<<iteration:[560/914] - total_loss: 54.9574  \n",
      "<<<iteration:[580/914] - total_loss: 54.9249  \n",
      "<<<iteration:[600/914] - total_loss: 54.9479  \n",
      "<<<iteration:[620/914] - total_loss: 54.9775  \n",
      "<<<iteration:[640/914] - total_loss: 54.9371  \n",
      "<<<iteration:[660/914] - total_loss: 54.9563  \n",
      "<<<iteration:[680/914] - total_loss: 54.9368  \n",
      "<<<iteration:[700/914] - total_loss: 54.9502  \n",
      "<<<iteration:[720/914] - total_loss: 54.9699  \n",
      "<<<iteration:[740/914] - total_loss: 54.9360  \n",
      "<<<iteration:[760/914] - total_loss: 54.9277  \n",
      "<<<iteration:[780/914] - total_loss: 54.9306  \n",
      "<<<iteration:[800/914] - total_loss: 54.9222  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[820/914] - total_loss: 54.9056  \n",
      "<<<iteration:[840/914] - total_loss: 54.8926  \n",
      "<<<iteration:[860/914] - total_loss: 54.9176  \n",
      "<<<iteration:[880/914] - total_loss: 54.9389  \n",
      "<<<iteration:[900/914] - total_loss: 54.9540  \n",
      "\n",
      "epoch:71/100 - Train Loss: 54.9372, Val Loss: 57.5420\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6774  \n",
      "<<<iteration:[40/914] - total_loss: 54.9229  \n",
      "<<<iteration:[60/914] - total_loss: 54.9139  \n",
      "<<<iteration:[80/914] - total_loss: 54.9092  \n",
      "<<<iteration:[100/914] - total_loss: 54.8905  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/914] - total_loss: 54.9114  \n",
      "<<<iteration:[140/914] - total_loss: 54.9146  \n",
      "<<<iteration:[160/914] - total_loss: 54.9527  \n",
      "<<<iteration:[180/914] - total_loss: 54.9031  \n",
      "<<<iteration:[200/914] - total_loss: 54.9500  \n",
      "<<<iteration:[220/914] - total_loss: 54.8783  \n",
      "<<<iteration:[240/914] - total_loss: 54.8973  \n",
      "<<<iteration:[260/914] - total_loss: 54.9346  \n",
      "<<<iteration:[280/914] - total_loss: 54.9294  \n",
      "<<<iteration:[300/914] - total_loss: 54.9074  \n",
      "<<<iteration:[320/914] - total_loss: 54.9121  \n",
      "<<<iteration:[340/914] - total_loss: 54.9360  \n",
      "<<<iteration:[360/914] - total_loss: 54.9629  \n",
      "<<<iteration:[380/914] - total_loss: 54.8931  \n",
      "<<<iteration:[400/914] - total_loss: 54.9397  \n",
      "<<<iteration:[420/914] - total_loss: 54.9006  \n",
      "<<<iteration:[440/914] - total_loss: 54.9176  \n",
      "<<<iteration:[460/914] - total_loss: 54.8988  \n",
      "<<<iteration:[480/914] - total_loss: 54.9031  \n",
      "<<<iteration:[500/914] - total_loss: 54.9218  \n",
      "<<<iteration:[520/914] - total_loss: 54.9162  \n",
      "<<<iteration:[540/914] - total_loss: 54.9348  \n",
      "<<<iteration:[560/914] - total_loss: 54.8920  \n",
      "<<<iteration:[580/914] - total_loss: 54.9054  \n",
      "<<<iteration:[600/914] - total_loss: 54.8915  \n",
      "<<<iteration:[620/914] - total_loss: 54.9011  \n",
      "<<<iteration:[640/914] - total_loss: 54.9013  \n",
      "<<<iteration:[660/914] - total_loss: 54.9472  \n",
      "<<<iteration:[680/914] - total_loss: 54.8893  \n",
      "<<<iteration:[700/914] - total_loss: 54.9135  \n",
      "<<<iteration:[720/914] - total_loss: 54.9115  \n",
      "<<<iteration:[740/914] - total_loss: 54.9291  \n",
      "<<<iteration:[760/914] - total_loss: 54.9025  \n",
      "<<<iteration:[780/914] - total_loss: 54.9325  \n",
      "<<<iteration:[800/914] - total_loss: 54.9289  \n",
      "<<<iteration:[820/914] - total_loss: 54.9454  \n",
      "<<<iteration:[840/914] - total_loss: 54.9278  \n",
      "<<<iteration:[860/914] - total_loss: 54.9337  \n",
      "<<<iteration:[880/914] - total_loss: 54.9319  \n",
      "<<<iteration:[900/914] - total_loss: 54.9218  \n",
      "\n",
      "epoch:72/100 - Train Loss: 54.9182, Val Loss: 57.5572\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6485  \n",
      "<<<iteration:[40/914] - total_loss: 54.9188  \n",
      "<<<iteration:[60/914] - total_loss: 54.8718  \n",
      "<<<iteration:[80/914] - total_loss: 54.9154  \n",
      "<<<iteration:[100/914] - total_loss: 54.9274  \n",
      "<<<iteration:[120/914] - total_loss: 54.9121  \n",
      "<<<iteration:[140/914] - total_loss: 54.9035  \n",
      "<<<iteration:[160/914] - total_loss: 54.9103  \n",
      "<<<iteration:[180/914] - total_loss: 54.9308  \n",
      "<<<iteration:[200/914] - total_loss: 54.9032  \n",
      "<<<iteration:[220/914] - total_loss: 54.8683  \n",
      "<<<iteration:[240/914] - total_loss: 54.9006  \n",
      "<<<iteration:[260/914] - total_loss: 54.9142  \n",
      "<<<iteration:[280/914] - total_loss: 54.8869  \n",
      "<<<iteration:[300/914] - total_loss: 54.9081  \n",
      "<<<iteration:[320/914] - total_loss: 54.9195  \n",
      "<<<iteration:[340/914] - total_loss: 54.9524  \n",
      "<<<iteration:[360/914] - total_loss: 54.8985  \n",
      "<<<iteration:[380/914] - total_loss: 54.9383  \n",
      "<<<iteration:[400/914] - total_loss: 54.9072  \n",
      "<<<iteration:[420/914] - total_loss: 54.8905  \n",
      "<<<iteration:[440/914] - total_loss: 54.9088  \n",
      "<<<iteration:[460/914] - total_loss: 54.9258  \n",
      "<<<iteration:[480/914] - total_loss: 54.9167  \n",
      "<<<iteration:[500/914] - total_loss: 54.9171  \n",
      "<<<iteration:[520/914] - total_loss: 54.8979  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[540/914] - total_loss: 54.9304  \n",
      "<<<iteration:[560/914] - total_loss: 54.9183  \n",
      "<<<iteration:[580/914] - total_loss: 54.9218  \n",
      "<<<iteration:[600/914] - total_loss: 54.9421  \n",
      "<<<iteration:[620/914] - total_loss: 54.9389  \n",
      "<<<iteration:[640/914] - total_loss: 54.8704  \n",
      "<<<iteration:[660/914] - total_loss: 54.9532  \n",
      "<<<iteration:[680/914] - total_loss: 54.9569  \n",
      "<<<iteration:[700/914] - total_loss: 54.9029  \n",
      "<<<iteration:[720/914] - total_loss: 54.8934  \n",
      "<<<iteration:[740/914] - total_loss: 54.9424  \n",
      "<<<iteration:[760/914] - total_loss: 54.9166  \n",
      "<<<iteration:[780/914] - total_loss: 54.9499  \n",
      "<<<iteration:[800/914] - total_loss: 54.9077  \n",
      "<<<iteration:[820/914] - total_loss: 54.9385  \n",
      "<<<iteration:[840/914] - total_loss: 54.9247  \n",
      "<<<iteration:[860/914] - total_loss: 54.9350  \n",
      "<<<iteration:[880/914] - total_loss: 54.9172  \n",
      "<<<iteration:[900/914] - total_loss: 54.9225  \n",
      "\n",
      "epoch:73/100 - Train Loss: 54.9162, Val Loss: 57.5630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/914] - total_loss: 57.6667  \n",
      "<<<iteration:[40/914] - total_loss: 54.8871  \n",
      "<<<iteration:[60/914] - total_loss: 54.9124  \n",
      "<<<iteration:[80/914] - total_loss: 54.9325  \n",
      "<<<iteration:[100/914] - total_loss: 54.9036  \n",
      "<<<iteration:[120/914] - total_loss: 54.9055  \n",
      "<<<iteration:[140/914] - total_loss: 54.9168  \n",
      "<<<iteration:[160/914] - total_loss: 54.9067  \n",
      "<<<iteration:[180/914] - total_loss: 54.8994  \n",
      "<<<iteration:[200/914] - total_loss: 54.9131  \n",
      "<<<iteration:[220/914] - total_loss: 54.8460  \n",
      "<<<iteration:[240/914] - total_loss: 54.8881  \n",
      "<<<iteration:[260/914] - total_loss: 54.8902  \n",
      "<<<iteration:[280/914] - total_loss: 54.9096  \n",
      "<<<iteration:[300/914] - total_loss: 54.8967  \n",
      "<<<iteration:[320/914] - total_loss: 54.8894  \n",
      "<<<iteration:[340/914] - total_loss: 54.9328  \n",
      "<<<iteration:[360/914] - total_loss: 54.8901  \n",
      "<<<iteration:[380/914] - total_loss: 54.9001  \n",
      "<<<iteration:[400/914] - total_loss: 54.9170  \n",
      "<<<iteration:[420/914] - total_loss: 54.8682  \n",
      "<<<iteration:[440/914] - total_loss: 54.8803  \n",
      "<<<iteration:[460/914] - total_loss: 54.8989  \n",
      "<<<iteration:[480/914] - total_loss: 54.8912  \n",
      "<<<iteration:[500/914] - total_loss: 54.9484  \n",
      "<<<iteration:[520/914] - total_loss: 54.8852  \n",
      "<<<iteration:[540/914] - total_loss: 54.9315  \n",
      "<<<iteration:[560/914] - total_loss: 54.8884  \n",
      "<<<iteration:[580/914] - total_loss: 54.9176  \n",
      "<<<iteration:[600/914] - total_loss: 54.8846  \n",
      "<<<iteration:[620/914] - total_loss: 54.9261  \n",
      "<<<iteration:[640/914] - total_loss: 54.8908  \n",
      "<<<iteration:[660/914] - total_loss: 54.9027  \n",
      "<<<iteration:[680/914] - total_loss: 54.8829  \n",
      "<<<iteration:[700/914] - total_loss: 54.8981  \n",
      "<<<iteration:[720/914] - total_loss: 54.9456  \n",
      "<<<iteration:[740/914] - total_loss: 54.8883  \n",
      "<<<iteration:[760/914] - total_loss: 54.9196  \n",
      "<<<iteration:[780/914] - total_loss: 54.8967  \n",
      "<<<iteration:[800/914] - total_loss: 54.8980  \n",
      "<<<iteration:[820/914] - total_loss: 54.9151  \n",
      "<<<iteration:[840/914] - total_loss: 54.9160  \n",
      "<<<iteration:[860/914] - total_loss: 54.8724  \n",
      "<<<iteration:[880/914] - total_loss: 54.8797  \n",
      "<<<iteration:[900/914] - total_loss: 54.8923  \n",
      "\n",
      "epoch:74/100 - Train Loss: 54.9027, Val Loss: 57.5282\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6516  \n",
      "<<<iteration:[40/914] - total_loss: 54.9034  \n",
      "<<<iteration:[60/914] - total_loss: 54.8659  \n",
      "<<<iteration:[80/914] - total_loss: 54.8681  \n",
      "<<<iteration:[100/914] - total_loss: 54.8573  \n",
      "<<<iteration:[120/914] - total_loss: 54.8769  \n",
      "<<<iteration:[140/914] - total_loss: 54.8609  \n",
      "<<<iteration:[160/914] - total_loss: 54.8892  \n",
      "<<<iteration:[180/914] - total_loss: 54.8871  \n",
      "<<<iteration:[200/914] - total_loss: 54.8718  \n",
      "<<<iteration:[220/914] - total_loss: 54.8709  \n",
      "<<<iteration:[240/914] - total_loss: 54.8397  \n",
      "<<<iteration:[260/914] - total_loss: 54.8612  \n",
      "<<<iteration:[280/914] - total_loss: 54.8961  \n",
      "<<<iteration:[300/914] - total_loss: 54.8878  \n",
      "<<<iteration:[320/914] - total_loss: 54.9035  \n",
      "<<<iteration:[340/914] - total_loss: 54.8873  \n",
      "<<<iteration:[360/914] - total_loss: 54.8807  \n",
      "<<<iteration:[380/914] - total_loss: 54.8977  \n",
      "<<<iteration:[400/914] - total_loss: 54.8533  \n",
      "<<<iteration:[420/914] - total_loss: 54.8743  \n",
      "<<<iteration:[440/914] - total_loss: 54.8836  \n",
      "<<<iteration:[460/914] - total_loss: 54.8842  \n",
      "<<<iteration:[480/914] - total_loss: 54.9152  \n",
      "<<<iteration:[500/914] - total_loss: 54.9007  \n",
      "<<<iteration:[520/914] - total_loss: 54.8740  \n",
      "<<<iteration:[540/914] - total_loss: 54.8379  \n",
      "<<<iteration:[560/914] - total_loss: 54.8881  \n",
      "<<<iteration:[580/914] - total_loss: 54.8516  \n",
      "<<<iteration:[600/914] - total_loss: 54.8867  \n",
      "<<<iteration:[620/914] - total_loss: 54.8610  \n",
      "<<<iteration:[640/914] - total_loss: 54.8649  \n",
      "<<<iteration:[660/914] - total_loss: 54.9130  \n",
      "<<<iteration:[680/914] - total_loss: 54.8738  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[700/914] - total_loss: 54.8598  \n",
      "<<<iteration:[720/914] - total_loss: 54.8605  \n",
      "<<<iteration:[740/914] - total_loss: 54.8769  \n",
      "<<<iteration:[760/914] - total_loss: 54.8695  \n",
      "<<<iteration:[780/914] - total_loss: 54.9057  \n",
      "<<<iteration:[800/914] - total_loss: 54.9012  \n",
      "<<<iteration:[820/914] - total_loss: 54.9157  \n",
      "<<<iteration:[840/914] - total_loss: 54.8956  \n",
      "<<<iteration:[860/914] - total_loss: 54.9253  \n",
      "<<<iteration:[880/914] - total_loss: 54.8572  \n",
      "<<<iteration:[900/914] - total_loss: 54.8616  \n",
      "\n",
      "epoch:75/100 - Train Loss: 54.8799, Val Loss: 57.5208\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6108  \n",
      "<<<iteration:[40/914] - total_loss: 54.8373  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/914] - total_loss: 54.8501  \n",
      "<<<iteration:[80/914] - total_loss: 54.8832  \n",
      "<<<iteration:[100/914] - total_loss: 54.8459  \n",
      "<<<iteration:[120/914] - total_loss: 54.8744  \n",
      "<<<iteration:[140/914] - total_loss: 54.8753  \n",
      "<<<iteration:[160/914] - total_loss: 54.8433  \n",
      "<<<iteration:[180/914] - total_loss: 54.8594  \n",
      "<<<iteration:[200/914] - total_loss: 54.8479  \n",
      "<<<iteration:[220/914] - total_loss: 54.8823  \n",
      "<<<iteration:[240/914] - total_loss: 54.8608  \n",
      "<<<iteration:[260/914] - total_loss: 54.8718  \n",
      "<<<iteration:[280/914] - total_loss: 54.8753  \n",
      "<<<iteration:[300/914] - total_loss: 54.8602  \n",
      "<<<iteration:[320/914] - total_loss: 54.8445  \n",
      "<<<iteration:[340/914] - total_loss: 54.8683  \n",
      "<<<iteration:[360/914] - total_loss: 54.8769  \n",
      "<<<iteration:[380/914] - total_loss: 54.8705  \n",
      "<<<iteration:[400/914] - total_loss: 54.8587  \n",
      "<<<iteration:[420/914] - total_loss: 54.8676  \n",
      "<<<iteration:[440/914] - total_loss: 54.8866  \n",
      "<<<iteration:[460/914] - total_loss: 54.9028  \n",
      "<<<iteration:[480/914] - total_loss: 54.8396  \n",
      "<<<iteration:[500/914] - total_loss: 54.8910  \n",
      "<<<iteration:[520/914] - total_loss: 54.8774  \n",
      "<<<iteration:[540/914] - total_loss: 54.8537  \n",
      "<<<iteration:[560/914] - total_loss: 54.8711  \n",
      "<<<iteration:[580/914] - total_loss: 54.8328  \n",
      "<<<iteration:[600/914] - total_loss: 54.8647  \n",
      "<<<iteration:[620/914] - total_loss: 54.8458  \n",
      "<<<iteration:[640/914] - total_loss: 54.8673  \n",
      "<<<iteration:[660/914] - total_loss: 54.8453  \n",
      "<<<iteration:[680/914] - total_loss: 54.8315  \n",
      "<<<iteration:[700/914] - total_loss: 54.9032  \n",
      "<<<iteration:[720/914] - total_loss: 54.8517  \n",
      "<<<iteration:[740/914] - total_loss: 54.8745  \n",
      "<<<iteration:[760/914] - total_loss: 54.8278  \n",
      "<<<iteration:[780/914] - total_loss: 54.8562  \n",
      "<<<iteration:[800/914] - total_loss: 54.8646  \n",
      "<<<iteration:[820/914] - total_loss: 54.8473  \n",
      "<<<iteration:[840/914] - total_loss: 54.8708  \n",
      "<<<iteration:[860/914] - total_loss: 54.8520  \n",
      "<<<iteration:[880/914] - total_loss: 54.8838  \n",
      "<<<iteration:[900/914] - total_loss: 54.8715  \n",
      "\n",
      "epoch:76/100 - Train Loss: 54.8625, Val Loss: 57.5173\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5595  \n",
      "<<<iteration:[40/914] - total_loss: 54.8535  \n",
      "<<<iteration:[60/914] - total_loss: 54.8438  \n",
      "<<<iteration:[80/914] - total_loss: 54.8499  \n",
      "<<<iteration:[100/914] - total_loss: 54.8340  \n",
      "<<<iteration:[120/914] - total_loss: 54.8586  \n",
      "<<<iteration:[140/914] - total_loss: 54.8646  \n",
      "<<<iteration:[160/914] - total_loss: 54.8656  \n",
      "<<<iteration:[180/914] - total_loss: 54.8675  \n",
      "<<<iteration:[200/914] - total_loss: 54.8379  \n",
      "<<<iteration:[220/914] - total_loss: 54.8186  \n",
      "<<<iteration:[240/914] - total_loss: 54.8365  \n",
      "<<<iteration:[260/914] - total_loss: 54.8384  \n",
      "<<<iteration:[280/914] - total_loss: 54.8486  \n",
      "<<<iteration:[300/914] - total_loss: 54.7960  \n",
      "<<<iteration:[320/914] - total_loss: 54.8790  \n",
      "<<<iteration:[340/914] - total_loss: 54.8285  \n",
      "<<<iteration:[360/914] - total_loss: 54.8505  \n",
      "<<<iteration:[380/914] - total_loss: 54.8497  \n",
      "<<<iteration:[400/914] - total_loss: 54.8115  \n",
      "<<<iteration:[420/914] - total_loss: 54.8170  \n",
      "<<<iteration:[440/914] - total_loss: 54.8660  \n",
      "<<<iteration:[460/914] - total_loss: 54.8969  \n",
      "<<<iteration:[480/914] - total_loss: 54.8447  \n",
      "<<<iteration:[500/914] - total_loss: 54.8638  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[520/914] - total_loss: 54.8614  \n",
      "<<<iteration:[540/914] - total_loss: 54.8844  \n",
      "<<<iteration:[560/914] - total_loss: 54.8506  \n",
      "<<<iteration:[580/914] - total_loss: 54.8625  \n",
      "<<<iteration:[600/914] - total_loss: 54.8476  \n",
      "<<<iteration:[620/914] - total_loss: 54.8480  \n",
      "<<<iteration:[640/914] - total_loss: 54.8875  \n",
      "<<<iteration:[660/914] - total_loss: 54.8196  \n",
      "<<<iteration:[680/914] - total_loss: 54.8424  \n",
      "<<<iteration:[700/914] - total_loss: 54.8487  \n",
      "<<<iteration:[720/914] - total_loss: 54.8651  \n",
      "<<<iteration:[740/914] - total_loss: 54.8422  \n",
      "<<<iteration:[760/914] - total_loss: 54.8439  \n",
      "<<<iteration:[780/914] - total_loss: 54.8662  \n",
      "<<<iteration:[800/914] - total_loss: 54.8594  \n",
      "<<<iteration:[820/914] - total_loss: 54.8759  \n",
      "<<<iteration:[840/914] - total_loss: 54.8759  \n",
      "<<<iteration:[860/914] - total_loss: 54.8366  \n",
      "<<<iteration:[880/914] - total_loss: 54.8654  \n",
      "<<<iteration:[900/914] - total_loss: 54.8579  \n",
      "\n",
      "epoch:77/100 - Train Loss: 54.8506, Val Loss: 57.5166\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.6388  \n",
      "<<<iteration:[40/914] - total_loss: 54.8683  \n",
      "<<<iteration:[60/914] - total_loss: 54.8653  \n",
      "<<<iteration:[80/914] - total_loss: 54.8378  \n",
      "<<<iteration:[100/914] - total_loss: 54.8900  \n",
      "<<<iteration:[120/914] - total_loss: 54.8585  \n",
      "<<<iteration:[140/914] - total_loss: 54.8736  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/914] - total_loss: 54.8660  \n",
      "<<<iteration:[180/914] - total_loss: 54.8743  \n",
      "<<<iteration:[200/914] - total_loss: 54.8825  \n",
      "<<<iteration:[220/914] - total_loss: 54.9020  \n",
      "<<<iteration:[240/914] - total_loss: 54.8641  \n",
      "<<<iteration:[260/914] - total_loss: 54.8889  \n",
      "<<<iteration:[280/914] - total_loss: 54.9043  \n",
      "<<<iteration:[300/914] - total_loss: 54.8905  \n",
      "<<<iteration:[320/914] - total_loss: 54.8969  \n",
      "<<<iteration:[340/914] - total_loss: 54.8631  \n",
      "<<<iteration:[360/914] - total_loss: 54.8583  \n",
      "<<<iteration:[380/914] - total_loss: 54.8699  \n",
      "<<<iteration:[400/914] - total_loss: 54.8584  \n",
      "<<<iteration:[420/914] - total_loss: 54.8851  \n",
      "<<<iteration:[440/914] - total_loss: 54.8519  \n",
      "<<<iteration:[460/914] - total_loss: 54.8665  \n",
      "<<<iteration:[480/914] - total_loss: 54.8735  \n",
      "<<<iteration:[500/914] - total_loss: 54.8689  \n",
      "<<<iteration:[520/914] - total_loss: 54.8357  \n",
      "<<<iteration:[540/914] - total_loss: 54.8538  \n",
      "<<<iteration:[560/914] - total_loss: 54.8741  \n",
      "<<<iteration:[580/914] - total_loss: 54.8765  \n",
      "<<<iteration:[600/914] - total_loss: 54.8610  \n",
      "<<<iteration:[620/914] - total_loss: 54.8621  \n",
      "<<<iteration:[640/914] - total_loss: 54.8824  \n",
      "<<<iteration:[660/914] - total_loss: 54.8681  \n",
      "<<<iteration:[680/914] - total_loss: 54.8802  \n",
      "<<<iteration:[700/914] - total_loss: 54.8929  \n",
      "<<<iteration:[720/914] - total_loss: 54.8533  \n",
      "<<<iteration:[740/914] - total_loss: 54.8742  \n",
      "<<<iteration:[760/914] - total_loss: 54.8473  \n",
      "<<<iteration:[780/914] - total_loss: 54.8828  \n",
      "<<<iteration:[800/914] - total_loss: 54.8609  \n",
      "<<<iteration:[820/914] - total_loss: 54.8696  \n",
      "<<<iteration:[840/914] - total_loss: 54.8596  \n",
      "<<<iteration:[860/914] - total_loss: 54.8386  \n",
      "<<<iteration:[880/914] - total_loss: 54.8771  \n",
      "<<<iteration:[900/914] - total_loss: 54.8594  \n",
      "\n",
      "epoch:78/100 - Train Loss: 54.8704, Val Loss: 57.5495\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5299  \n",
      "<<<iteration:[40/914] - total_loss: 54.8632  \n",
      "<<<iteration:[60/914] - total_loss: 54.8449  \n",
      "<<<iteration:[80/914] - total_loss: 54.8223  \n",
      "<<<iteration:[100/914] - total_loss: 54.8849  \n",
      "<<<iteration:[120/914] - total_loss: 54.8578  \n",
      "<<<iteration:[140/914] - total_loss: 54.8567  \n",
      "<<<iteration:[160/914] - total_loss: 54.8413  \n",
      "<<<iteration:[180/914] - total_loss: 54.8301  \n",
      "<<<iteration:[200/914] - total_loss: 54.8199  \n",
      "<<<iteration:[220/914] - total_loss: 54.8102  \n",
      "<<<iteration:[240/914] - total_loss: 54.8547  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/914] - total_loss: 54.8291  \n",
      "<<<iteration:[280/914] - total_loss: 54.8125  \n",
      "<<<iteration:[300/914] - total_loss: 54.8251  \n",
      "<<<iteration:[320/914] - total_loss: 54.8298  \n",
      "<<<iteration:[340/914] - total_loss: 54.8131  \n",
      "<<<iteration:[360/914] - total_loss: 54.8562  \n",
      "<<<iteration:[380/914] - total_loss: 54.8820  \n",
      "<<<iteration:[400/914] - total_loss: 54.8511  \n",
      "<<<iteration:[420/914] - total_loss: 54.8463  \n",
      "<<<iteration:[440/914] - total_loss: 54.7713  \n",
      "<<<iteration:[460/914] - total_loss: 54.8303  \n",
      "<<<iteration:[480/914] - total_loss: 54.8865  \n",
      "<<<iteration:[500/914] - total_loss: 54.8184  \n",
      "<<<iteration:[520/914] - total_loss: 54.8088  \n",
      "<<<iteration:[540/914] - total_loss: 54.8612  \n",
      "<<<iteration:[560/914] - total_loss: 54.8504  \n",
      "<<<iteration:[580/914] - total_loss: 54.8162  \n",
      "<<<iteration:[600/914] - total_loss: 54.8337  \n",
      "<<<iteration:[620/914] - total_loss: 54.8022  \n",
      "<<<iteration:[640/914] - total_loss: 54.8335  \n",
      "<<<iteration:[660/914] - total_loss: 54.8351  \n",
      "<<<iteration:[680/914] - total_loss: 54.8269  \n",
      "<<<iteration:[700/914] - total_loss: 54.8242  \n",
      "<<<iteration:[720/914] - total_loss: 54.8675  \n",
      "<<<iteration:[740/914] - total_loss: 54.8352  \n",
      "<<<iteration:[760/914] - total_loss: 54.8431  \n",
      "<<<iteration:[780/914] - total_loss: 54.8428  \n",
      "<<<iteration:[800/914] - total_loss: 54.8562  \n",
      "<<<iteration:[820/914] - total_loss: 54.8372  \n",
      "<<<iteration:[840/914] - total_loss: 54.8615  \n",
      "<<<iteration:[860/914] - total_loss: 54.8393  \n",
      "<<<iteration:[880/914] - total_loss: 54.8496  \n",
      "<<<iteration:[900/914] - total_loss: 54.8404  \n",
      "\n",
      "epoch:79/100 - Train Loss: 54.8374, Val Loss: 57.5302\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5454  \n",
      "<<<iteration:[40/914] - total_loss: 54.8532  \n",
      "<<<iteration:[60/914] - total_loss: 54.8200  \n",
      "<<<iteration:[80/914] - total_loss: 54.8142  \n",
      "<<<iteration:[100/914] - total_loss: 54.8400  \n",
      "<<<iteration:[120/914] - total_loss: 54.8012  \n",
      "<<<iteration:[140/914] - total_loss: 54.7707  \n",
      "<<<iteration:[160/914] - total_loss: 54.8246  \n",
      "<<<iteration:[180/914] - total_loss: 54.8021  \n",
      "<<<iteration:[200/914] - total_loss: 54.8023  \n",
      "<<<iteration:[220/914] - total_loss: 54.8069  \n",
      "<<<iteration:[240/914] - total_loss: 54.7858  \n",
      "<<<iteration:[260/914] - total_loss: 54.7990  \n",
      "<<<iteration:[280/914] - total_loss: 54.8094  \n",
      "<<<iteration:[300/914] - total_loss: 54.8060  \n",
      "<<<iteration:[320/914] - total_loss: 54.7895  \n",
      "<<<iteration:[340/914] - total_loss: 54.8293  \n",
      "<<<iteration:[360/914] - total_loss: 54.8459  \n",
      "<<<iteration:[380/914] - total_loss: 54.8085  \n",
      "<<<iteration:[400/914] - total_loss: 54.8048  \n",
      "<<<iteration:[420/914] - total_loss: 54.8138  \n",
      "<<<iteration:[440/914] - total_loss: 54.8111  \n",
      "<<<iteration:[460/914] - total_loss: 54.8078  \n",
      "<<<iteration:[480/914] - total_loss: 54.8508  \n",
      "<<<iteration:[500/914] - total_loss: 54.8375  \n",
      "<<<iteration:[520/914] - total_loss: 54.8066  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[540/914] - total_loss: 54.7944  \n",
      "<<<iteration:[560/914] - total_loss: 54.8215  \n",
      "<<<iteration:[580/914] - total_loss: 54.8057  \n",
      "<<<iteration:[600/914] - total_loss: 54.7965  \n",
      "<<<iteration:[620/914] - total_loss: 54.8044  \n",
      "<<<iteration:[640/914] - total_loss: 54.8511  \n",
      "<<<iteration:[660/914] - total_loss: 54.8272  \n",
      "<<<iteration:[680/914] - total_loss: 54.7770  \n",
      "<<<iteration:[700/914] - total_loss: 54.8184  \n",
      "<<<iteration:[720/914] - total_loss: 54.7589  \n",
      "<<<iteration:[740/914] - total_loss: 54.8220  \n",
      "<<<iteration:[760/914] - total_loss: 54.8168  \n",
      "<<<iteration:[780/914] - total_loss: 54.8079  \n",
      "<<<iteration:[800/914] - total_loss: 54.7983  \n",
      "<<<iteration:[820/914] - total_loss: 54.7722  \n",
      "<<<iteration:[840/914] - total_loss: 54.8044  \n",
      "<<<iteration:[860/914] - total_loss: 54.8476  \n",
      "<<<iteration:[880/914] - total_loss: 54.8217  \n",
      "<<<iteration:[900/914] - total_loss: 54.7954  \n",
      "\n",
      "epoch:80/100 - Train Loss: 54.8109, Val Loss: 57.5162\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5288  \n",
      "<<<iteration:[40/914] - total_loss: 54.7959  \n",
      "<<<iteration:[60/914] - total_loss: 54.8101  \n",
      "<<<iteration:[80/914] - total_loss: 54.8137  \n",
      "<<<iteration:[100/914] - total_loss: 54.7622  \n",
      "<<<iteration:[120/914] - total_loss: 54.8054  \n",
      "<<<iteration:[140/914] - total_loss: 54.8178  \n",
      "<<<iteration:[160/914] - total_loss: 54.7989  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/914] - total_loss: 54.7998  \n",
      "<<<iteration:[200/914] - total_loss: 54.8334  \n",
      "<<<iteration:[220/914] - total_loss: 54.7899  \n",
      "<<<iteration:[240/914] - total_loss: 54.7743  \n",
      "<<<iteration:[260/914] - total_loss: 54.8078  \n",
      "<<<iteration:[280/914] - total_loss: 54.8113  \n",
      "<<<iteration:[300/914] - total_loss: 54.8085  \n",
      "<<<iteration:[320/914] - total_loss: 54.7875  \n",
      "<<<iteration:[340/914] - total_loss: 54.8022  \n",
      "<<<iteration:[360/914] - total_loss: 54.7896  \n",
      "<<<iteration:[380/914] - total_loss: 54.8219  \n",
      "<<<iteration:[400/914] - total_loss: 54.8003  \n",
      "<<<iteration:[420/914] - total_loss: 54.7810  \n",
      "<<<iteration:[440/914] - total_loss: 54.7983  \n",
      "<<<iteration:[460/914] - total_loss: 54.7861  \n",
      "<<<iteration:[480/914] - total_loss: 54.8267  \n",
      "<<<iteration:[500/914] - total_loss: 54.7936  \n",
      "<<<iteration:[520/914] - total_loss: 54.7898  \n",
      "<<<iteration:[540/914] - total_loss: 54.7778  \n",
      "<<<iteration:[560/914] - total_loss: 54.7737  \n",
      "<<<iteration:[580/914] - total_loss: 54.7825  \n",
      "<<<iteration:[600/914] - total_loss: 54.8397  \n",
      "<<<iteration:[620/914] - total_loss: 54.8057  \n",
      "<<<iteration:[640/914] - total_loss: 54.8134  \n",
      "<<<iteration:[660/914] - total_loss: 54.7851  \n",
      "<<<iteration:[680/914] - total_loss: 54.7966  \n",
      "<<<iteration:[700/914] - total_loss: 54.8101  \n",
      "<<<iteration:[720/914] - total_loss: 54.7734  \n",
      "<<<iteration:[740/914] - total_loss: 54.7828  \n",
      "<<<iteration:[760/914] - total_loss: 54.7910  \n",
      "<<<iteration:[780/914] - total_loss: 54.8211  \n",
      "<<<iteration:[800/914] - total_loss: 54.8008  \n",
      "<<<iteration:[820/914] - total_loss: 54.8094  \n",
      "<<<iteration:[840/914] - total_loss: 54.8252  \n",
      "<<<iteration:[860/914] - total_loss: 54.8141  \n",
      "<<<iteration:[880/914] - total_loss: 54.8440  \n",
      "<<<iteration:[900/914] - total_loss: 54.8157  \n",
      "\n",
      "epoch:81/100 - Train Loss: 54.8017, Val Loss: 57.5133\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5092  \n",
      "<<<iteration:[40/914] - total_loss: 54.8079  \n",
      "<<<iteration:[60/914] - total_loss: 54.7873  \n",
      "<<<iteration:[80/914] - total_loss: 54.7831  \n",
      "<<<iteration:[100/914] - total_loss: 54.7929  \n",
      "<<<iteration:[120/914] - total_loss: 54.8181  \n",
      "<<<iteration:[140/914] - total_loss: 54.7571  \n",
      "<<<iteration:[160/914] - total_loss: 54.7846  \n",
      "<<<iteration:[180/914] - total_loss: 54.7772  \n",
      "<<<iteration:[200/914] - total_loss: 54.8105  \n",
      "<<<iteration:[220/914] - total_loss: 54.7568  \n",
      "<<<iteration:[240/914] - total_loss: 54.7905  \n",
      "<<<iteration:[260/914] - total_loss: 54.8408  \n",
      "<<<iteration:[280/914] - total_loss: 54.7881  \n",
      "<<<iteration:[300/914] - total_loss: 54.7862  \n",
      "<<<iteration:[320/914] - total_loss: 54.7911  \n",
      "<<<iteration:[340/914] - total_loss: 54.7864  \n",
      "<<<iteration:[360/914] - total_loss: 54.8199  \n",
      "<<<iteration:[380/914] - total_loss: 54.7601  \n",
      "<<<iteration:[400/914] - total_loss: 54.8080  \n",
      "<<<iteration:[420/914] - total_loss: 54.8187  \n",
      "<<<iteration:[440/914] - total_loss: 54.8058  \n",
      "<<<iteration:[460/914] - total_loss: 54.8134  \n",
      "<<<iteration:[480/914] - total_loss: 54.7896  \n",
      "<<<iteration:[500/914] - total_loss: 54.7688  \n",
      "<<<iteration:[520/914] - total_loss: 54.8046  \n",
      "<<<iteration:[540/914] - total_loss: 54.8028  \n",
      "<<<iteration:[560/914] - total_loss: 54.8384  \n",
      "<<<iteration:[580/914] - total_loss: 54.8044  \n",
      "<<<iteration:[600/914] - total_loss: 54.7745  \n",
      "<<<iteration:[620/914] - total_loss: 54.8151  \n",
      "<<<iteration:[640/914] - total_loss: 54.7910  \n",
      "<<<iteration:[660/914] - total_loss: 54.7650  \n",
      "<<<iteration:[680/914] - total_loss: 54.7780  \n",
      "<<<iteration:[700/914] - total_loss: 54.7865  \n",
      "<<<iteration:[720/914] - total_loss: 54.8114  \n",
      "<<<iteration:[740/914] - total_loss: 54.8085  \n",
      "<<<iteration:[760/914] - total_loss: 54.7853  \n",
      "<<<iteration:[780/914] - total_loss: 54.7831  \n",
      "<<<iteration:[800/914] - total_loss: 54.8219  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[820/914] - total_loss: 54.7933  \n",
      "<<<iteration:[840/914] - total_loss: 54.8062  \n",
      "<<<iteration:[860/914] - total_loss: 54.7879  \n",
      "<<<iteration:[880/914] - total_loss: 54.7813  \n",
      "<<<iteration:[900/914] - total_loss: 54.8252  \n",
      "\n",
      "epoch:82/100 - Train Loss: 54.7953, Val Loss: 57.5479\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5488  \n",
      "<<<iteration:[40/914] - total_loss: 54.7917  \n",
      "<<<iteration:[60/914] - total_loss: 54.7997  \n",
      "<<<iteration:[80/914] - total_loss: 54.8010  \n",
      "<<<iteration:[100/914] - total_loss: 54.7910  \n",
      "<<<iteration:[120/914] - total_loss: 54.7748  \n",
      "<<<iteration:[140/914] - total_loss: 54.7834  \n",
      "<<<iteration:[160/914] - total_loss: 54.7904  \n",
      "<<<iteration:[180/914] - total_loss: 54.8513  \n",
      "<<<iteration:[200/914] - total_loss: 54.8263  \n",
      "<<<iteration:[220/914] - total_loss: 54.7757  \n",
      "<<<iteration:[240/914] - total_loss: 54.8243  \n",
      "<<<iteration:[260/914] - total_loss: 54.7748  \n",
      "<<<iteration:[280/914] - total_loss: 54.8041  \n",
      "<<<iteration:[300/914] - total_loss: 54.8491  \n",
      "<<<iteration:[320/914] - total_loss: 54.8102  \n",
      "<<<iteration:[340/914] - total_loss: 54.8005  \n",
      "<<<iteration:[360/914] - total_loss: 54.8627  \n",
      "<<<iteration:[380/914] - total_loss: 54.7901  \n",
      "<<<iteration:[400/914] - total_loss: 54.7893  \n",
      "<<<iteration:[420/914] - total_loss: 54.8122  \n",
      "<<<iteration:[440/914] - total_loss: 54.7772  \n",
      "<<<iteration:[460/914] - total_loss: 54.7778  \n",
      "<<<iteration:[480/914] - total_loss: 54.8070  \n",
      "<<<iteration:[500/914] - total_loss: 54.7779  \n",
      "<<<iteration:[520/914] - total_loss: 54.8100  \n",
      "<<<iteration:[540/914] - total_loss: 54.8380  \n",
      "<<<iteration:[560/914] - total_loss: 54.7732  \n",
      "<<<iteration:[580/914] - total_loss: 54.8093  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[600/914] - total_loss: 54.8178  \n",
      "<<<iteration:[620/914] - total_loss: 54.8244  \n",
      "<<<iteration:[640/914] - total_loss: 54.7863  \n",
      "<<<iteration:[660/914] - total_loss: 54.8161  \n",
      "<<<iteration:[680/914] - total_loss: 54.8253  \n",
      "<<<iteration:[700/914] - total_loss: 54.8339  \n",
      "<<<iteration:[720/914] - total_loss: 54.7955  \n",
      "<<<iteration:[740/914] - total_loss: 54.8022  \n",
      "<<<iteration:[760/914] - total_loss: 54.8006  \n",
      "<<<iteration:[780/914] - total_loss: 54.7908  \n",
      "<<<iteration:[800/914] - total_loss: 54.8266  \n",
      "<<<iteration:[820/914] - total_loss: 54.7937  \n",
      "<<<iteration:[840/914] - total_loss: 54.8127  \n",
      "<<<iteration:[860/914] - total_loss: 54.8363  \n",
      "<<<iteration:[880/914] - total_loss: 54.8004  \n",
      "<<<iteration:[900/914] - total_loss: 54.8227  \n",
      "\n",
      "epoch:83/100 - Train Loss: 54.8057, Val Loss: 57.5382\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5258  \n",
      "<<<iteration:[40/914] - total_loss: 54.7910  \n",
      "<<<iteration:[60/914] - total_loss: 54.7921  \n",
      "<<<iteration:[80/914] - total_loss: 54.7815  \n",
      "<<<iteration:[100/914] - total_loss: 54.7771  \n",
      "<<<iteration:[120/914] - total_loss: 54.8044  \n",
      "<<<iteration:[140/914] - total_loss: 54.7889  \n",
      "<<<iteration:[160/914] - total_loss: 54.8207  \n",
      "<<<iteration:[180/914] - total_loss: 54.7884  \n",
      "<<<iteration:[200/914] - total_loss: 54.7755  \n",
      "<<<iteration:[220/914] - total_loss: 54.8194  \n",
      "<<<iteration:[240/914] - total_loss: 54.8031  \n",
      "<<<iteration:[260/914] - total_loss: 54.7756  \n",
      "<<<iteration:[280/914] - total_loss: 54.7897  \n",
      "<<<iteration:[300/914] - total_loss: 54.7926  \n",
      "<<<iteration:[320/914] - total_loss: 54.8074  \n",
      "<<<iteration:[340/914] - total_loss: 54.8167  \n",
      "<<<iteration:[360/914] - total_loss: 54.7833  \n",
      "<<<iteration:[380/914] - total_loss: 54.7887  \n",
      "<<<iteration:[400/914] - total_loss: 54.7894  \n",
      "<<<iteration:[420/914] - total_loss: 54.7911  \n",
      "<<<iteration:[440/914] - total_loss: 54.8187  \n",
      "<<<iteration:[460/914] - total_loss: 54.7945  \n",
      "<<<iteration:[480/914] - total_loss: 54.7877  \n",
      "<<<iteration:[500/914] - total_loss: 54.8019  \n",
      "<<<iteration:[520/914] - total_loss: 54.7870  \n",
      "<<<iteration:[540/914] - total_loss: 54.7767  \n",
      "<<<iteration:[560/914] - total_loss: 54.7805  \n",
      "<<<iteration:[580/914] - total_loss: 54.7817  \n",
      "<<<iteration:[600/914] - total_loss: 54.7802  \n",
      "<<<iteration:[620/914] - total_loss: 54.7734  \n",
      "<<<iteration:[640/914] - total_loss: 54.8081  \n",
      "<<<iteration:[660/914] - total_loss: 54.7937  \n",
      "<<<iteration:[680/914] - total_loss: 54.7792  \n",
      "<<<iteration:[700/914] - total_loss: 54.7947  \n",
      "<<<iteration:[720/914] - total_loss: 54.8542  \n",
      "<<<iteration:[740/914] - total_loss: 54.7745  \n",
      "<<<iteration:[760/914] - total_loss: 54.7641  \n",
      "<<<iteration:[780/914] - total_loss: 54.8126  \n",
      "<<<iteration:[800/914] - total_loss: 54.8365  \n",
      "<<<iteration:[820/914] - total_loss: 54.8033  \n",
      "<<<iteration:[840/914] - total_loss: 54.8254  \n",
      "<<<iteration:[860/914] - total_loss: 54.7894  \n",
      "<<<iteration:[880/914] - total_loss: 54.8020  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[900/914] - total_loss: 54.8055  \n",
      "\n",
      "epoch:84/100 - Train Loss: 54.7953, Val Loss: 57.5218\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.5108  \n",
      "<<<iteration:[40/914] - total_loss: 54.7650  \n",
      "<<<iteration:[60/914] - total_loss: 54.7500  \n",
      "<<<iteration:[80/914] - total_loss: 54.7546  \n",
      "<<<iteration:[100/914] - total_loss: 54.7700  \n",
      "<<<iteration:[120/914] - total_loss: 54.7520  \n",
      "<<<iteration:[140/914] - total_loss: 54.7542  \n",
      "<<<iteration:[160/914] - total_loss: 54.7514  \n",
      "<<<iteration:[180/914] - total_loss: 54.7691  \n",
      "<<<iteration:[200/914] - total_loss: 54.7675  \n",
      "<<<iteration:[220/914] - total_loss: 54.7514  \n",
      "<<<iteration:[240/914] - total_loss: 54.7461  \n",
      "<<<iteration:[260/914] - total_loss: 54.7801  \n",
      "<<<iteration:[280/914] - total_loss: 54.7803  \n",
      "<<<iteration:[300/914] - total_loss: 54.7791  \n",
      "<<<iteration:[320/914] - total_loss: 54.7946  \n",
      "<<<iteration:[340/914] - total_loss: 54.7495  \n",
      "<<<iteration:[360/914] - total_loss: 54.7315  \n",
      "<<<iteration:[380/914] - total_loss: 54.7385  \n",
      "<<<iteration:[400/914] - total_loss: 54.7761  \n",
      "<<<iteration:[420/914] - total_loss: 54.7580  \n",
      "<<<iteration:[440/914] - total_loss: 54.7670  \n",
      "<<<iteration:[460/914] - total_loss: 54.7351  \n",
      "<<<iteration:[480/914] - total_loss: 54.7676  \n",
      "<<<iteration:[500/914] - total_loss: 54.7750  \n",
      "<<<iteration:[520/914] - total_loss: 54.7487  \n",
      "<<<iteration:[540/914] - total_loss: 54.7612  \n",
      "<<<iteration:[560/914] - total_loss: 54.7660  \n",
      "<<<iteration:[580/914] - total_loss: 54.7888  \n",
      "<<<iteration:[600/914] - total_loss: 54.7615  \n",
      "<<<iteration:[620/914] - total_loss: 54.7243  \n",
      "<<<iteration:[640/914] - total_loss: 54.7540  \n",
      "<<<iteration:[660/914] - total_loss: 54.7643  \n",
      "<<<iteration:[680/914] - total_loss: 54.7478  \n",
      "<<<iteration:[700/914] - total_loss: 54.7718  \n",
      "<<<iteration:[720/914] - total_loss: 54.7365  \n",
      "<<<iteration:[740/914] - total_loss: 54.7693  \n",
      "<<<iteration:[760/914] - total_loss: 54.7677  \n",
      "<<<iteration:[780/914] - total_loss: 54.7701  \n",
      "<<<iteration:[800/914] - total_loss: 54.7544  \n",
      "<<<iteration:[820/914] - total_loss: 54.7782  \n",
      "<<<iteration:[840/914] - total_loss: 54.7730  \n",
      "<<<iteration:[860/914] - total_loss: 54.7535  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[880/914] - total_loss: 54.7800  \n",
      "<<<iteration:[900/914] - total_loss: 54.7706  \n",
      "\n",
      "epoch:85/100 - Train Loss: 54.7622, Val Loss: 57.5291\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.4883  \n",
      "<<<iteration:[40/914] - total_loss: 54.7021  \n",
      "<<<iteration:[60/914] - total_loss: 54.7403  \n",
      "<<<iteration:[80/914] - total_loss: 54.7406  \n",
      "<<<iteration:[100/914] - total_loss: 54.7269  \n",
      "<<<iteration:[120/914] - total_loss: 54.7217  \n",
      "<<<iteration:[140/914] - total_loss: 54.7565  \n",
      "<<<iteration:[160/914] - total_loss: 54.7381  \n",
      "<<<iteration:[180/914] - total_loss: 54.7164  \n",
      "<<<iteration:[200/914] - total_loss: 54.7338  \n",
      "<<<iteration:[220/914] - total_loss: 54.7785  \n",
      "<<<iteration:[240/914] - total_loss: 54.7570  \n",
      "<<<iteration:[260/914] - total_loss: 54.7612  \n",
      "<<<iteration:[280/914] - total_loss: 54.7604  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[300/914] - total_loss: 54.7618  \n",
      "<<<iteration:[320/914] - total_loss: 54.7588  \n",
      "<<<iteration:[340/914] - total_loss: 54.7704  \n",
      "<<<iteration:[360/914] - total_loss: 54.7230  \n",
      "<<<iteration:[380/914] - total_loss: 54.7306  \n",
      "<<<iteration:[400/914] - total_loss: 54.7209  \n",
      "<<<iteration:[420/914] - total_loss: 54.7289  \n",
      "<<<iteration:[440/914] - total_loss: 54.7495  \n",
      "<<<iteration:[460/914] - total_loss: 54.7582  \n",
      "<<<iteration:[480/914] - total_loss: 54.7619  \n",
      "<<<iteration:[500/914] - total_loss: 54.7355  \n",
      "<<<iteration:[520/914] - total_loss: 54.7311  \n",
      "<<<iteration:[540/914] - total_loss: 54.7018  \n",
      "<<<iteration:[560/914] - total_loss: 54.7199  \n",
      "<<<iteration:[580/914] - total_loss: 54.7386  \n",
      "<<<iteration:[600/914] - total_loss: 54.7109  \n",
      "<<<iteration:[620/914] - total_loss: 54.7282  \n",
      "<<<iteration:[640/914] - total_loss: 54.7383  \n",
      "<<<iteration:[660/914] - total_loss: 54.7862  \n",
      "<<<iteration:[680/914] - total_loss: 54.7747  \n",
      "<<<iteration:[700/914] - total_loss: 54.7803  \n",
      "<<<iteration:[720/914] - total_loss: 54.7739  \n",
      "<<<iteration:[740/914] - total_loss: 54.7437  \n",
      "<<<iteration:[760/914] - total_loss: 54.7698  \n",
      "<<<iteration:[780/914] - total_loss: 54.7294  \n",
      "<<<iteration:[800/914] - total_loss: 54.7576  \n",
      "<<<iteration:[820/914] - total_loss: 54.7476  \n",
      "<<<iteration:[840/914] - total_loss: 54.7189  \n",
      "<<<iteration:[860/914] - total_loss: 54.7604  \n",
      "<<<iteration:[880/914] - total_loss: 54.7485  \n",
      "<<<iteration:[900/914] - total_loss: 54.7602  \n",
      "\n",
      "epoch:86/100 - Train Loss: 54.7443, Val Loss: 57.5237\n",
      "\n",
      "<<<iteration:[20/914] - total_loss: 57.4719  \n",
      "<<<iteration:[40/914] - total_loss: 54.7410  \n",
      "<<<iteration:[60/914] - total_loss: 54.6943  \n",
      "<<<iteration:[80/914] - total_loss: 54.7128  \n",
      "<<<iteration:[100/914] - total_loss: 54.7245  \n",
      "<<<iteration:[120/914] - total_loss: 54.7445  \n",
      "<<<iteration:[140/914] - total_loss: 54.7354  \n",
      "<<<iteration:[160/914] - total_loss: 54.7305  \n"
     ]
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Val Loss\": val_loss['total_loss'],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{IMAGE_ENC}_{TEXT_ENC}_{DECODER}_cross_ent\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67da5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe10dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5f1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
