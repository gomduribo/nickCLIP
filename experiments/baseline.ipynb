{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c6ba10f-0def-48d3-b726-926f4558d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ce285c-6ee1-41ab-ace2-f49af16857c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d5c2f-6373-4d1e-a762-41d5d53c1f9a",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93377edb-602d-4ddd-9c12-d89c1e445297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, root, phase, transformer=None):\n",
    "        self.root=root\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.image_list=sorted(os.listdir(root+\"image/\"+phase))\n",
    "        self.des_list=sorted(os.listdir(root+\"description/\"+phase))\n",
    "        self.label_list=sorted(os.listdir(root+\"label/\"+phase))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img, des, label = self.get_data(index)\n",
    "        return img, des, label\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def get_data(self, index):\n",
    "        # label\n",
    "        label_file_name=self.label_list[index]\n",
    "        lab_f=open(self.root+\"label/\"+self.phase+\"/\"+label_file_name, \"r\")\n",
    "        label=lab_f.read()\n",
    "\n",
    "        # description\n",
    "        des_file_name=self.des_list[index]\n",
    "        des_f=open(self.root+\"description/\"+self.phase+\"/\"+des_file_name, \"r\")\n",
    "        des_text=des_f.read()\n",
    "#         des=des_text.split(\" \")\n",
    "        des=des_text\n",
    "\n",
    "        # image\n",
    "        img_file_name=self.image_list[index]\n",
    "        image=cv2.imread(self.root+\"image/\"+self.phase+\"/\"+img_file_name)\n",
    "        img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if(self.transformer!=None):\n",
    "            transformed_img=self.transformer(image=img)\n",
    "            img=transformed_img\n",
    "        \n",
    "        return img, des, label\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b37180c3-40c0-4f29-84b7-da062c85be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5e40fb9-26a2-4084-a74c-62d7647138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/workspace/team2/data/nickData/'\n",
    "train_dataset=Dataset(root=root, phase=\"train\", transformer=transformer)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a25b3eb2-ebf3-403c-98db-b3b6fd964e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e25531b84b64b738dc7c7c8a4928e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=49, description='index', max=99), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(train_dataset)-1))\n",
    "def show_sample(index):\n",
    "    img, des, label = train_dataset[index]\n",
    "    image=img['image'].permute(1,2,0).numpy()\n",
    "    print(f'desciption: {des}')\n",
    "    print(f'label: {label}')\n",
    "    print(image.shape)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb5975-f093-4940-952b-abff5967f2fc",
   "metadata": {},
   "source": [
    "## MODELs\n",
    " ![Untitled](../img/nickCLIP_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae290c3",
   "metadata": {},
   "source": [
    "### Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d328de53-85c7-43e6-808c-32c4241de00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        resnet = torchvision.models.resnet34(pretrained = True)\n",
    "        layers = [m for m in resnet.children()]\n",
    "        \n",
    "        self.backbone = nn.Sequential(*layers[:-2]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=128, out_channels=32, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=32, out_channels=4, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(4),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features=784, out_features=768)\n",
    "            \n",
    "            )\n",
    "        \n",
    "#         self.head = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0,bias=False),\n",
    "#                 nn.BatchNorm2d(256),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1,bias=False),\n",
    "#                 nn.BatchNorm2d(128),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(in_channels=128, out_channels=32, kernel_size=3, padding=1,bias=False),\n",
    "#                 nn.BatchNorm2d(32),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, padding=1,bias=False),\n",
    "#                 nn.BatchNorm2d(1),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Flatten()\n",
    "#             )\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.head(out) # final output=> (1, 196)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b041c468-eff7-4f10-a803-cebecf1bbe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "             ReLU-14         [-1, 64, 112, 112]               0\n",
      "           Conv2d-15         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 112, 112]             128\n",
      "             ReLU-17         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-18         [-1, 64, 112, 112]               0\n",
      "           Conv2d-19         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-20         [-1, 64, 112, 112]             128\n",
      "             ReLU-21         [-1, 64, 112, 112]               0\n",
      "           Conv2d-22         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-23         [-1, 64, 112, 112]             128\n",
      "             ReLU-24         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-25         [-1, 64, 112, 112]               0\n",
      "           Conv2d-26          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 56, 56]             256\n",
      "             ReLU-28          [-1, 128, 56, 56]               0\n",
      "           Conv2d-29          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
      "           Conv2d-31          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-34          [-1, 128, 56, 56]               0\n",
      "           Conv2d-35          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 56, 56]             256\n",
      "             ReLU-37          [-1, 128, 56, 56]               0\n",
      "           Conv2d-38          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 56, 56]             256\n",
      "             ReLU-40          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-41          [-1, 128, 56, 56]               0\n",
      "           Conv2d-42          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 56, 56]             256\n",
      "             ReLU-44          [-1, 128, 56, 56]               0\n",
      "           Conv2d-45          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 56, 56]             256\n",
      "             ReLU-47          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-48          [-1, 128, 56, 56]               0\n",
      "           Conv2d-49          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
      "             ReLU-51          [-1, 128, 56, 56]               0\n",
      "           Conv2d-52          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
      "             ReLU-54          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-55          [-1, 128, 56, 56]               0\n",
      "           Conv2d-56          [-1, 256, 28, 28]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 28, 28]             512\n",
      "             ReLU-58          [-1, 256, 28, 28]               0\n",
      "           Conv2d-59          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 28, 28]             512\n",
      "           Conv2d-61          [-1, 256, 28, 28]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 28, 28]             512\n",
      "             ReLU-63          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-64          [-1, 256, 28, 28]               0\n",
      "           Conv2d-65          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 28, 28]             512\n",
      "             ReLU-67          [-1, 256, 28, 28]               0\n",
      "           Conv2d-68          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 28, 28]             512\n",
      "             ReLU-70          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 256, 28, 28]               0\n",
      "           Conv2d-72          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 28, 28]             512\n",
      "             ReLU-74          [-1, 256, 28, 28]               0\n",
      "           Conv2d-75          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 28, 28]             512\n",
      "             ReLU-77          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-78          [-1, 256, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 28, 28]             512\n",
      "             ReLU-84          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-85          [-1, 256, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 28, 28]             512\n",
      "             ReLU-88          [-1, 256, 28, 28]               0\n",
      "           Conv2d-89          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 28, 28]             512\n",
      "             ReLU-91          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-92          [-1, 256, 28, 28]               0\n",
      "           Conv2d-93          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 28, 28]             512\n",
      "             ReLU-95          [-1, 256, 28, 28]               0\n",
      "           Conv2d-96          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 28, 28]             512\n",
      "             ReLU-98          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-99          [-1, 256, 28, 28]               0\n",
      "          Conv2d-100          [-1, 512, 14, 14]       1,179,648\n",
      "     BatchNorm2d-101          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-102          [-1, 512, 14, 14]               0\n",
      "          Conv2d-103          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-104          [-1, 512, 14, 14]           1,024\n",
      "          Conv2d-105          [-1, 512, 14, 14]         131,072\n",
      "     BatchNorm2d-106          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-107          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-108          [-1, 512, 14, 14]               0\n",
      "          Conv2d-109          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-110          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-111          [-1, 512, 14, 14]               0\n",
      "          Conv2d-112          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-113          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-114          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-115          [-1, 512, 14, 14]               0\n",
      "          Conv2d-116          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-117          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-118          [-1, 512, 14, 14]               0\n",
      "          Conv2d-119          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-120          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-121          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-122          [-1, 512, 14, 14]               0\n",
      "          Conv2d-123          [-1, 256, 14, 14]         131,072\n",
      "     BatchNorm2d-124          [-1, 256, 14, 14]             512\n",
      "            ReLU-125          [-1, 256, 14, 14]               0\n",
      "          Conv2d-126          [-1, 128, 14, 14]         294,912\n",
      "     BatchNorm2d-127          [-1, 128, 14, 14]             256\n",
      "            ReLU-128          [-1, 128, 14, 14]               0\n",
      "          Conv2d-129           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-130           [-1, 32, 14, 14]              64\n",
      "            ReLU-131           [-1, 32, 14, 14]               0\n",
      "          Conv2d-132            [-1, 4, 14, 14]           1,152\n",
      "     BatchNorm2d-133            [-1, 4, 14, 14]               8\n",
      "            ReLU-134            [-1, 4, 14, 14]               0\n",
      "         Flatten-135                  [-1, 784]               0\n",
      "          Linear-136                  [-1, 768]         602,880\n",
      "================================================================\n",
      "Total params: 22,352,392\n",
      "Trainable params: 22,352,392\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 387.01\n",
      "Params size (MB): 85.27\n",
      "Estimated Total Size (MB): 474.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Image_Enc = Image_Encoder()\n",
    "Image_Enc.to(device)\n",
    "torchsummary.summary(Image_Enc, (3,448,448))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04259a95",
   "metadata": {},
   "source": [
    "### Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d841b979-6222-4183-854d-a83b06918ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Encoder(nn.Module):\n",
    "    def __init__(self, device, pretrained='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.pretrained=pretrained\n",
    "        self.device=device\n",
    "        self.BERT = BertModel.from_pretrained(self.pretrained)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        tokenizer = BertTokenizer.from_pretrained(self.pretrained)\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        \n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(self.device)\n",
    "        segments_tensors = torch.tensor([segments_ids]).to(self.device)\n",
    "        \n",
    "        return tokens_tensor, segments_tensors\n",
    "        \n",
    "    def postprocess(self, encoded_layers):\n",
    "#         token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "#         token_embeddings = token_embeddings.permute(1,0,2)\n",
    "        token_vecs = encoded_layers[11][0]\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        \n",
    "        return sentence_embedding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tokens_tensor, segments_tensors = self.preprocess(x)\n",
    "        \n",
    "        encoded_layers, _ = self.BERT(tokens_tensor, segments_tensors)\n",
    "        \n",
    "        sentence_embedding = self.postprocess(encoded_layers)\n",
    "        \n",
    "        return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "926c73a0-8099-4ced-a244-25a563220ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Enc=Text_Encoder(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "767d95a6-5999-45a7-9573-4749e7931ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text_Encoder(\n",
       "  (BERT): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_Enc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "093fc8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67115faeeb8b4efda5304902ce0db4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=49, description='index', max=99), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(train_dataset)-1))\n",
    "def show_sample(index):\n",
    "    img, des, label = train_dataset[index]\n",
    "#     image=img['image'].permute(1,2,0).numpy()\n",
    "    image=img['image'].unsqueeze(0).to(device)\n",
    "    print(image.shape)\n",
    "    img_embed=Image_Enc(image)\n",
    "    sen_embed=Text_Enc(des)\n",
    "    print(f'desciption: {des}')\n",
    "    print(f'label: {label}')\n",
    "    print(f\"img shape:{image.shape}\")\n",
    "    print(f'sen_emb shape:{sen_embed.shape}')\n",
    "    print(f'img_embed shape:{img_embed.shape}')\n",
    "    image=image.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cb9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "487d41ac",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_encoder, text_encoder):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf74912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
