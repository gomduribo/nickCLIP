{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3c1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69a064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc78e375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'hello', 'my', 'name', 'is', 'young', '##bo', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text=\"Hello my name is youngbo\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c18d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2026, 2171, 2003, 2402, 5092, 102]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75720bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "hello         7,592\n",
      "my            2,026\n",
      "name          2,171\n",
      "is            2,003\n",
      "young         2,402\n",
      "##bo          5,092\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a9fc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "segments_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c2ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80692685",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "#     hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c97c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.1545,  0.0195, -0.0786,  ..., -0.0880,  0.0727,  0.0560],\n",
       "          [ 0.5052,  0.0383,  0.2937,  ..., -0.0753,  1.0579, -0.6632],\n",
       "          [ 0.2731,  0.4624, -0.3089,  ..., -1.3637,  0.0340, -0.3090],\n",
       "          ...,\n",
       "          [-0.7341, -0.0807,  0.1923,  ..., -0.1601,  0.1035, -1.2278],\n",
       "          [-0.7021,  0.1623,  0.3586,  ...,  0.0350, -0.0816,  0.5968],\n",
       "          [ 0.2316, -0.0331,  0.0127,  ..., -0.0538,  1.0404,  0.1069]]]),\n",
       " tensor([[[ 0.0572, -0.1903, -0.1716,  ...,  0.0111,  0.1342,  0.0215],\n",
       "          [ 0.6783,  0.4242,  0.8778,  ...,  0.3806,  1.0458, -1.0323],\n",
       "          [ 0.2613,  0.4424,  0.0188,  ..., -1.2744,  0.2990, -0.6045],\n",
       "          ...,\n",
       "          [-0.6290,  0.3520,  0.4743,  ..., -0.3998,  0.2656, -1.7474],\n",
       "          [-0.8426,  0.4608, -0.0417,  ...,  0.0709,  0.1479,  0.5743],\n",
       "          [ 0.0574,  0.0451,  0.2252,  ...,  0.1441,  0.8292, -0.1336]]]),\n",
       " tensor([[[-0.0381, -0.0981,  0.0228,  ...,  0.1306,  0.0799,  0.1739],\n",
       "          [ 0.6379,  0.6734,  1.2408,  ...,  0.6515,  0.3667, -0.9592],\n",
       "          [-0.0604,  0.0538,  0.3775,  ..., -0.7150, -0.0360,  0.0543],\n",
       "          ...,\n",
       "          [-1.0203,  0.1433,  1.0027,  ..., -0.5148,  0.2748, -2.1362],\n",
       "          [-0.6654,  0.6900, -0.1123,  ...,  0.0875, -0.5021,  0.0805],\n",
       "          [-0.0324, -0.0290,  0.1511,  ...,  0.1172,  0.1162, -0.0421]]]),\n",
       " tensor([[[-9.7912e-02, -4.1263e-01, -3.1046e-01,  ...,  1.2587e-01,\n",
       "           -7.9628e-02,  5.2394e-01],\n",
       "          [ 5.7989e-01,  3.2873e-01,  1.3278e+00,  ...,  7.8557e-01,\n",
       "            3.5137e-01, -9.1591e-01],\n",
       "          [-3.5736e-01, -6.5142e-02,  3.0000e-01,  ..., -5.6058e-01,\n",
       "           -1.2167e-01,  6.3168e-03],\n",
       "          ...,\n",
       "          [-1.0033e+00, -5.3827e-01,  8.7690e-01,  ..., -7.5196e-01,\n",
       "           -4.3272e-01, -1.8056e+00],\n",
       "          [-6.5856e-01,  2.3477e-02,  1.9663e-01,  ..., -1.2592e-03,\n",
       "           -4.5407e-01,  3.8015e-01],\n",
       "          [-2.8533e-02, -2.3706e-02,  9.2900e-03,  ...,  3.8914e-02,\n",
       "            3.7946e-02, -1.7071e-02]]]),\n",
       " tensor([[[-0.0578, -0.0476, -0.4706,  ..., -0.2233,  0.2018,  0.8885],\n",
       "          [ 0.4717,  0.4890,  1.1135,  ...,  0.1427,  0.5470, -0.8075],\n",
       "          [-0.1472,  0.6292,  0.4658,  ..., -0.4627, -0.3428,  0.4623],\n",
       "          ...,\n",
       "          [-0.8817, -0.4986,  1.1057,  ..., -0.6736, -0.2159, -1.0468],\n",
       "          [ 0.0029,  0.4260,  0.7278,  ..., -0.4111, -0.6945,  0.4655],\n",
       "          [-0.0231, -0.0160, -0.0087,  ...,  0.0416, -0.0130, -0.0126]]]),\n",
       " tensor([[[-0.0808, -0.0038, -0.1582,  ...,  0.0057,  0.1187,  0.9028],\n",
       "          [ 0.3647,  0.5197,  1.3064,  ..., -0.1475, -0.1106, -0.8498],\n",
       "          [-0.1484,  0.1523,  0.4258,  ..., -0.0717, -0.3453,  0.6765],\n",
       "          ...,\n",
       "          [-0.5795, -0.5313,  0.8068,  ..., -0.5080, -0.2400, -1.3920],\n",
       "          [ 0.0211,  0.3550,  0.3449,  ..., -0.6350, -0.7105,  0.2426],\n",
       "          [ 0.0140, -0.0057, -0.0114,  ...,  0.0269, -0.0358, -0.0275]]]),\n",
       " tensor([[[-0.0155,  0.2234, -0.1358,  ..., -0.3010,  0.5430,  0.7861],\n",
       "          [ 0.2452,  0.6005,  1.1650,  ...,  0.2979, -0.2393, -0.9246],\n",
       "          [-0.4033, -0.0821,  0.0929,  ...,  0.2983,  0.5151,  0.8308],\n",
       "          ...,\n",
       "          [-0.6957, -0.6835,  0.9677,  ..., -0.0645, -0.3665, -1.3324],\n",
       "          [-0.2468,  0.5906,  0.4459,  ..., -0.8508, -0.2116,  0.1742],\n",
       "          [ 0.0287,  0.0021, -0.0178,  ..., -0.0100,  0.0089, -0.0491]]]),\n",
       " tensor([[[-0.2828,  0.2896, -0.1360,  ..., -0.5586,  0.4014,  0.7829],\n",
       "          [ 0.0648,  0.5901,  1.0924,  ...,  0.0556, -0.2559, -0.5448],\n",
       "          [-0.3782, -0.1835,  0.1254,  ...,  0.2245,  0.0777,  0.7804],\n",
       "          ...,\n",
       "          [-0.6896, -0.7916,  1.0074,  ...,  0.0606, -0.2479, -1.3888],\n",
       "          [-0.4687,  0.6497,  0.2544,  ..., -0.7030, -0.1661,  0.0538],\n",
       "          [ 0.0452,  0.0204,  0.0302,  ..., -0.0103, -0.0468, -0.0532]]]),\n",
       " tensor([[[-0.2044,  0.4781,  0.1279,  ..., -0.5293, -0.0984,  0.5495],\n",
       "          [-0.2762,  0.7473,  0.9536,  ..., -0.1853, -0.5549, -0.2707],\n",
       "          [-0.4781, -0.0626,  0.1304,  ..., -0.0380, -0.0676,  0.7795],\n",
       "          ...,\n",
       "          [-0.7016, -0.5948,  0.8018,  ...,  0.1232,  0.0070, -0.9771],\n",
       "          [-0.4501,  0.6325,  0.2051,  ..., -0.3873, -0.0643, -0.0718],\n",
       "          [ 0.0065,  0.0703,  0.0046,  ..., -0.0462, -0.0647,  0.0027]]]),\n",
       " tensor([[[-0.2813, -0.4110,  0.2343,  ..., -0.6358,  0.0664,  0.2633],\n",
       "          [-0.8819,  0.1591,  1.2357,  ..., -0.2343, -0.5675, -0.3994],\n",
       "          [-0.6806, -0.6673,  0.3646,  ..., -0.3942,  0.1235,  0.1723],\n",
       "          ...,\n",
       "          [-1.0322, -0.7342,  0.5892,  ...,  0.2942, -0.0669, -1.1880],\n",
       "          [-0.6197,  0.5144,  0.8375,  ...,  0.0386, -0.2132, -0.0222],\n",
       "          [-0.0085, -0.0111, -0.0347,  ...,  0.0354,  0.0197, -0.0167]]]),\n",
       " tensor([[[-0.3760, -0.0896,  0.2530,  ..., -0.3282, -0.3836,  0.1426],\n",
       "          [-0.7449,  0.3992,  0.9265,  ..., -0.5786, -0.2282, -0.0914],\n",
       "          [-0.9868, -0.3397,  0.2261,  ..., -0.5291,  0.1159,  0.7865],\n",
       "          ...,\n",
       "          [-0.8188, -0.6374,  0.3138,  ...,  0.0266, -0.0044, -0.8525],\n",
       "          [-0.3546,  0.5373,  0.4791,  ...,  0.0344, -0.1798,  0.4611],\n",
       "          [ 0.0393,  0.0123, -0.0508,  ...,  0.0123, -0.0099,  0.0075]]]),\n",
       " tensor([[[-0.0692,  0.1482,  0.0358,  ..., -0.2214,  0.0815,  0.5078],\n",
       "          [-0.1674,  0.4965,  1.1598,  ..., -0.4240, -0.0899,  0.0831],\n",
       "          [-0.4800, -0.3586,  0.1958,  ..., -0.3873, -0.3555,  0.4899],\n",
       "          ...,\n",
       "          [-0.5519, -0.4088,  0.0296,  ...,  0.0244,  0.0150, -0.7867],\n",
       "          [-0.1109,  0.3770,  0.2011,  ...,  0.4937,  0.1849,  0.2287],\n",
       "          [ 0.8472, -0.1030, -0.4152,  ..., -0.0538, -0.4774, -0.2627]]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d53a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 8\n",
      "Number of hidden units: 768\n",
      "torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
    "\n",
    "# 8개의 개별 토큰(단어)이 768차원의 12개의 개별 벡터를 가짐 \n",
    "print(encoded_layers[0].shape, encoded_layers[11].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0608eec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe0c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 8, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aba333ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "402e48dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()# 8개의 개별 토큰(단어)이 768차원의 12개의 개별 벡터를 가짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb210e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 8 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [8 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [8 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fee2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `encoded_layers` has shape [12 x 1 x 8 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [8 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 8 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22653e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebba7d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 hello\n",
      "2 my\n",
      "3 name\n",
      "4 is\n",
      "5 young\n",
      "6 ##bo\n",
      "7 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420c79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74066755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
