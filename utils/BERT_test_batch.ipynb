{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3c1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69a064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d101db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "text=\"Hello my name is youngbo ha ha\"\n",
    "text2='this sentence is second sentence'\n",
    "text3='this is test sentence'\n",
    "text4='good to go to picnic'\n",
    "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# marked_text2 = \"[CLS] \" + text2 + \" [SEP]\"\n",
    "# marked_text3 = \"[CLS] \" + text3 + \" [SEP]\"\n",
    "# marked_text4 = \"[CLS] \" + text4 + \" [SEP]\"\n",
    "batch_text=[text,text2, text3,text4]\n",
    "\n",
    "result=tokenizer(batch_text, \n",
    "                 add_special_tokens=True, \n",
    "                 max_length=100, \n",
    "                 padding=\"max_length\",\n",
    "                 truncation=True,\n",
    "                 return_tensors=\"pt\")\n",
    "# print(result)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "with torch.no_grad():\n",
    "    output = model(**result)\n",
    "print(output.last_hidden_state.shape)\n",
    "out=output.last_hidden_state.mean(axis=1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c18d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2026, 2171, 2003, 2402, 5092, 102]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655cc9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 7592, 2026, 2171, 2003, 2402, 5092, 102],\n",
       " [101, 2023, 6251, 2003, 2117, 6251, 102]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens2 = list(map(tokenizer.convert_tokens_to_ids,tokenized_text2))\n",
    "indexed_tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75720bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "hello         7,592\n",
      "my            2,026\n",
      "name          2,171\n",
      "is            2,003\n",
      "young         2,402\n",
      "##bo          5,092\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e41715",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "segments_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7a9fc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segments_ids = [1] * len(tokenized_text)\n",
    "# segments_ids\n",
    "def make_seg_ids(lst):\n",
    "    result=[]\n",
    "    for i in range(len(lst)):\n",
    "        result.append(lst[i]*[1])\n",
    "    return result\n",
    "len_token=list(map(len,tokenized_text2))\n",
    "print(len_token)\n",
    "segments_ids2=make_seg_ids(len_token)\n",
    "segments_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3b5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101, 7592, 2026, 2171, 2003, 2402, 5092, 102], [101, 2023, 6251, 2003, 2117, 6251, 102]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 8 at dim 1 (got 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(indexed_tokens2)\n\u001b[0;32m----> 2\u001b[0m tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexed_tokens2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m segments_tensors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(segments_ids2)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 8 at dim 1 (got 7)"
     ]
    }
   ],
   "source": [
    "print(indexed_tokens2)\n",
    "tokens_tensor = torch.tensor(indexed_tokens2)\n",
    "segments_tensors = torch.tensor(segments_ids2)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c2ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80692685",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "#     hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c97c65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mencoded_layers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "encoded_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d53a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 8\n",
      "Number of hidden units: 768\n",
      "torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
    "\n",
    "# 8개의 개별 토큰(단어)이 768차원의 12개의 개별 벡터를 가짐 \n",
    "print(encoded_layers[0].shape, encoded_layers[11].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0608eec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe0c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 8, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aba333ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "402e48dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()# 8개의 개별 토큰(단어)이 768차원의 12개의 개별 벡터를 가짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb210e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 8 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [8 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [8 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fee2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `encoded_layers` has shape [12 x 1 x 8 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [8 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 8 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22653e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebba7d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 hello\n",
      "2 my\n",
      "3 name\n",
      "4 is\n",
      "5 young\n",
      "6 ##bo\n",
      "7 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420c79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74066755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
